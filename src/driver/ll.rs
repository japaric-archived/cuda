// automatically generated by rust-bindgen

pub const _FEATURES_H: ::std::os::raw::c_uint = 1;
pub const _DEFAULT_SOURCE: ::std::os::raw::c_uint = 1;
pub const __USE_ISOC11: ::std::os::raw::c_uint = 1;
pub const __USE_ISOC99: ::std::os::raw::c_uint = 1;
pub const __USE_ISOC95: ::std::os::raw::c_uint = 1;
pub const __USE_POSIX_IMPLICITLY: ::std::os::raw::c_uint = 1;
pub const _POSIX_SOURCE: ::std::os::raw::c_uint = 1;
pub const _POSIX_C_SOURCE: ::std::os::raw::c_uint = 200809;
pub const __USE_POSIX: ::std::os::raw::c_uint = 1;
pub const __USE_POSIX2: ::std::os::raw::c_uint = 1;
pub const __USE_POSIX199309: ::std::os::raw::c_uint = 1;
pub const __USE_POSIX199506: ::std::os::raw::c_uint = 1;
pub const __USE_XOPEN2K: ::std::os::raw::c_uint = 1;
pub const __USE_XOPEN2K8: ::std::os::raw::c_uint = 1;
pub const _ATFILE_SOURCE: ::std::os::raw::c_uint = 1;
pub const __USE_MISC: ::std::os::raw::c_uint = 1;
pub const __USE_ATFILE: ::std::os::raw::c_uint = 1;
pub const __USE_FORTIFY_LEVEL: ::std::os::raw::c_uint = 0;
pub const _STDC_PREDEF_H: ::std::os::raw::c_uint = 1;
pub const __STDC_IEC_559__: ::std::os::raw::c_uint = 1;
pub const __STDC_IEC_559_COMPLEX__: ::std::os::raw::c_uint = 1;
pub const __STDC_ISO_10646__: ::std::os::raw::c_uint = 201505;
pub const __STDC_NO_THREADS__: ::std::os::raw::c_uint = 1;
pub const __GNU_LIBRARY__: ::std::os::raw::c_uint = 6;
pub const __GLIBC__: ::std::os::raw::c_uint = 2;
pub const __GLIBC_MINOR__: ::std::os::raw::c_uint = 24;
pub const _SYS_CDEFS_H: ::std::os::raw::c_uint = 1;
pub const __WORDSIZE: ::std::os::raw::c_uint = 64;
pub const __WORDSIZE_TIME64_COMPAT32: ::std::os::raw::c_uint = 1;
pub const __SYSCALL_WORDSIZE: ::std::os::raw::c_uint = 64;
pub const _STDLIB_H: ::std::os::raw::c_uint = 1;
pub const WNOHANG: ::std::os::raw::c_uint = 1;
pub const WUNTRACED: ::std::os::raw::c_uint = 2;
pub const WSTOPPED: ::std::os::raw::c_uint = 2;
pub const WEXITED: ::std::os::raw::c_uint = 4;
pub const WCONTINUED: ::std::os::raw::c_uint = 8;
pub const WNOWAIT: ::std::os::raw::c_uint = 16777216;
pub const __WNOTHREAD: ::std::os::raw::c_uint = 536870912;
pub const __WALL: ::std::os::raw::c_uint = 1073741824;
pub const __WCLONE: ::std::os::raw::c_uint = 2147483648;
pub const __W_CONTINUED: ::std::os::raw::c_uint = 65535;
pub const __WCOREFLAG: ::std::os::raw::c_uint = 128;
pub const __ldiv_t_defined: ::std::os::raw::c_uint = 1;
pub const RAND_MAX: ::std::os::raw::c_uint = 2147483647;
pub const EXIT_FAILURE: ::std::os::raw::c_uint = 1;
pub const EXIT_SUCCESS: ::std::os::raw::c_uint = 0;
pub const _SYS_TYPES_H: ::std::os::raw::c_uint = 1;
pub const _BITS_TYPES_H: ::std::os::raw::c_uint = 1;
pub const _BITS_TYPESIZES_H: ::std::os::raw::c_uint = 1;
pub const __OFF_T_MATCHES_OFF64_T: ::std::os::raw::c_uint = 1;
pub const __INO_T_MATCHES_INO64_T: ::std::os::raw::c_uint = 1;
pub const __FD_SETSIZE: ::std::os::raw::c_uint = 1024;
pub const __clock_t_defined: ::std::os::raw::c_uint = 1;
pub const __time_t_defined: ::std::os::raw::c_uint = 1;
pub const __clockid_t_defined: ::std::os::raw::c_uint = 1;
pub const __timer_t_defined: ::std::os::raw::c_uint = 1;
pub const __BIT_TYPES_DEFINED__: ::std::os::raw::c_uint = 1;
pub const _ENDIAN_H: ::std::os::raw::c_uint = 1;
pub const __LITTLE_ENDIAN: ::std::os::raw::c_uint = 1234;
pub const __BIG_ENDIAN: ::std::os::raw::c_uint = 4321;
pub const __PDP_ENDIAN: ::std::os::raw::c_uint = 3412;
pub const __BYTE_ORDER: ::std::os::raw::c_uint = 1234;
pub const __FLOAT_WORD_ORDER: ::std::os::raw::c_uint = 1234;
pub const LITTLE_ENDIAN: ::std::os::raw::c_uint = 1234;
pub const BIG_ENDIAN: ::std::os::raw::c_uint = 4321;
pub const PDP_ENDIAN: ::std::os::raw::c_uint = 3412;
pub const BYTE_ORDER: ::std::os::raw::c_uint = 1234;
pub const _BITS_BYTESWAP_H: ::std::os::raw::c_uint = 1;
pub const _SYS_SELECT_H: ::std::os::raw::c_uint = 1;
pub const __FD_ZERO_STOS: &'static [u8; 6usize] = b"stosq\x00";
pub const _SIGSET_H_types: ::std::os::raw::c_uint = 1;
pub const __timespec_defined: ::std::os::raw::c_uint = 1;
pub const _STRUCT_TIMEVAL: ::std::os::raw::c_uint = 1;
pub const FD_SETSIZE: ::std::os::raw::c_uint = 1024;
pub const _SYS_SYSMACROS_H: ::std::os::raw::c_uint = 1;
pub const _BITS_PTHREADTYPES_H: ::std::os::raw::c_uint = 1;
pub const __SIZEOF_PTHREAD_ATTR_T: ::std::os::raw::c_uint = 56;
pub const __SIZEOF_PTHREAD_MUTEX_T: ::std::os::raw::c_uint = 40;
pub const __SIZEOF_PTHREAD_MUTEXATTR_T: ::std::os::raw::c_uint = 4;
pub const __SIZEOF_PTHREAD_COND_T: ::std::os::raw::c_uint = 48;
pub const __SIZEOF_PTHREAD_CONDATTR_T: ::std::os::raw::c_uint = 4;
pub const __SIZEOF_PTHREAD_RWLOCK_T: ::std::os::raw::c_uint = 56;
pub const __SIZEOF_PTHREAD_RWLOCKATTR_T: ::std::os::raw::c_uint = 8;
pub const __SIZEOF_PTHREAD_BARRIER_T: ::std::os::raw::c_uint = 32;
pub const __SIZEOF_PTHREAD_BARRIERATTR_T: ::std::os::raw::c_uint = 4;
pub const __have_pthread_attr_t: ::std::os::raw::c_uint = 1;
pub const __PTHREAD_MUTEX_HAVE_PREV: ::std::os::raw::c_uint = 1;
pub const _ALLOCA_H: ::std::os::raw::c_uint = 1;
pub const _STDINT_H: ::std::os::raw::c_uint = 1;
pub const _BITS_WCHAR_H: ::std::os::raw::c_uint = 1;
pub const INT8_MIN: ::std::os::raw::c_int = -128;
pub const INT16_MIN: ::std::os::raw::c_int = -32768;
pub const INT32_MIN: ::std::os::raw::c_int = -2147483648;
pub const INT8_MAX: ::std::os::raw::c_uint = 127;
pub const INT16_MAX: ::std::os::raw::c_uint = 32767;
pub const INT32_MAX: ::std::os::raw::c_uint = 2147483647;
pub const UINT8_MAX: ::std::os::raw::c_uint = 255;
pub const UINT16_MAX: ::std::os::raw::c_uint = 65535;
pub const UINT32_MAX: ::std::os::raw::c_uint = 4294967295;
pub const INT_LEAST8_MIN: ::std::os::raw::c_int = -128;
pub const INT_LEAST16_MIN: ::std::os::raw::c_int = -32768;
pub const INT_LEAST32_MIN: ::std::os::raw::c_int = -2147483648;
pub const INT_LEAST8_MAX: ::std::os::raw::c_uint = 127;
pub const INT_LEAST16_MAX: ::std::os::raw::c_uint = 32767;
pub const INT_LEAST32_MAX: ::std::os::raw::c_uint = 2147483647;
pub const UINT_LEAST8_MAX: ::std::os::raw::c_uint = 255;
pub const UINT_LEAST16_MAX: ::std::os::raw::c_uint = 65535;
pub const UINT_LEAST32_MAX: ::std::os::raw::c_uint = 4294967295;
pub const INT_FAST8_MIN: ::std::os::raw::c_int = -128;
pub const INT_FAST16_MIN: ::std::os::raw::c_longlong = -9223372036854775808;
pub const INT_FAST32_MIN: ::std::os::raw::c_longlong = -9223372036854775808;
pub const INT_FAST8_MAX: ::std::os::raw::c_uint = 127;
pub const INT_FAST16_MAX: ::std::os::raw::c_ulonglong = 9223372036854775807;
pub const INT_FAST32_MAX: ::std::os::raw::c_ulonglong = 9223372036854775807;
pub const UINT_FAST8_MAX: ::std::os::raw::c_uint = 255;
pub const UINT_FAST16_MAX: ::std::os::raw::c_int = -1;
pub const UINT_FAST32_MAX: ::std::os::raw::c_int = -1;
pub const INTPTR_MIN: ::std::os::raw::c_longlong = -9223372036854775808;
pub const INTPTR_MAX: ::std::os::raw::c_ulonglong = 9223372036854775807;
pub const UINTPTR_MAX: ::std::os::raw::c_int = -1;
pub const PTRDIFF_MIN: ::std::os::raw::c_longlong = -9223372036854775808;
pub const PTRDIFF_MAX: ::std::os::raw::c_ulonglong = 9223372036854775807;
pub const SIG_ATOMIC_MIN: ::std::os::raw::c_int = -2147483648;
pub const SIG_ATOMIC_MAX: ::std::os::raw::c_uint = 2147483647;
pub const SIZE_MAX: ::std::os::raw::c_int = -1;
pub const WINT_MIN: ::std::os::raw::c_uint = 0;
pub const WINT_MAX: ::std::os::raw::c_uint = 4294967295;
pub const __CUDA_API_VERSION: ::std::os::raw::c_uint = 8000;
pub const CUDA_VERSION: ::std::os::raw::c_uint = 8000;
pub const CU_IPC_HANDLE_SIZE: ::std::os::raw::c_uint = 64;
pub const CU_MEMHOSTALLOC_PORTABLE: ::std::os::raw::c_uint = 1;
pub const CU_MEMHOSTALLOC_DEVICEMAP: ::std::os::raw::c_uint = 2;
pub const CU_MEMHOSTALLOC_WRITECOMBINED: ::std::os::raw::c_uint = 4;
pub const CU_MEMHOSTREGISTER_PORTABLE: ::std::os::raw::c_uint = 1;
pub const CU_MEMHOSTREGISTER_DEVICEMAP: ::std::os::raw::c_uint = 2;
pub const CU_MEMHOSTREGISTER_IOMEMORY: ::std::os::raw::c_uint = 4;
pub const CUDA_ARRAY3D_LAYERED: ::std::os::raw::c_uint = 1;
pub const CUDA_ARRAY3D_2DARRAY: ::std::os::raw::c_uint = 1;
pub const CUDA_ARRAY3D_SURFACE_LDST: ::std::os::raw::c_uint = 2;
pub const CUDA_ARRAY3D_CUBEMAP: ::std::os::raw::c_uint = 4;
pub const CUDA_ARRAY3D_TEXTURE_GATHER: ::std::os::raw::c_uint = 8;
pub const CUDA_ARRAY3D_DEPTH_TEXTURE: ::std::os::raw::c_uint = 16;
pub const CU_TRSA_OVERRIDE_FORMAT: ::std::os::raw::c_uint = 1;
pub const CU_TRSF_READ_AS_INTEGER: ::std::os::raw::c_uint = 1;
pub const CU_TRSF_NORMALIZED_COORDINATES: ::std::os::raw::c_uint = 2;
pub const CU_TRSF_SRGB: ::std::os::raw::c_uint = 16;
pub const CU_PARAM_TR_DEFAULT: ::std::os::raw::c_int = -1;
pub type wchar_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_1 {
    pub quot: ::std::os::raw::c_int,
    pub rem: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout__bindgen_ty_1() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_1>(), 8usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_1>(), 4usize);
}
impl Clone for _bindgen_ty_1 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type div_t = _bindgen_ty_1;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_2 {
    pub quot: ::std::os::raw::c_long,
    pub rem: ::std::os::raw::c_long,
}
#[test]
fn bindgen_test_layout__bindgen_ty_2() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_2>(), 16usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_2>(), 8usize);
}
impl Clone for _bindgen_ty_2 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type ldiv_t = _bindgen_ty_2;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_3 {
    pub quot: ::std::os::raw::c_longlong,
    pub rem: ::std::os::raw::c_longlong,
}
#[test]
fn bindgen_test_layout__bindgen_ty_3() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_3>(), 16usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_3>(), 8usize);
}
impl Clone for _bindgen_ty_3 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type lldiv_t = _bindgen_ty_3;
extern "C" {
    pub fn __ctype_get_mb_cur_max() -> usize;
}
extern "C" {
    pub fn atof(__nptr: *const ::std::os::raw::c_char) -> f64;
}
extern "C" {
    pub fn atoi(__nptr: *const ::std::os::raw::c_char)
                -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn atol(__nptr: *const ::std::os::raw::c_char)
                -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn atoll(__nptr: *const ::std::os::raw::c_char)
                 -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtod(__nptr: *const ::std::os::raw::c_char,
                  __endptr: *mut *mut ::std::os::raw::c_char)
                  -> f64;
}
extern "C" {
    pub fn strtof(__nptr: *const ::std::os::raw::c_char,
                  __endptr: *mut *mut ::std::os::raw::c_char)
                  -> f32;
}
extern "C" {
    pub fn strtold(__nptr: *const ::std::os::raw::c_char,
                   __endptr: *mut *mut ::std::os::raw::c_char)
                   -> f64;
}
extern "C" {
    pub fn strtol(__nptr: *const ::std::os::raw::c_char,
                  __endptr: *mut *mut ::std::os::raw::c_char,
                  __base: ::std::os::raw::c_int)
                  -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn strtoul(__nptr: *const ::std::os::raw::c_char,
                   __endptr: *mut *mut ::std::os::raw::c_char,
                   __base: ::std::os::raw::c_int)
                   -> ::std::os::raw::c_ulong;
}
extern "C" {
    pub fn strtoq(__nptr: *const ::std::os::raw::c_char,
                  __endptr: *mut *mut ::std::os::raw::c_char,
                  __base: ::std::os::raw::c_int)
                  -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtouq(__nptr: *const ::std::os::raw::c_char,
                   __endptr: *mut *mut ::std::os::raw::c_char,
                   __base: ::std::os::raw::c_int)
                   -> ::std::os::raw::c_ulonglong;
}
extern "C" {
    pub fn strtoll(__nptr: *const ::std::os::raw::c_char,
                   __endptr: *mut *mut ::std::os::raw::c_char,
                   __base: ::std::os::raw::c_int)
                   -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn strtoull(__nptr: *const ::std::os::raw::c_char,
                    __endptr: *mut *mut ::std::os::raw::c_char,
                    __base: ::std::os::raw::c_int)
                    -> ::std::os::raw::c_ulonglong;
}
extern "C" {
    pub fn l64a(__n: ::std::os::raw::c_long) -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn a64l(__s: *const ::std::os::raw::c_char) -> ::std::os::raw::c_long;
}
pub type __u_char = ::std::os::raw::c_uchar;
pub type __u_short = ::std::os::raw::c_ushort;
pub type __u_int = ::std::os::raw::c_uint;
pub type __u_long = ::std::os::raw::c_ulong;
pub type __int8_t = ::std::os::raw::c_char;
pub type __uint8_t = ::std::os::raw::c_uchar;
pub type __int16_t = ::std::os::raw::c_short;
pub type __uint16_t = ::std::os::raw::c_ushort;
pub type __int32_t = ::std::os::raw::c_int;
pub type __uint32_t = ::std::os::raw::c_uint;
pub type __int64_t = ::std::os::raw::c_long;
pub type __uint64_t = ::std::os::raw::c_ulong;
pub type __quad_t = ::std::os::raw::c_long;
pub type __u_quad_t = ::std::os::raw::c_ulong;
pub type __dev_t = ::std::os::raw::c_ulong;
pub type __uid_t = ::std::os::raw::c_uint;
pub type __gid_t = ::std::os::raw::c_uint;
pub type __ino_t = ::std::os::raw::c_ulong;
pub type __ino64_t = ::std::os::raw::c_ulong;
pub type __mode_t = ::std::os::raw::c_uint;
pub type __nlink_t = ::std::os::raw::c_ulong;
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __pid_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_4 {
    pub __val: [::std::os::raw::c_int; 2usize],
}
#[test]
fn bindgen_test_layout__bindgen_ty_4() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_4>(), 8usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_4>(), 4usize);
}
impl Clone for _bindgen_ty_4 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type __fsid_t = _bindgen_ty_4;
pub type __clock_t = ::std::os::raw::c_long;
pub type __rlim_t = ::std::os::raw::c_ulong;
pub type __rlim64_t = ::std::os::raw::c_ulong;
pub type __id_t = ::std::os::raw::c_uint;
pub type __time_t = ::std::os::raw::c_long;
pub type __useconds_t = ::std::os::raw::c_uint;
pub type __suseconds_t = ::std::os::raw::c_long;
pub type __daddr_t = ::std::os::raw::c_int;
pub type __key_t = ::std::os::raw::c_int;
pub type __clockid_t = ::std::os::raw::c_int;
pub type __timer_t = *mut ::std::os::raw::c_void;
pub type __blksize_t = ::std::os::raw::c_long;
pub type __blkcnt_t = ::std::os::raw::c_long;
pub type __blkcnt64_t = ::std::os::raw::c_long;
pub type __fsblkcnt_t = ::std::os::raw::c_ulong;
pub type __fsblkcnt64_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt64_t = ::std::os::raw::c_ulong;
pub type __fsword_t = ::std::os::raw::c_long;
pub type __ssize_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
pub type __syscall_ulong_t = ::std::os::raw::c_ulong;
pub type __loff_t = __off64_t;
pub type __qaddr_t = *mut __quad_t;
pub type __caddr_t = *mut ::std::os::raw::c_char;
pub type __intptr_t = ::std::os::raw::c_long;
pub type __socklen_t = ::std::os::raw::c_uint;
pub type u_char = __u_char;
pub type u_short = __u_short;
pub type u_int = __u_int;
pub type u_long = __u_long;
pub type quad_t = __quad_t;
pub type u_quad_t = __u_quad_t;
pub type fsid_t = __fsid_t;
pub type loff_t = __loff_t;
pub type ino_t = __ino_t;
pub type dev_t = __dev_t;
pub type gid_t = __gid_t;
pub type mode_t = __mode_t;
pub type nlink_t = __nlink_t;
pub type uid_t = __uid_t;
pub type off_t = __off_t;
pub type pid_t = __pid_t;
pub type id_t = __id_t;
pub type daddr_t = __daddr_t;
pub type caddr_t = __caddr_t;
pub type key_t = __key_t;
pub type clock_t = __clock_t;
pub type time_t = __time_t;
pub type clockid_t = __clockid_t;
pub type timer_t = __timer_t;
pub type ulong = ::std::os::raw::c_ulong;
pub type ushort = ::std::os::raw::c_ushort;
pub type uint = ::std::os::raw::c_uint;
pub type u_int8_t = ::std::os::raw::c_uchar;
pub type u_int16_t = ::std::os::raw::c_ushort;
pub type u_int32_t = ::std::os::raw::c_uint;
pub type u_int64_t = ::std::os::raw::c_ulong;
pub type register_t = ::std::os::raw::c_long;
pub type __sig_atomic_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_5 {
    pub __val: [::std::os::raw::c_ulong; 16usize],
}
#[test]
fn bindgen_test_layout__bindgen_ty_5() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_5>(), 128usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_5>(), 8usize);
}
impl Clone for _bindgen_ty_5 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type __sigset_t = _bindgen_ty_5;
pub type sigset_t = __sigset_t;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct timespec {
    pub tv_sec: __time_t,
    pub tv_nsec: __syscall_slong_t,
}
#[test]
fn bindgen_test_layout_timespec() {
    assert_eq!(::std::mem::size_of::<timespec>(), 16usize);
    assert_eq!(::std::mem::align_of::<timespec>(), 8usize);
}
impl Clone for timespec {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct timeval {
    pub tv_sec: __time_t,
    pub tv_usec: __suseconds_t,
}
#[test]
fn bindgen_test_layout_timeval() {
    assert_eq!(::std::mem::size_of::<timeval>(), 16usize);
    assert_eq!(::std::mem::align_of::<timeval>(), 8usize);
}
impl Clone for timeval {
    fn clone(&self) -> Self {
        *self
    }
}
pub type suseconds_t = __suseconds_t;
pub type __fd_mask = ::std::os::raw::c_long;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_6 {
    pub __fds_bits: [__fd_mask; 16usize],
}
#[test]
fn bindgen_test_layout__bindgen_ty_6() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_6>(), 128usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_6>(), 8usize);
}
impl Clone for _bindgen_ty_6 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type fd_set = _bindgen_ty_6;
pub type fd_mask = __fd_mask;
extern "C" {
    pub fn select(__nfds: ::std::os::raw::c_int,
                  __readfds: *mut fd_set,
                  __writefds: *mut fd_set,
                  __exceptfds: *mut fd_set,
                  __timeout: *mut timeval)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn pselect(__nfds: ::std::os::raw::c_int,
                   __readfds: *mut fd_set,
                   __writefds: *mut fd_set,
                   __exceptfds: *mut fd_set,
                   __timeout: *const timespec,
                   __sigmask: *const __sigset_t)
                   -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn gnu_dev_major(__dev: ::std::os::raw::c_ulonglong)
                         -> ::std::os::raw::c_uint;
}
extern "C" {
    pub fn gnu_dev_minor(__dev: ::std::os::raw::c_ulonglong)
                         -> ::std::os::raw::c_uint;
}
extern "C" {
    pub fn gnu_dev_makedev(__major: ::std::os::raw::c_uint,
                           __minor: ::std::os::raw::c_uint)
                           -> ::std::os::raw::c_ulonglong;
}
pub type blksize_t = __blksize_t;
pub type blkcnt_t = __blkcnt_t;
pub type fsblkcnt_t = __fsblkcnt_t;
pub type fsfilcnt_t = __fsfilcnt_t;
pub type pthread_t = ::std::os::raw::c_ulong;
#[repr(C)]
pub union pthread_attr_t {
    pub __size: [::std::os::raw::c_char; 56usize],
    pub __align: ::std::os::raw::c_long,
}
#[test]
fn bindgen_test_layout_pthread_attr_t() {
    assert_eq!(::std::mem::size_of::<pthread_attr_t>(), 56usize);
    assert_eq!(::std::mem::align_of::<pthread_attr_t>(), 8usize);
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct __pthread_internal_list {
    pub __prev: *mut __pthread_internal_list,
    pub __next: *mut __pthread_internal_list,
}
#[test]
fn bindgen_test_layout___pthread_internal_list() {
    assert_eq!(::std::mem::size_of::<__pthread_internal_list>(), 16usize);
    assert_eq!(::std::mem::align_of::<__pthread_internal_list>(), 8usize);
}
impl Clone for __pthread_internal_list {
    fn clone(&self) -> Self {
        *self
    }
}
pub type __pthread_list_t = __pthread_internal_list;
#[repr(C)]
pub union _bindgen_ty_7 {
    pub __data: _bindgen_ty_7___pthread_mutex_s,
    pub __size: [::std::os::raw::c_char; 40usize],
    pub __align: ::std::os::raw::c_long,
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_7___pthread_mutex_s {
    pub __lock: ::std::os::raw::c_int,
    pub __count: ::std::os::raw::c_uint,
    pub __owner: ::std::os::raw::c_int,
    pub __nusers: ::std::os::raw::c_uint,
    pub __kind: ::std::os::raw::c_int,
    pub __spins: ::std::os::raw::c_short,
    pub __elision: ::std::os::raw::c_short,
    pub __list: __pthread_list_t,
}
#[test]
fn bindgen_test_layout__bindgen_ty_7___pthread_mutex_s() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_7___pthread_mutex_s>(),
               40usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_7___pthread_mutex_s>(),
               8usize);
}
impl Clone for _bindgen_ty_7___pthread_mutex_s {
    fn clone(&self) -> Self {
        *self
    }
}
#[test]
fn bindgen_test_layout__bindgen_ty_7() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_7>(), 40usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_7>(), 8usize);
}
pub type pthread_mutex_t = _bindgen_ty_7;
#[repr(C)]
#[derive(Copy)]
pub union _bindgen_ty_8 {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout__bindgen_ty_8() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_8>(), 4usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_8>(), 4usize);
}
impl Clone for _bindgen_ty_8 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type pthread_mutexattr_t = _bindgen_ty_8;
#[repr(C)]
pub union _bindgen_ty_9 {
    pub __data: _bindgen_ty_9__bindgen_ty_1,
    pub __size: [::std::os::raw::c_char; 48usize],
    pub __align: ::std::os::raw::c_longlong,
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_9__bindgen_ty_1 {
    pub __lock: ::std::os::raw::c_int,
    pub __futex: ::std::os::raw::c_uint,
    pub __total_seq: ::std::os::raw::c_ulonglong,
    pub __wakeup_seq: ::std::os::raw::c_ulonglong,
    pub __woken_seq: ::std::os::raw::c_ulonglong,
    pub __mutex: *mut ::std::os::raw::c_void,
    pub __nwaiters: ::std::os::raw::c_uint,
    pub __broadcast_seq: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout__bindgen_ty_9__bindgen_ty_1() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_9__bindgen_ty_1>(),
               48usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_9__bindgen_ty_1>(),
               8usize);
}
impl Clone for _bindgen_ty_9__bindgen_ty_1 {
    fn clone(&self) -> Self {
        *self
    }
}
#[test]
fn bindgen_test_layout__bindgen_ty_9() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_9>(), 48usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_9>(), 8usize);
}
pub type pthread_cond_t = _bindgen_ty_9;
#[repr(C)]
#[derive(Copy)]
pub union _bindgen_ty_10 {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout__bindgen_ty_10() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_10>(), 4usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_10>(), 4usize);
}
impl Clone for _bindgen_ty_10 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type pthread_condattr_t = _bindgen_ty_10;
pub type pthread_key_t = ::std::os::raw::c_uint;
pub type pthread_once_t = ::std::os::raw::c_int;
#[repr(C)]
pub union _bindgen_ty_11 {
    pub __data: _bindgen_ty_11__bindgen_ty_1,
    pub __size: [::std::os::raw::c_char; 56usize],
    pub __align: ::std::os::raw::c_long,
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct _bindgen_ty_11__bindgen_ty_1 {
    pub __lock: ::std::os::raw::c_int,
    pub __nr_readers: ::std::os::raw::c_uint,
    pub __readers_wakeup: ::std::os::raw::c_uint,
    pub __writer_wakeup: ::std::os::raw::c_uint,
    pub __nr_readers_queued: ::std::os::raw::c_uint,
    pub __nr_writers_queued: ::std::os::raw::c_uint,
    pub __writer: ::std::os::raw::c_int,
    pub __shared: ::std::os::raw::c_int,
    pub __rwelision: ::std::os::raw::c_char,
    pub __pad1: [::std::os::raw::c_uchar; 7usize],
    pub __pad2: ::std::os::raw::c_ulong,
    pub __flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout__bindgen_ty_11__bindgen_ty_1() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_11__bindgen_ty_1>(),
               56usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_11__bindgen_ty_1>(),
               8usize);
}
impl Clone for _bindgen_ty_11__bindgen_ty_1 {
    fn clone(&self) -> Self {
        *self
    }
}
#[test]
fn bindgen_test_layout__bindgen_ty_11() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_11>(), 56usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_11>(), 8usize);
}
pub type pthread_rwlock_t = _bindgen_ty_11;
#[repr(C)]
#[derive(Copy)]
pub union _bindgen_ty_12 {
    pub __size: [::std::os::raw::c_char; 8usize],
    pub __align: ::std::os::raw::c_long,
}
#[test]
fn bindgen_test_layout__bindgen_ty_12() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_12>(), 8usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_12>(), 8usize);
}
impl Clone for _bindgen_ty_12 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type pthread_rwlockattr_t = _bindgen_ty_12;
pub type pthread_spinlock_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Copy)]
pub union _bindgen_ty_13 {
    pub __size: [::std::os::raw::c_char; 32usize],
    pub __align: ::std::os::raw::c_long,
}
#[test]
fn bindgen_test_layout__bindgen_ty_13() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_13>(), 32usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_13>(), 8usize);
}
impl Clone for _bindgen_ty_13 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type pthread_barrier_t = _bindgen_ty_13;
#[repr(C)]
#[derive(Copy)]
pub union _bindgen_ty_14 {
    pub __size: [::std::os::raw::c_char; 4usize],
    pub __align: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout__bindgen_ty_14() {
    assert_eq!(::std::mem::size_of::<_bindgen_ty_14>(), 4usize);
    assert_eq!(::std::mem::align_of::<_bindgen_ty_14>(), 4usize);
}
impl Clone for _bindgen_ty_14 {
    fn clone(&self) -> Self {
        *self
    }
}
pub type pthread_barrierattr_t = _bindgen_ty_14;
extern "C" {
    pub fn random() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srandom(__seed: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn initstate(__seed: ::std::os::raw::c_uint,
                     __statebuf: *mut ::std::os::raw::c_char,
                     __statelen: usize)
                     -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn setstate(__statebuf: *mut ::std::os::raw::c_char)
                    -> *mut ::std::os::raw::c_char;
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct random_data {
    pub fptr: *mut i32,
    pub rptr: *mut i32,
    pub state: *mut i32,
    pub rand_type: ::std::os::raw::c_int,
    pub rand_deg: ::std::os::raw::c_int,
    pub rand_sep: ::std::os::raw::c_int,
    pub end_ptr: *mut i32,
}
#[test]
fn bindgen_test_layout_random_data() {
    assert_eq!(::std::mem::size_of::<random_data>(), 48usize);
    assert_eq!(::std::mem::align_of::<random_data>(), 8usize);
}
impl Clone for random_data {
    fn clone(&self) -> Self {
        *self
    }
}
extern "C" {
    pub fn random_r(__buf: *mut random_data,
                    __result: *mut i32)
                    -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srandom_r(__seed: ::std::os::raw::c_uint,
                     __buf: *mut random_data)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn initstate_r(__seed: ::std::os::raw::c_uint,
                       __statebuf: *mut ::std::os::raw::c_char,
                       __statelen: usize,
                       __buf: *mut random_data)
                       -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setstate_r(__statebuf: *mut ::std::os::raw::c_char,
                      __buf: *mut random_data)
                      -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn rand() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srand(__seed: ::std::os::raw::c_uint);
}
extern "C" {
    pub fn rand_r(__seed: *mut ::std::os::raw::c_uint)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn drand48() -> f64;
}
extern "C" {
    pub fn erand48(__xsubi: *mut ::std::os::raw::c_ushort) -> f64;
}
extern "C" {
    pub fn lrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn nrand48(__xsubi: *mut ::std::os::raw::c_ushort)
                   -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn mrand48() -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn jrand48(__xsubi: *mut ::std::os::raw::c_ushort)
                   -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn srand48(__seedval: ::std::os::raw::c_long);
}
extern "C" {
    pub fn seed48(__seed16v: *mut ::std::os::raw::c_ushort)
                  -> *mut ::std::os::raw::c_ushort;
}
extern "C" {
    pub fn lcong48(__param: *mut ::std::os::raw::c_ushort);
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct drand48_data {
    pub __x: [::std::os::raw::c_ushort; 3usize],
    pub __old_x: [::std::os::raw::c_ushort; 3usize],
    pub __c: ::std::os::raw::c_ushort,
    pub __init: ::std::os::raw::c_ushort,
    pub __a: ::std::os::raw::c_ulonglong,
}
#[test]
fn bindgen_test_layout_drand48_data() {
    assert_eq!(::std::mem::size_of::<drand48_data>(), 24usize);
    assert_eq!(::std::mem::align_of::<drand48_data>(), 8usize);
}
impl Clone for drand48_data {
    fn clone(&self) -> Self {
        *self
    }
}
extern "C" {
    pub fn drand48_r(__buffer: *mut drand48_data,
                     __result: *mut f64)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn erand48_r(__xsubi: *mut ::std::os::raw::c_ushort,
                     __buffer: *mut drand48_data,
                     __result: *mut f64)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn lrand48_r(__buffer: *mut drand48_data,
                     __result: *mut ::std::os::raw::c_long)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn nrand48_r(__xsubi: *mut ::std::os::raw::c_ushort,
                     __buffer: *mut drand48_data,
                     __result: *mut ::std::os::raw::c_long)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mrand48_r(__buffer: *mut drand48_data,
                     __result: *mut ::std::os::raw::c_long)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn jrand48_r(__xsubi: *mut ::std::os::raw::c_ushort,
                     __buffer: *mut drand48_data,
                     __result: *mut ::std::os::raw::c_long)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn srand48_r(__seedval: ::std::os::raw::c_long,
                     __buffer: *mut drand48_data)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn seed48_r(__seed16v: *mut ::std::os::raw::c_ushort,
                    __buffer: *mut drand48_data)
                    -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn lcong48_r(__param: *mut ::std::os::raw::c_ushort,
                     __buffer: *mut drand48_data)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn malloc(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn calloc(__nmemb: usize,
                  __size: usize)
                  -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn realloc(__ptr: *mut ::std::os::raw::c_void,
                   __size: usize)
                   -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn free(__ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    pub fn cfree(__ptr: *mut ::std::os::raw::c_void);
}
extern "C" {
    pub fn alloca(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn valloc(__size: usize) -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn posix_memalign(__memptr: *mut *mut ::std::os::raw::c_void,
                          __alignment: usize,
                          __size: usize)
                          -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn aligned_alloc(__alignment: usize,
                         __size: usize)
                         -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn abort();
}
extern "C" {
    pub fn atexit(__func: ::std::option::Option<unsafe extern "C" fn()>)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn at_quick_exit(__func:
                             ::std::option::Option<unsafe extern "C" fn()>)
     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn on_exit(__func:
                       ::std::option::Option<unsafe extern "C" fn(__status:
                                                                      ::std::os::raw::c_int,
                                                                  __arg:
                                                                      *mut ::std::os::raw::c_void)>,
                   __arg: *mut ::std::os::raw::c_void)
     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn quick_exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn _Exit(__status: ::std::os::raw::c_int);
}
extern "C" {
    pub fn getenv(__name: *const ::std::os::raw::c_char)
                  -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn putenv(__string: *mut ::std::os::raw::c_char)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn setenv(__name: *const ::std::os::raw::c_char,
                  __value: *const ::std::os::raw::c_char,
                  __replace: ::std::os::raw::c_int)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn unsetenv(__name: *const ::std::os::raw::c_char)
                    -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn clearenv() -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mktemp(__template: *mut ::std::os::raw::c_char)
                  -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn mkstemp(__template: *mut ::std::os::raw::c_char)
                   -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mkstemps(__template: *mut ::std::os::raw::c_char,
                    __suffixlen: ::std::os::raw::c_int)
                    -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mkdtemp(__template: *mut ::std::os::raw::c_char)
                   -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn system(__command: *const ::std::os::raw::c_char)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn realpath(__name: *const ::std::os::raw::c_char,
                    __resolved: *mut ::std::os::raw::c_char)
                    -> *mut ::std::os::raw::c_char;
}
pub type __compar_fn_t =
    ::std::option::Option<unsafe extern "C" fn(arg1:
                                                   *const ::std::os::raw::c_void,
                                               arg2:
                                                   *const ::std::os::raw::c_void)
                              -> ::std::os::raw::c_int>;
extern "C" {
    pub fn bsearch(__key: *const ::std::os::raw::c_void,
                   __base: *const ::std::os::raw::c_void,
                   __nmemb: usize,
                   __size: usize,
                   __compar: __compar_fn_t)
                   -> *mut ::std::os::raw::c_void;
}
extern "C" {
    pub fn qsort(__base: *mut ::std::os::raw::c_void,
                 __nmemb: usize,
                 __size: usize,
                 __compar: __compar_fn_t);
}
extern "C" {
    pub fn abs(__x: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn labs(__x: ::std::os::raw::c_long) -> ::std::os::raw::c_long;
}
extern "C" {
    pub fn llabs(__x: ::std::os::raw::c_longlong)
                 -> ::std::os::raw::c_longlong;
}
extern "C" {
    pub fn div(__numer: ::std::os::raw::c_int,
               __denom: ::std::os::raw::c_int)
               -> div_t;
}
extern "C" {
    pub fn ldiv(__numer: ::std::os::raw::c_long,
                __denom: ::std::os::raw::c_long)
                -> ldiv_t;
}
extern "C" {
    pub fn lldiv(__numer: ::std::os::raw::c_longlong,
                 __denom: ::std::os::raw::c_longlong)
                 -> lldiv_t;
}
extern "C" {
    pub fn ecvt(__value: f64,
                __ndigit: ::std::os::raw::c_int,
                __decpt: *mut ::std::os::raw::c_int,
                __sign: *mut ::std::os::raw::c_int)
                -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn fcvt(__value: f64,
                __ndigit: ::std::os::raw::c_int,
                __decpt: *mut ::std::os::raw::c_int,
                __sign: *mut ::std::os::raw::c_int)
                -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn gcvt(__value: f64,
                __ndigit: ::std::os::raw::c_int,
                __buf: *mut ::std::os::raw::c_char)
                -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qecvt(__value: f64,
                 __ndigit: ::std::os::raw::c_int,
                 __decpt: *mut ::std::os::raw::c_int,
                 __sign: *mut ::std::os::raw::c_int)
                 -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qfcvt(__value: f64,
                 __ndigit: ::std::os::raw::c_int,
                 __decpt: *mut ::std::os::raw::c_int,
                 __sign: *mut ::std::os::raw::c_int)
                 -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn qgcvt(__value: f64,
                 __ndigit: ::std::os::raw::c_int,
                 __buf: *mut ::std::os::raw::c_char)
                 -> *mut ::std::os::raw::c_char;
}
extern "C" {
    pub fn ecvt_r(__value: f64,
                  __ndigit: ::std::os::raw::c_int,
                  __decpt: *mut ::std::os::raw::c_int,
                  __sign: *mut ::std::os::raw::c_int,
                  __buf: *mut ::std::os::raw::c_char,
                  __len: usize)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn fcvt_r(__value: f64,
                  __ndigit: ::std::os::raw::c_int,
                  __decpt: *mut ::std::os::raw::c_int,
                  __sign: *mut ::std::os::raw::c_int,
                  __buf: *mut ::std::os::raw::c_char,
                  __len: usize)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn qecvt_r(__value: f64,
                   __ndigit: ::std::os::raw::c_int,
                   __decpt: *mut ::std::os::raw::c_int,
                   __sign: *mut ::std::os::raw::c_int,
                   __buf: *mut ::std::os::raw::c_char,
                   __len: usize)
                   -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn qfcvt_r(__value: f64,
                   __ndigit: ::std::os::raw::c_int,
                   __decpt: *mut ::std::os::raw::c_int,
                   __sign: *mut ::std::os::raw::c_int,
                   __buf: *mut ::std::os::raw::c_char,
                   __len: usize)
                   -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mblen(__s: *const ::std::os::raw::c_char,
                 __n: usize)
                 -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbtowc(__pwc: *mut wchar_t,
                  __s: *const ::std::os::raw::c_char,
                  __n: usize)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn wctomb(__s: *mut ::std::os::raw::c_char,
                  __wchar: wchar_t)
                  -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn mbstowcs(__pwcs: *mut wchar_t,
                    __s: *const ::std::os::raw::c_char,
                    __n: usize)
                    -> usize;
}
extern "C" {
    pub fn wcstombs(__s: *mut ::std::os::raw::c_char,
                    __pwcs: *const wchar_t,
                    __n: usize)
                    -> usize;
}
extern "C" {
    pub fn rpmatch(__response: *const ::std::os::raw::c_char)
                   -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getsubopt(__optionp: *mut *mut ::std::os::raw::c_char,
                     __tokens: *const *const ::std::os::raw::c_char,
                     __valuep: *mut *mut ::std::os::raw::c_char)
                     -> ::std::os::raw::c_int;
}
extern "C" {
    pub fn getloadavg(__loadavg: *mut f64,
                      __nelem: ::std::os::raw::c_int)
                      -> ::std::os::raw::c_int;
}
pub type int_least8_t = ::std::os::raw::c_char;
pub type int_least16_t = ::std::os::raw::c_short;
pub type int_least32_t = ::std::os::raw::c_int;
pub type int_least64_t = ::std::os::raw::c_long;
pub type uint_least8_t = ::std::os::raw::c_uchar;
pub type uint_least16_t = ::std::os::raw::c_ushort;
pub type uint_least32_t = ::std::os::raw::c_uint;
pub type uint_least64_t = ::std::os::raw::c_ulong;
pub type int_fast8_t = ::std::os::raw::c_char;
pub type int_fast16_t = ::std::os::raw::c_long;
pub type int_fast32_t = ::std::os::raw::c_long;
pub type int_fast64_t = ::std::os::raw::c_long;
pub type uint_fast8_t = ::std::os::raw::c_uchar;
pub type uint_fast16_t = ::std::os::raw::c_ulong;
pub type uint_fast32_t = ::std::os::raw::c_ulong;
pub type uint_fast64_t = ::std::os::raw::c_ulong;
pub type intmax_t = ::std::os::raw::c_long;
pub type uintmax_t = ::std::os::raw::c_ulong;
pub type cuuint32_t = u32;
pub type cuuint64_t = u64;
pub type CUdeviceptr = ::std::os::raw::c_ulonglong;
pub type CUdevice = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUctx_st {
    pub _address: u8,
}
impl Clone for CUctx_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUcontext = *mut CUctx_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUmod_st {
    pub _address: u8,
}
impl Clone for CUmod_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUmodule = *mut CUmod_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUfunc_st {
    pub _address: u8,
}
impl Clone for CUfunc_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUfunction = *mut CUfunc_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUarray_st {
    pub _address: u8,
}
impl Clone for CUarray_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUarray = *mut CUarray_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUmipmappedArray_st {
    pub _address: u8,
}
impl Clone for CUmipmappedArray_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUmipmappedArray = *mut CUmipmappedArray_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUtexref_st {
    pub _address: u8,
}
impl Clone for CUtexref_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUtexref = *mut CUtexref_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUsurfref_st {
    pub _address: u8,
}
impl Clone for CUsurfref_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUsurfref = *mut CUsurfref_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUevent_st {
    pub _address: u8,
}
impl Clone for CUevent_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUevent = *mut CUevent_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUstream_st {
    pub _address: u8,
}
impl Clone for CUstream_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUstream = *mut CUstream_st;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUgraphicsResource_st {
    pub _address: u8,
}
impl Clone for CUgraphicsResource_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUgraphicsResource = *mut CUgraphicsResource_st;
pub type CUtexObject = ::std::os::raw::c_ulonglong;
pub type CUsurfObject = ::std::os::raw::c_ulonglong;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUuuid_st {
    pub bytes: [::std::os::raw::c_char; 16usize],
}
#[test]
fn bindgen_test_layout_CUuuid_st() {
    assert_eq!(::std::mem::size_of::<CUuuid_st>(), 16usize);
    assert_eq!(::std::mem::align_of::<CUuuid_st>(), 1usize);
}
impl Clone for CUuuid_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUuuid = CUuuid_st;
/**
 * CUDA IPC event handle
 */
#[repr(C)]
pub struct CUipcEventHandle_st {
    pub reserved: [::std::os::raw::c_char; 64usize],
}
#[test]
fn bindgen_test_layout_CUipcEventHandle_st() {
    assert_eq!(::std::mem::size_of::<CUipcEventHandle_st>(), 64usize);
    assert_eq!(::std::mem::align_of::<CUipcEventHandle_st>(), 1usize);
}
pub type CUipcEventHandle = CUipcEventHandle_st;
/**
 * CUDA IPC mem handle
 */
#[repr(C)]
pub struct CUipcMemHandle_st {
    pub reserved: [::std::os::raw::c_char; 64usize],
}
#[test]
fn bindgen_test_layout_CUipcMemHandle_st() {
    assert_eq!(::std::mem::size_of::<CUipcMemHandle_st>(), 64usize);
    assert_eq!(::std::mem::align_of::<CUipcMemHandle_st>(), 1usize);
}
pub type CUipcMemHandle = CUipcMemHandle_st;
#[repr(u32)]
/**
 * CUDA Ipc Mem Flags
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUipcMem_flags_enum {
    CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS = 1,
}
pub type CUipcMem_flags = CUipcMem_flags_enum;
#[repr(u32)]
/**
 * CUDA Mem Attach Flags
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUmemAttach_flags_enum {
    CU_MEM_ATTACH_GLOBAL = 1,
    CU_MEM_ATTACH_HOST = 2,
    CU_MEM_ATTACH_SINGLE = 4,
}
pub type CUmemAttach_flags = CUmemAttach_flags_enum;
pub const CUctx_flags_enum_CU_CTX_BLOCKING_SYNC: CUctx_flags_enum =
    CUctx_flags_enum::CU_CTX_SCHED_BLOCKING_SYNC;
#[repr(u32)]
/**
 * Context creation flags
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUctx_flags_enum {
    CU_CTX_SCHED_AUTO = 0,
    CU_CTX_SCHED_SPIN = 1,
    CU_CTX_SCHED_YIELD = 2,
    CU_CTX_SCHED_BLOCKING_SYNC = 4,
    CU_CTX_SCHED_MASK = 7,
    CU_CTX_MAP_HOST = 8,
    CU_CTX_LMEM_RESIZE_TO_MAX = 16,
    CU_CTX_FLAGS_MASK = 31,
}
pub type CUctx_flags = CUctx_flags_enum;
#[repr(u32)]
/**
 * Stream creation flags
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUstream_flags_enum {
    CU_STREAM_DEFAULT = 0,
    CU_STREAM_NON_BLOCKING = 1,
}
pub type CUstream_flags = CUstream_flags_enum;
#[repr(u32)]
/**
 * Event creation flags
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUevent_flags_enum {
    CU_EVENT_DEFAULT = 0,
    CU_EVENT_BLOCKING_SYNC = 1,
    CU_EVENT_DISABLE_TIMING = 2,
    CU_EVENT_INTERPROCESS = 4,
}
pub type CUevent_flags = CUevent_flags_enum;
#[repr(u32)]
/**
 * Flags for ::cuStreamWaitValue32
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUstreamWaitValue_flags_enum {
    CU_STREAM_WAIT_VALUE_GEQ = 0,
    CU_STREAM_WAIT_VALUE_EQ = 1,
    CU_STREAM_WAIT_VALUE_AND = 2,
    CU_STREAM_WAIT_VALUE_FLUSH = 1073741824,
}
pub type CUstreamWaitValue_flags = CUstreamWaitValue_flags_enum;
#[repr(u32)]
/**
 * Flags for ::cuStreamWriteValue32
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUstreamWriteValue_flags_enum {
    CU_STREAM_WRITE_VALUE_DEFAULT = 0,
    CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER = 1,
}
pub type CUstreamWriteValue_flags = CUstreamWriteValue_flags_enum;
#[repr(u32)]
/**
 * Operations for ::cuStreamBatchMemOp
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUstreamBatchMemOpType_enum {
    CU_STREAM_MEM_OP_WAIT_VALUE_32 = 1,
    CU_STREAM_MEM_OP_WRITE_VALUE_32 = 2,
    CU_STREAM_MEM_OP_FLUSH_REMOTE_WRITES = 3,
}
pub type CUstreamBatchMemOpType = CUstreamBatchMemOpType_enum;
/**
 * Per-operation parameters for ::cuStreamBatchMemOp
 */
#[repr(C)]
#[derive(Copy)]
pub union CUstreamBatchMemOpParams_union {
    pub operation: CUstreamBatchMemOpType,
    pub waitValue: CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st,
    pub writeValue: CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st,
    pub flushRemoteWrites: CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st,
    pub pad: [cuuint64_t; 6usize],
}
#[repr(C)]
#[derive(Copy)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub address: CUdeviceptr,
    pub __bindgen_anon_1: CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1,
    pub flags: ::std::os::raw::c_uint,
    /**< For driver internal use. Initial value is unimportant. */
    pub alias: CUdeviceptr,
}
#[repr(C)]
#[derive(Copy)]
pub union CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1 {
    pub value: cuuint32_t,
    pub pad: cuuint64_t,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
    () {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1>()
               , 8usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1>()
               , 8usize);
}
impl Clone for
 CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st__bindgen_ty_1
 {
    fn clone(&self) -> Self { *self }
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st
    () {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>()
               , 40usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st>()
               , 8usize);
}
impl Clone for CUstreamBatchMemOpParams_union_CUstreamMemOpWaitValueParams_st {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Copy)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub address: CUdeviceptr,
    pub __bindgen_anon_1: CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1,
    pub flags: ::std::os::raw::c_uint,
    /**< For driver internal use. Initial value is unimportant. */
    pub alias: CUdeviceptr,
}
#[repr(C)]
#[derive(Copy)]
pub union CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1 {
    pub value: cuuint32_t,
    pub pad: cuuint64_t,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
    () {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1>()
               , 8usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1>()
               , 8usize);
}
impl Clone for
 CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st__bindgen_ty_1
 {
    fn clone(&self) -> Self { *self }
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st
    () {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>()
               , 40usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st>()
               , 8usize);
}
impl Clone for CUstreamBatchMemOpParams_union_CUstreamMemOpWriteValueParams_st {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st {
    pub operation: CUstreamBatchMemOpType,
    pub flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st
    () {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st>()
               , 8usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st>()
               , 4usize);
}
impl Clone for
 CUstreamBatchMemOpParams_union_CUstreamMemOpFlushRemoteWritesParams_st {
    fn clone(&self) -> Self { *self }
}
#[test]
fn bindgen_test_layout_CUstreamBatchMemOpParams_union() {
    assert_eq!(::std::mem::size_of::<CUstreamBatchMemOpParams_union>(),
               48usize);
    assert_eq!(::std::mem::align_of::<CUstreamBatchMemOpParams_union>(),
               8usize);
}
impl Clone for CUstreamBatchMemOpParams_union {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUstreamBatchMemOpParams = CUstreamBatchMemOpParams_union;
#[repr(u32)]
/**
 * Occupancy calculator flag
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUoccupancy_flags_enum {
    CU_OCCUPANCY_DEFAULT = 0,
    CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE = 1,
}
pub type CUoccupancy_flags = CUoccupancy_flags_enum;
#[repr(u32)]
/**
 * Array formats
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUarray_format_enum {
    CU_AD_FORMAT_UNSIGNED_INT8 = 1,
    CU_AD_FORMAT_UNSIGNED_INT16 = 2,
    CU_AD_FORMAT_UNSIGNED_INT32 = 3,
    CU_AD_FORMAT_SIGNED_INT8 = 8,
    CU_AD_FORMAT_SIGNED_INT16 = 9,
    CU_AD_FORMAT_SIGNED_INT32 = 10,
    CU_AD_FORMAT_HALF = 16,
    CU_AD_FORMAT_FLOAT = 32,
}
pub type CUarray_format = CUarray_format_enum;
#[repr(u32)]
/**
 * Texture reference addressing modes
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUaddress_mode_enum {
    CU_TR_ADDRESS_MODE_WRAP = 0,
    CU_TR_ADDRESS_MODE_CLAMP = 1,
    CU_TR_ADDRESS_MODE_MIRROR = 2,
    CU_TR_ADDRESS_MODE_BORDER = 3,
}
pub type CUaddress_mode = CUaddress_mode_enum;
#[repr(u32)]
/**
 * Texture reference filtering modes
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUfilter_mode_enum {
    CU_TR_FILTER_MODE_POINT = 0,
    CU_TR_FILTER_MODE_LINEAR = 1,
}
pub type CUfilter_mode = CUfilter_mode_enum;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK:
          CUdevice_attribute_enum =
    CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK:
          CUdevice_attribute_enum =
    CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_WIDTH:
          CUdevice_attribute_enum =
    CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_HEIGHT:
          CUdevice_attribute_enum =
    CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT;
pub const CUdevice_attribute_enum_CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES:
          CUdevice_attribute_enum =
    CUdevice_attribute_enum::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS;
#[repr(u32)]
/**
 * Device properties
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUdevice_attribute_enum {
    CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK = 1,
    CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X = 2,
    CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y = 3,
    CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z = 4,
    CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X = 5,
    CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y = 6,
    CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z = 7,
    CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK = 8,
    CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY = 9,
    CU_DEVICE_ATTRIBUTE_WARP_SIZE = 10,
    CU_DEVICE_ATTRIBUTE_MAX_PITCH = 11,
    CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK = 12,
    CU_DEVICE_ATTRIBUTE_CLOCK_RATE = 13,
    CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT = 14,
    CU_DEVICE_ATTRIBUTE_GPU_OVERLAP = 15,
    CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT = 16,
    CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT = 17,
    CU_DEVICE_ATTRIBUTE_INTEGRATED = 18,
    CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY = 19,
    CU_DEVICE_ATTRIBUTE_COMPUTE_MODE = 20,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH = 21,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH = 22,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT = 23,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH = 24,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT = 25,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH = 26,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH = 27,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT = 28,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS = 29,
    CU_DEVICE_ATTRIBUTE_SURFACE_ALIGNMENT = 30,
    CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS = 31,
    CU_DEVICE_ATTRIBUTE_ECC_ENABLED = 32,
    CU_DEVICE_ATTRIBUTE_PCI_BUS_ID = 33,
    CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID = 34,
    CU_DEVICE_ATTRIBUTE_TCC_DRIVER = 35,
    CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE = 36,
    CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH = 37,
    CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE = 38,
    CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR = 39,
    CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT = 40,
    CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING = 41,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH = 42,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS = 43,
    CU_DEVICE_ATTRIBUTE_CAN_TEX2D_GATHER = 44,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_WIDTH = 45,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_HEIGHT = 46,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE = 47,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE = 48,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE = 49,
    CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID = 50,
    CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT = 51,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH = 52,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH = 53,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS = 54,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH = 55,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH = 56,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT = 57,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH = 58,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT = 59,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH = 60,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH = 61,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS = 62,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH = 63,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT = 64,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS = 65,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH = 66,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH = 67,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS = 68,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH = 69,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH = 70,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT = 71,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH = 72,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH = 73,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT = 74,
    CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR = 75,
    CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR = 76,
    CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH = 77,
    CU_DEVICE_ATTRIBUTE_STREAM_PRIORITIES_SUPPORTED = 78,
    CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED = 79,
    CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED = 80,
    CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR = 81,
    CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR = 82,
    CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY = 83,
    CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD = 84,
    CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID = 85,
    CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED = 86,
    CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO = 87,
    CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS = 88,
    CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS = 89,
    CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED = 90,
    CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM = 91,
    CU_DEVICE_ATTRIBUTE_MAX = 92,
}
pub type CUdevice_attribute = CUdevice_attribute_enum;
/**
 * Legacy device properties
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUdevprop_st {
    /**< Maximum number of threads per block */
    pub maxThreadsPerBlock: ::std::os::raw::c_int,
    /**< Maximum size of each dimension of a block */
    pub maxThreadsDim: [::std::os::raw::c_int; 3usize],
    /**< Maximum size of each dimension of a grid */
    pub maxGridSize: [::std::os::raw::c_int; 3usize],
    /**< Shared memory available per block in bytes */
    pub sharedMemPerBlock: ::std::os::raw::c_int,
    /**< Constant memory available on device in bytes */
    pub totalConstantMemory: ::std::os::raw::c_int,
    /**< Warp size in threads */
    pub SIMDWidth: ::std::os::raw::c_int,
    /**< Maximum pitch in bytes allowed by memory copies */
    pub memPitch: ::std::os::raw::c_int,
    /**< 32-bit registers available per block */
    pub regsPerBlock: ::std::os::raw::c_int,
    /**< Clock frequency in kilohertz */
    pub clockRate: ::std::os::raw::c_int,
    /**< Alignment requirement for textures */
    pub textureAlign: ::std::os::raw::c_int,
}
#[test]
fn bindgen_test_layout_CUdevprop_st() {
    assert_eq!(::std::mem::size_of::<CUdevprop_st>(), 56usize);
    assert_eq!(::std::mem::align_of::<CUdevprop_st>(), 4usize);
}
impl Clone for CUdevprop_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUdevprop = CUdevprop_st;
#[repr(u32)]
/**
 * Pointer information
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUpointer_attribute_enum {
    CU_POINTER_ATTRIBUTE_CONTEXT = 1,
    CU_POINTER_ATTRIBUTE_MEMORY_TYPE = 2,
    CU_POINTER_ATTRIBUTE_DEVICE_POINTER = 3,
    CU_POINTER_ATTRIBUTE_HOST_POINTER = 4,
    CU_POINTER_ATTRIBUTE_P2P_TOKENS = 5,
    CU_POINTER_ATTRIBUTE_SYNC_MEMOPS = 6,
    CU_POINTER_ATTRIBUTE_BUFFER_ID = 7,
    CU_POINTER_ATTRIBUTE_IS_MANAGED = 8,
}
pub type CUpointer_attribute = CUpointer_attribute_enum;
#[repr(u32)]
/**
 * Function properties
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUfunction_attribute_enum {
    CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK = 0,
    CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES = 1,
    CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES = 2,
    CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES = 3,
    CU_FUNC_ATTRIBUTE_NUM_REGS = 4,
    CU_FUNC_ATTRIBUTE_PTX_VERSION = 5,
    CU_FUNC_ATTRIBUTE_BINARY_VERSION = 6,
    CU_FUNC_ATTRIBUTE_CACHE_MODE_CA = 7,
    CU_FUNC_ATTRIBUTE_MAX = 8,
}
pub type CUfunction_attribute = CUfunction_attribute_enum;
#[repr(u32)]
/**
 * Function cache configurations
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUfunc_cache_enum {
    CU_FUNC_CACHE_PREFER_NONE = 0,
    CU_FUNC_CACHE_PREFER_SHARED = 1,
    CU_FUNC_CACHE_PREFER_L1 = 2,
    CU_FUNC_CACHE_PREFER_EQUAL = 3,
}
pub type CUfunc_cache = CUfunc_cache_enum;
#[repr(u32)]
/**
 * Shared memory configurations
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUsharedconfig_enum {
    CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE = 0,
    CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE = 1,
    CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE = 2,
}
pub type CUsharedconfig = CUsharedconfig_enum;
#[repr(u32)]
/**
 * Memory types
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUmemorytype_enum {
    CU_MEMORYTYPE_HOST = 1,
    CU_MEMORYTYPE_DEVICE = 2,
    CU_MEMORYTYPE_ARRAY = 3,
    CU_MEMORYTYPE_UNIFIED = 4,
}
pub type CUmemorytype = CUmemorytype_enum;
#[repr(u32)]
/**
 * Compute Modes
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUcomputemode_enum {
    CU_COMPUTEMODE_DEFAULT = 0,
    CU_COMPUTEMODE_PROHIBITED = 2,
    CU_COMPUTEMODE_EXCLUSIVE_PROCESS = 3,
}
pub type CUcomputemode = CUcomputemode_enum;
#[repr(u32)]
/**
 * Memory advise values
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUmem_advise_enum {
    CU_MEM_ADVISE_SET_READ_MOSTLY = 1,
    CU_MEM_ADVISE_UNSET_READ_MOSTLY = 2,
    CU_MEM_ADVISE_SET_PREFERRED_LOCATION = 3,
    CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION = 4,
    CU_MEM_ADVISE_SET_ACCESSED_BY = 5,
    CU_MEM_ADVISE_UNSET_ACCESSED_BY = 6,
}
pub type CUmem_advise = CUmem_advise_enum;
#[repr(u32)]
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUmem_range_attribute_enum {
    CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY = 1,
    CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION = 2,
    CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY = 3,
    CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION = 4,
}
pub type CUmem_range_attribute = CUmem_range_attribute_enum;
#[repr(u32)]
/**
 * Online compiler and linker options
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUjit_option_enum {
    CU_JIT_MAX_REGISTERS = 0,
    CU_JIT_THREADS_PER_BLOCK = 1,
    CU_JIT_WALL_TIME = 2,
    CU_JIT_INFO_LOG_BUFFER = 3,
    CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES = 4,
    CU_JIT_ERROR_LOG_BUFFER = 5,
    CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES = 6,
    CU_JIT_OPTIMIZATION_LEVEL = 7,
    CU_JIT_TARGET_FROM_CUCONTEXT = 8,
    CU_JIT_TARGET = 9,
    CU_JIT_FALLBACK_STRATEGY = 10,
    CU_JIT_GENERATE_DEBUG_INFO = 11,
    CU_JIT_LOG_VERBOSE = 12,
    CU_JIT_GENERATE_LINE_INFO = 13,
    CU_JIT_CACHE_MODE = 14,
    CU_JIT_NEW_SM3X_OPT = 15,
    CU_JIT_FAST_COMPILE = 16,
    CU_JIT_NUM_OPTIONS = 17,
}
pub type CUjit_option = CUjit_option_enum;
#[repr(u32)]
/**
 * Online compilation targets
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUjit_target_enum {
    CU_TARGET_COMPUTE_10 = 10,
    CU_TARGET_COMPUTE_11 = 11,
    CU_TARGET_COMPUTE_12 = 12,
    CU_TARGET_COMPUTE_13 = 13,
    CU_TARGET_COMPUTE_20 = 20,
    CU_TARGET_COMPUTE_21 = 21,
    CU_TARGET_COMPUTE_30 = 30,
    CU_TARGET_COMPUTE_32 = 32,
    CU_TARGET_COMPUTE_35 = 35,
    CU_TARGET_COMPUTE_37 = 37,
    CU_TARGET_COMPUTE_50 = 50,
    CU_TARGET_COMPUTE_52 = 52,
    CU_TARGET_COMPUTE_53 = 53,
    CU_TARGET_COMPUTE_60 = 60,
    CU_TARGET_COMPUTE_61 = 61,
    CU_TARGET_COMPUTE_62 = 62,
}
pub type CUjit_target = CUjit_target_enum;
#[repr(u32)]
/**
 * Cubin matching fallback strategies
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUjit_fallback_enum {
    CU_PREFER_PTX = 0,
    CU_PREFER_BINARY = 1,
}
pub type CUjit_fallback = CUjit_fallback_enum;
#[repr(u32)]
/**
 * Caching modes for dlcm 
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUjit_cacheMode_enum {
    CU_JIT_CACHE_OPTION_NONE = 0,
    CU_JIT_CACHE_OPTION_CG = 1,
    CU_JIT_CACHE_OPTION_CA = 2,
}
pub type CUjit_cacheMode = CUjit_cacheMode_enum;
#[repr(u32)]
/**
 * Device code formats
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUjitInputType_enum {
    CU_JIT_INPUT_CUBIN = 0,
    CU_JIT_INPUT_PTX = 1,
    CU_JIT_INPUT_FATBINARY = 2,
    CU_JIT_INPUT_OBJECT = 3,
    CU_JIT_INPUT_LIBRARY = 4,
    CU_JIT_NUM_INPUT_TYPES = 5,
}
pub type CUjitInputType = CUjitInputType_enum;
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUlinkState_st {
    pub _address: u8,
}
impl Clone for CUlinkState_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUlinkState = *mut CUlinkState_st;
#[repr(u32)]
/**
 * Flags to register a graphics resource
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUgraphicsRegisterFlags_enum {
    CU_GRAPHICS_REGISTER_FLAGS_NONE = 0,
    CU_GRAPHICS_REGISTER_FLAGS_READ_ONLY = 1,
    CU_GRAPHICS_REGISTER_FLAGS_WRITE_DISCARD = 2,
    CU_GRAPHICS_REGISTER_FLAGS_SURFACE_LDST = 4,
    CU_GRAPHICS_REGISTER_FLAGS_TEXTURE_GATHER = 8,
}
pub type CUgraphicsRegisterFlags = CUgraphicsRegisterFlags_enum;
#[repr(u32)]
/**
 * Flags for mapping and unmapping interop resources
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUgraphicsMapResourceFlags_enum {
    CU_GRAPHICS_MAP_RESOURCE_FLAGS_NONE = 0,
    CU_GRAPHICS_MAP_RESOURCE_FLAGS_READ_ONLY = 1,
    CU_GRAPHICS_MAP_RESOURCE_FLAGS_WRITE_DISCARD = 2,
}
pub type CUgraphicsMapResourceFlags = CUgraphicsMapResourceFlags_enum;
#[repr(u32)]
/**
 * Array indices for cube faces
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUarray_cubemap_face_enum {
    CU_CUBEMAP_FACE_POSITIVE_X = 0,
    CU_CUBEMAP_FACE_NEGATIVE_X = 1,
    CU_CUBEMAP_FACE_POSITIVE_Y = 2,
    CU_CUBEMAP_FACE_NEGATIVE_Y = 3,
    CU_CUBEMAP_FACE_POSITIVE_Z = 4,
    CU_CUBEMAP_FACE_NEGATIVE_Z = 5,
}
pub type CUarray_cubemap_face = CUarray_cubemap_face_enum;
#[repr(u32)]
/**
 * Limits
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUlimit_enum {
    CU_LIMIT_STACK_SIZE = 0,
    CU_LIMIT_PRINTF_FIFO_SIZE = 1,
    CU_LIMIT_MALLOC_HEAP_SIZE = 2,
    CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH = 3,
    CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT = 4,
    CU_LIMIT_MAX = 5,
}
pub type CUlimit = CUlimit_enum;
#[repr(u32)]
/**
 * Resource types
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUresourcetype_enum {
    CU_RESOURCE_TYPE_ARRAY = 0,
    CU_RESOURCE_TYPE_MIPMAPPED_ARRAY = 1,
    CU_RESOURCE_TYPE_LINEAR = 2,
    CU_RESOURCE_TYPE_PITCH2D = 3,
}
pub type CUresourcetype = CUresourcetype_enum;
#[repr(u32)]
/**
 * Error codes
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum cudaError_enum {
    CUDA_SUCCESS = 0,
    CUDA_ERROR_INVALID_VALUE = 1,
    CUDA_ERROR_OUT_OF_MEMORY = 2,
    CUDA_ERROR_NOT_INITIALIZED = 3,
    CUDA_ERROR_DEINITIALIZED = 4,
    CUDA_ERROR_PROFILER_DISABLED = 5,
    CUDA_ERROR_PROFILER_NOT_INITIALIZED = 6,
    CUDA_ERROR_PROFILER_ALREADY_STARTED = 7,
    CUDA_ERROR_PROFILER_ALREADY_STOPPED = 8,
    CUDA_ERROR_NO_DEVICE = 100,
    CUDA_ERROR_INVALID_DEVICE = 101,
    CUDA_ERROR_INVALID_IMAGE = 200,
    CUDA_ERROR_INVALID_CONTEXT = 201,
    CUDA_ERROR_CONTEXT_ALREADY_CURRENT = 202,
    CUDA_ERROR_MAP_FAILED = 205,
    CUDA_ERROR_UNMAP_FAILED = 206,
    CUDA_ERROR_ARRAY_IS_MAPPED = 207,
    CUDA_ERROR_ALREADY_MAPPED = 208,
    CUDA_ERROR_NO_BINARY_FOR_GPU = 209,
    CUDA_ERROR_ALREADY_ACQUIRED = 210,
    CUDA_ERROR_NOT_MAPPED = 211,
    CUDA_ERROR_NOT_MAPPED_AS_ARRAY = 212,
    CUDA_ERROR_NOT_MAPPED_AS_POINTER = 213,
    CUDA_ERROR_ECC_UNCORRECTABLE = 214,
    CUDA_ERROR_UNSUPPORTED_LIMIT = 215,
    CUDA_ERROR_CONTEXT_ALREADY_IN_USE = 216,
    CUDA_ERROR_PEER_ACCESS_UNSUPPORTED = 217,
    CUDA_ERROR_INVALID_PTX = 218,
    CUDA_ERROR_INVALID_GRAPHICS_CONTEXT = 219,
    CUDA_ERROR_NVLINK_UNCORRECTABLE = 220,
    CUDA_ERROR_INVALID_SOURCE = 300,
    CUDA_ERROR_FILE_NOT_FOUND = 301,
    CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND = 302,
    CUDA_ERROR_SHARED_OBJECT_INIT_FAILED = 303,
    CUDA_ERROR_OPERATING_SYSTEM = 304,
    CUDA_ERROR_INVALID_HANDLE = 400,
    CUDA_ERROR_NOT_FOUND = 500,
    CUDA_ERROR_NOT_READY = 600,
    CUDA_ERROR_ILLEGAL_ADDRESS = 700,
    CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES = 701,
    CUDA_ERROR_LAUNCH_TIMEOUT = 702,
    CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING = 703,
    CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED = 704,
    CUDA_ERROR_PEER_ACCESS_NOT_ENABLED = 705,
    CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE = 708,
    CUDA_ERROR_CONTEXT_IS_DESTROYED = 709,
    CUDA_ERROR_ASSERT = 710,
    CUDA_ERROR_TOO_MANY_PEERS = 711,
    CUDA_ERROR_HOST_MEMORY_ALREADY_REGISTERED = 712,
    CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED = 713,
    CUDA_ERROR_HARDWARE_STACK_ERROR = 714,
    CUDA_ERROR_ILLEGAL_INSTRUCTION = 715,
    CUDA_ERROR_MISALIGNED_ADDRESS = 716,
    CUDA_ERROR_INVALID_ADDRESS_SPACE = 717,
    CUDA_ERROR_INVALID_PC = 718,
    CUDA_ERROR_LAUNCH_FAILED = 719,
    CUDA_ERROR_NOT_PERMITTED = 800,
    CUDA_ERROR_NOT_SUPPORTED = 801,
    CUDA_ERROR_UNKNOWN = 999,
}
pub type CUresult = cudaError_enum;
#[repr(u32)]
/**
 * P2P Attributes
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUdevice_P2PAttribute_enum {
    CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK = 1,
    CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED = 2,
    CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED = 3,
}
pub type CUdevice_P2PAttribute = CUdevice_P2PAttribute_enum;
/**
 * CUDA stream callback
 * \param hStream The stream the callback was added to, as passed to ::cuStreamAddCallback.  May be NULL.
 * \param status ::CUDA_SUCCESS or any persistent error on the stream.
 * \param userData User parameter provided at registration.
 */
pub type CUstreamCallback =
    ::std::option::Option<unsafe extern "C" fn(hStream: CUstream,
                                               status: CUresult,
                                               userData:
                                                   *mut ::std::os::raw::c_void)>;
/**
 * Block size to per-block dynamic shared memory mapping for a certain
 * kernel \param blockSize Block size of the kernel.
 *
 * \return The dynamic shared memory needed by a block.
 */
pub type CUoccupancyB2DSize =
    ::std::option::Option<unsafe extern "C" fn(blockSize:
                                                   ::std::os::raw::c_int)
                              -> ::std::os::raw::c_ulong>;
/**
 * 2D memory copy parameters
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_MEMCPY2D_st {
    /**< Source X in bytes */
    pub srcXInBytes: usize,
    /**< Source Y */
    pub srcY: usize,
    /**< Source memory type (host, device, array) */
    pub srcMemoryType: CUmemorytype,
    /**< Source host pointer */
    pub srcHost: *const ::std::os::raw::c_void,
    /**< Source device pointer */
    pub srcDevice: CUdeviceptr,
    /**< Source array reference */
    pub srcArray: CUarray,
    /**< Source pitch (ignored when src is array) */
    pub srcPitch: usize,
    /**< Destination X in bytes */
    pub dstXInBytes: usize,
    /**< Destination Y */
    pub dstY: usize,
    /**< Destination memory type (host, device, array) */
    pub dstMemoryType: CUmemorytype,
    /**< Destination host pointer */
    pub dstHost: *mut ::std::os::raw::c_void,
    /**< Destination device pointer */
    pub dstDevice: CUdeviceptr,
    /**< Destination array reference */
    pub dstArray: CUarray,
    /**< Destination pitch (ignored when dst is array) */
    pub dstPitch: usize,
    /**< Width of 2D memory copy in bytes */
    pub WidthInBytes: usize,
    /**< Height of 2D memory copy */
    pub Height: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY2D_st() {
    assert_eq!(::std::mem::size_of::<CUDA_MEMCPY2D_st>(), 128usize);
    assert_eq!(::std::mem::align_of::<CUDA_MEMCPY2D_st>(), 8usize);
}
impl Clone for CUDA_MEMCPY2D_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_MEMCPY2D = CUDA_MEMCPY2D_st;
/**
 * 3D memory copy parameters
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_MEMCPY3D_st {
    /**< Source X in bytes */
    pub srcXInBytes: usize,
    /**< Source Y */
    pub srcY: usize,
    /**< Source Z */
    pub srcZ: usize,
    /**< Source LOD */
    pub srcLOD: usize,
    /**< Source memory type (host, device, array) */
    pub srcMemoryType: CUmemorytype,
    /**< Source host pointer */
    pub srcHost: *const ::std::os::raw::c_void,
    /**< Source device pointer */
    pub srcDevice: CUdeviceptr,
    /**< Source array reference */
    pub srcArray: CUarray,
    /**< Must be NULL */
    pub reserved0: *mut ::std::os::raw::c_void,
    /**< Source pitch (ignored when src is array) */
    pub srcPitch: usize,
    /**< Source height (ignored when src is array; may be 0 if Depth==1) */
    pub srcHeight: usize,
    /**< Destination X in bytes */
    pub dstXInBytes: usize,
    /**< Destination Y */
    pub dstY: usize,
    /**< Destination Z */
    pub dstZ: usize,
    /**< Destination LOD */
    pub dstLOD: usize,
    /**< Destination memory type (host, device, array) */
    pub dstMemoryType: CUmemorytype,
    /**< Destination host pointer */
    pub dstHost: *mut ::std::os::raw::c_void,
    /**< Destination device pointer */
    pub dstDevice: CUdeviceptr,
    /**< Destination array reference */
    pub dstArray: CUarray,
    /**< Must be NULL */
    pub reserved1: *mut ::std::os::raw::c_void,
    /**< Destination pitch (ignored when dst is array) */
    pub dstPitch: usize,
    /**< Destination height (ignored when dst is array; may be 0 if Depth==1) */
    pub dstHeight: usize,
    /**< Width of 3D memory copy in bytes */
    pub WidthInBytes: usize,
    /**< Height of 3D memory copy */
    pub Height: usize,
    /**< Depth of 3D memory copy */
    pub Depth: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY3D_st() {
    assert_eq!(::std::mem::size_of::<CUDA_MEMCPY3D_st>(), 200usize);
    assert_eq!(::std::mem::align_of::<CUDA_MEMCPY3D_st>(), 8usize);
}
impl Clone for CUDA_MEMCPY3D_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_MEMCPY3D = CUDA_MEMCPY3D_st;
/**
 * 3D memory cross-context copy parameters
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_MEMCPY3D_PEER_st {
    /**< Source X in bytes */
    pub srcXInBytes: usize,
    /**< Source Y */
    pub srcY: usize,
    /**< Source Z */
    pub srcZ: usize,
    /**< Source LOD */
    pub srcLOD: usize,
    /**< Source memory type (host, device, array) */
    pub srcMemoryType: CUmemorytype,
    /**< Source host pointer */
    pub srcHost: *const ::std::os::raw::c_void,
    /**< Source device pointer */
    pub srcDevice: CUdeviceptr,
    /**< Source array reference */
    pub srcArray: CUarray,
    /**< Source context (ignored with srcMemoryType is ::CU_MEMORYTYPE_ARRAY) */
    pub srcContext: CUcontext,
    /**< Source pitch (ignored when src is array) */
    pub srcPitch: usize,
    /**< Source height (ignored when src is array; may be 0 if Depth==1) */
    pub srcHeight: usize,
    /**< Destination X in bytes */
    pub dstXInBytes: usize,
    /**< Destination Y */
    pub dstY: usize,
    /**< Destination Z */
    pub dstZ: usize,
    /**< Destination LOD */
    pub dstLOD: usize,
    /**< Destination memory type (host, device, array) */
    pub dstMemoryType: CUmemorytype,
    /**< Destination host pointer */
    pub dstHost: *mut ::std::os::raw::c_void,
    /**< Destination device pointer */
    pub dstDevice: CUdeviceptr,
    /**< Destination array reference */
    pub dstArray: CUarray,
    /**< Destination context (ignored with dstMemoryType is ::CU_MEMORYTYPE_ARRAY) */
    pub dstContext: CUcontext,
    /**< Destination pitch (ignored when dst is array) */
    pub dstPitch: usize,
    /**< Destination height (ignored when dst is array; may be 0 if Depth==1) */
    pub dstHeight: usize,
    /**< Width of 3D memory copy in bytes */
    pub WidthInBytes: usize,
    /**< Height of 3D memory copy */
    pub Height: usize,
    /**< Depth of 3D memory copy */
    pub Depth: usize,
}
#[test]
fn bindgen_test_layout_CUDA_MEMCPY3D_PEER_st() {
    assert_eq!(::std::mem::size_of::<CUDA_MEMCPY3D_PEER_st>(), 200usize);
    assert_eq!(::std::mem::align_of::<CUDA_MEMCPY3D_PEER_st>(), 8usize);
}
impl Clone for CUDA_MEMCPY3D_PEER_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_MEMCPY3D_PEER = CUDA_MEMCPY3D_PEER_st;
/**
 * Array descriptor
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_ARRAY_DESCRIPTOR_st {
    /**< Width of array */
    pub Width: usize,
    /**< Height of array */
    pub Height: usize,
    /**< Array format */
    pub Format: CUarray_format,
    /**< Channels per array element */
    pub NumChannels: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_ARRAY_DESCRIPTOR_st() {
    assert_eq!(::std::mem::size_of::<CUDA_ARRAY_DESCRIPTOR_st>(), 24usize);
    assert_eq!(::std::mem::align_of::<CUDA_ARRAY_DESCRIPTOR_st>(), 8usize);
}
impl Clone for CUDA_ARRAY_DESCRIPTOR_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_ARRAY_DESCRIPTOR = CUDA_ARRAY_DESCRIPTOR_st;
/**
 * 3D array descriptor
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_ARRAY3D_DESCRIPTOR_st {
    /**< Width of 3D array */
    pub Width: usize,
    /**< Height of 3D array */
    pub Height: usize,
    /**< Depth of 3D array */
    pub Depth: usize,
    /**< Array format */
    pub Format: CUarray_format,
    /**< Channels per array element */
    pub NumChannels: ::std::os::raw::c_uint,
    /**< Flags */
    pub Flags: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_ARRAY3D_DESCRIPTOR_st() {
    assert_eq!(::std::mem::size_of::<CUDA_ARRAY3D_DESCRIPTOR_st>(), 40usize);
    assert_eq!(::std::mem::align_of::<CUDA_ARRAY3D_DESCRIPTOR_st>(), 8usize);
}
impl Clone for CUDA_ARRAY3D_DESCRIPTOR_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_ARRAY3D_DESCRIPTOR = CUDA_ARRAY3D_DESCRIPTOR_st;
/**
 * CUDA Resource descriptor
 */
#[repr(C)]
#[derive(Copy)]
pub struct CUDA_RESOURCE_DESC_st {
    /**< Resource type */
    pub resType: CUresourcetype,
    pub res: CUDA_RESOURCE_DESC_st__bindgen_ty_1,
    /**< Flags (must be zero) */
    pub flags: ::std::os::raw::c_uint,
}
#[repr(C)]
#[derive(Copy)]
pub union CUDA_RESOURCE_DESC_st__bindgen_ty_1 {
    pub array: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1,
    pub mipmap: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2,
    pub linear: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3,
    pub pitch2D: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4,
    pub reserved: CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5,
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
    /**< CUDA array */
    pub hArray: CUarray,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1>()
               , 8usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1>()
               , 8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2 {
    /**< CUDA mipmapped array */
    pub hMipmappedArray: CUmipmappedArray,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2>()
               , 8usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2>()
               , 8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_2 {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3 {
    /**< Device pointer */
    pub devPtr: CUdeviceptr,
    /**< Array format */
    pub format: CUarray_format,
    /**< Channels per array element */
    pub numChannels: ::std::os::raw::c_uint,
    /**< Size in bytes */
    pub sizeInBytes: usize,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>()
               , 24usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3>()
               , 8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_3 {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4 {
    /**< Device pointer */
    pub devPtr: CUdeviceptr,
    /**< Array format */
    pub format: CUarray_format,
    /**< Channels per array element */
    pub numChannels: ::std::os::raw::c_uint,
    /**< Width of the array in elements */
    pub width: usize,
    /**< Height of the array in elements */
    pub height: usize,
    /**< Pitch between two rows in bytes */
    pub pitchInBytes: usize,
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>()
               , 40usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4>()
               , 8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_4 {
    fn clone(&self) -> Self {
        *self
    }
}
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5 {
    pub reserved: [::std::os::raw::c_int; 32usize],
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5>()
               , 128usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5>()
               , 4usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1__bindgen_ty_5 {
    fn clone(&self) -> Self {
        *self
    }
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st__bindgen_ty_1() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>(),
               128usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st__bindgen_ty_1>(),
               8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st__bindgen_ty_1 {
    fn clone(&self) -> Self {
        *self
    }
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_DESC_st() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_DESC_st>(), 144usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_DESC_st>(), 8usize);
}
impl Clone for CUDA_RESOURCE_DESC_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_RESOURCE_DESC = CUDA_RESOURCE_DESC_st;
/**
 * Texture descriptor
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_TEXTURE_DESC_st {
    /**< Address modes */
    pub addressMode: [CUaddress_mode; 3usize],
    /**< Filter mode */
    pub filterMode: CUfilter_mode,
    /**< Flags */
    pub flags: ::std::os::raw::c_uint,
    /**< Maximum anisotropy ratio */
    pub maxAnisotropy: ::std::os::raw::c_uint,
    /**< Mipmap filter mode */
    pub mipmapFilterMode: CUfilter_mode,
    /**< Mipmap level bias */
    pub mipmapLevelBias: f32,
    /**< Mipmap minimum level clamp */
    pub minMipmapLevelClamp: f32,
    /**< Mipmap maximum level clamp */
    pub maxMipmapLevelClamp: f32,
    /**< Border Color */
    pub borderColor: [f32; 4usize],
    pub reserved: [::std::os::raw::c_int; 12usize],
}
#[test]
fn bindgen_test_layout_CUDA_TEXTURE_DESC_st() {
    assert_eq!(::std::mem::size_of::<CUDA_TEXTURE_DESC_st>(), 104usize);
    assert_eq!(::std::mem::align_of::<CUDA_TEXTURE_DESC_st>(), 4usize);
}
impl Clone for CUDA_TEXTURE_DESC_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_TEXTURE_DESC = CUDA_TEXTURE_DESC_st;
#[repr(u32)]
/**
 * Resource view format
 */
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CUresourceViewFormat_enum {
    CU_RES_VIEW_FORMAT_NONE = 0,
    CU_RES_VIEW_FORMAT_UINT_1X8 = 1,
    CU_RES_VIEW_FORMAT_UINT_2X8 = 2,
    CU_RES_VIEW_FORMAT_UINT_4X8 = 3,
    CU_RES_VIEW_FORMAT_SINT_1X8 = 4,
    CU_RES_VIEW_FORMAT_SINT_2X8 = 5,
    CU_RES_VIEW_FORMAT_SINT_4X8 = 6,
    CU_RES_VIEW_FORMAT_UINT_1X16 = 7,
    CU_RES_VIEW_FORMAT_UINT_2X16 = 8,
    CU_RES_VIEW_FORMAT_UINT_4X16 = 9,
    CU_RES_VIEW_FORMAT_SINT_1X16 = 10,
    CU_RES_VIEW_FORMAT_SINT_2X16 = 11,
    CU_RES_VIEW_FORMAT_SINT_4X16 = 12,
    CU_RES_VIEW_FORMAT_UINT_1X32 = 13,
    CU_RES_VIEW_FORMAT_UINT_2X32 = 14,
    CU_RES_VIEW_FORMAT_UINT_4X32 = 15,
    CU_RES_VIEW_FORMAT_SINT_1X32 = 16,
    CU_RES_VIEW_FORMAT_SINT_2X32 = 17,
    CU_RES_VIEW_FORMAT_SINT_4X32 = 18,
    CU_RES_VIEW_FORMAT_FLOAT_1X16 = 19,
    CU_RES_VIEW_FORMAT_FLOAT_2X16 = 20,
    CU_RES_VIEW_FORMAT_FLOAT_4X16 = 21,
    CU_RES_VIEW_FORMAT_FLOAT_1X32 = 22,
    CU_RES_VIEW_FORMAT_FLOAT_2X32 = 23,
    CU_RES_VIEW_FORMAT_FLOAT_4X32 = 24,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC1 = 25,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC2 = 26,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC3 = 27,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC4 = 28,
    CU_RES_VIEW_FORMAT_SIGNED_BC4 = 29,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC5 = 30,
    CU_RES_VIEW_FORMAT_SIGNED_BC5 = 31,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC6H = 32,
    CU_RES_VIEW_FORMAT_SIGNED_BC6H = 33,
    CU_RES_VIEW_FORMAT_UNSIGNED_BC7 = 34,
}
pub type CUresourceViewFormat = CUresourceViewFormat_enum;
/**
 * Resource view descriptor
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_RESOURCE_VIEW_DESC_st {
    /**< Resource view format */
    pub format: CUresourceViewFormat,
    /**< Width of the resource view */
    pub width: usize,
    /**< Height of the resource view */
    pub height: usize,
    /**< Depth of the resource view */
    pub depth: usize,
    /**< First defined mipmap level */
    pub firstMipmapLevel: ::std::os::raw::c_uint,
    /**< Last defined mipmap level */
    pub lastMipmapLevel: ::std::os::raw::c_uint,
    /**< First layer index */
    pub firstLayer: ::std::os::raw::c_uint,
    /**< Last layer index */
    pub lastLayer: ::std::os::raw::c_uint,
    pub reserved: [::std::os::raw::c_uint; 16usize],
}
#[test]
fn bindgen_test_layout_CUDA_RESOURCE_VIEW_DESC_st() {
    assert_eq!(::std::mem::size_of::<CUDA_RESOURCE_VIEW_DESC_st>(),
               112usize);
    assert_eq!(::std::mem::align_of::<CUDA_RESOURCE_VIEW_DESC_st>(), 8usize);
}
impl Clone for CUDA_RESOURCE_VIEW_DESC_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_RESOURCE_VIEW_DESC = CUDA_RESOURCE_VIEW_DESC_st;
/**
 * GPU Direct v3 tokens
 */
#[repr(C)]
#[derive(Debug, Copy)]
pub struct CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st {
    pub p2pToken: ::std::os::raw::c_ulonglong,
    pub vaSpaceToken: ::std::os::raw::c_uint,
}
#[test]
fn bindgen_test_layout_CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st() {
    assert_eq!(::std::mem::size_of::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>(),
               16usize);
    assert_eq!(::std::mem::align_of::<CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st>()
               , 8usize);
}
impl Clone for CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st {
    fn clone(&self) -> Self {
        *self
    }
}
pub type CUDA_POINTER_ATTRIBUTE_P2P_TOKENS =
    CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st;
extern "C" {
    /// \brief Gets the string description of an error code
    ///
    /// Sets \p *pStr to the address of a NULL-terminated string description
    /// of the error code \p error.
    /// If the error code is not recognized, ::CUDA_ERROR_INVALID_VALUE
    /// will be returned and \p *pStr will be set to the NULL address.
    ///
    /// \param error - Error code to convert to string
    /// \param pStr - Address of the string pointer.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::CUresult
    ///
    pub fn cuGetErrorString(error: CUresult,
                            pStr: *mut *const ::std::os::raw::c_char)
                            -> CUresult;
}
extern "C" {
    /// \brief Gets the string representation of an error code enum name
    ///
    /// Sets \p *pStr to the address of a NULL-terminated string representation
    /// of the name of the enum error code \p error.
    /// If the error code is not recognized, ::CUDA_ERROR_INVALID_VALUE
    /// will be returned and \p *pStr will be set to the NULL address.
    ///
    /// \param error - Error code to convert to string
    /// \param pStr - Address of the string pointer.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::CUresult
    ///
    pub fn cuGetErrorName(error: CUresult,
                          pStr: *mut *const ::std::os::raw::c_char)
                          -> CUresult;
}
extern "C" {
    /// \brief Initialize the CUDA driver API
    ///
    /// Initializes the driver API and must be called before any other function from
    /// the driver API. Currently, the \p Flags parameter must be 0. If ::cuInit()
    /// has not been called, any function from the driver API will return
    /// ::CUDA_ERROR_NOT_INITIALIZED.
    ///
    /// \param Flags - Initialization flag for CUDA.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    pub fn cuInit(Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Returns the CUDA driver version
    ///
    /// Returns in \p *driverVersion the version number of the installed CUDA
    /// driver. This function automatically returns ::CUDA_ERROR_INVALID_VALUE if
    /// the \p driverVersion argument is NULL.
    ///
    /// \param driverVersion - Returns the CUDA driver version
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    pub fn cuDriverGetVersion(driverVersion: *mut ::std::os::raw::c_int)
                              -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a compute device
    ///
    /// Returns in \p *device a device handle given an ordinal in the range <b>[0,
    /// ::cuDeviceGetCount()-1]</b>.
    ///
    /// \param device  - Returned device handle
    /// \param ordinal - Device number to get handle for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceGet(device: *mut CUdevice,
                       ordinal: ::std::os::raw::c_int)
                       -> CUresult;
}
extern "C" {
    /// \brief Returns the number of compute-capable devices
    ///
    /// Returns in \p *count the number of devices with compute capability greater
    /// than or equal to 1.0 that are available for execution. If there is no such
    /// device, ::cuDeviceGetCount() returns 0.
    ///
    /// \param count - Returned number of compute-capable devices
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceGetCount(count: *mut ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    /// \brief Returns an identifer string for the device
    ///
    /// Returns an ASCII string identifying the device \p dev in the NULL-terminated
    /// string pointed to by \p name. \p len specifies the maximum length of the
    /// string that may be returned.
    ///
    /// \param name - Returned identifier string for the device
    /// \param len  - Maximum length of string to store in \p name
    /// \param dev  - Device to get identifier string for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceGetName(name: *mut ::std::os::raw::c_char,
                           len: ::std::os::raw::c_int,
                           dev: CUdevice)
                           -> CUresult;
}
extern "C" {
    pub fn cuDeviceTotalMem_v2(bytes: *mut usize, dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Returns information about the device
    ///
    /// Returns in \p *pi the integer value of the attribute \p attrib on device
    /// \p dev. The supported attributes are:
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK: Maximum number of threads per
    ///   block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X: Maximum x-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y: Maximum y-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z: Maximum z-dimension of a block;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X: Maximum x-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y: Maximum y-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z: Maximum z-dimension of a grid;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK: Maximum amount of
    ///   shared memory available to a thread block in bytes;
    /// - ::CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY: Memory available on device for
    ///   __constant__ variables in a CUDA C kernel in bytes;
    /// - ::CU_DEVICE_ATTRIBUTE_WARP_SIZE: Warp size in threads;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_PITCH: Maximum pitch in bytes allowed by the
    ///   memory copy functions that involve memory regions allocated through
    ///   ::cuMemAllocPitch();
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH: Maximum 1D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH: Maximum width
    ///  for a 1D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: Maximum
    ///  mipmapped 1D texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH: Maximum 2D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT: Maximum 2D
    ///  texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH: Maximum width
    ///  for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: Maximum height
    ///  for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH: Maximum pitch
    ///  in bytes for a 2D texture bound to linear memory;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: Maximum
    ///  mipmapped 2D texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: Maximum
    ///  mipmapped 2D texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH: Maximum 3D
    ///  texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT: Maximum 3D
    ///  texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH: Maximum 3D
    ///  texture depth;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE:
    ///  Alternate maximum 3D texture width, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE:
    ///  Alternate maximum 3D texture height, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE:
    ///  Alternate maximum 3D texture depth, 0 if no alternate
    ///  maximum 3D texture size is supported;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH:
    ///  Maximum cubemap texture width or height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH:
    ///  Maximum 1D layered texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS:
    ///   Maximum layers in a 1D layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH:
    ///  Maximum 2D layered texture width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT:
    ///   Maximum 2D layered texture height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS:
    ///   Maximum layers in a 2D layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH:
    ///   Maximum cubemap layered texture width or height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS:
    ///   Maximum layers in a cubemap layered texture;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH:
    ///   Maximum 1D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH:
    ///   Maximum 2D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT:
    ///   Maximum 2D surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH:
    ///   Maximum 3D surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT:
    ///   Maximum 3D surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH:
    ///   Maximum 3D surface depth;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH:
    ///   Maximum 1D layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS:
    ///   Maximum layers in a 1D layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH:
    ///   Maximum 2D layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT:
    ///   Maximum 2D layered surface height;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS:
    ///   Maximum layers in a 2D layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH:
    ///   Maximum cubemap surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH:
    ///   Maximum cubemap layered surface width;
    /// - ::CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS:
    ///   Maximum layers in a cubemap layered surface;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK: Maximum number of 32-bit
    ///   registers available to a thread block;
    /// - ::CU_DEVICE_ATTRIBUTE_CLOCK_RATE: The typical clock frequency in kilohertz;
    /// - ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT: Alignment requirement; texture
    ///   base addresses aligned to ::textureAlign bytes do not need an offset
    ///   applied to texture fetches;
    /// - ::CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT: Pitch alignment requirement
    ///   for 2D texture references bound to pitched memory;
    /// - ::CU_DEVICE_ATTRIBUTE_GPU_OVERLAP: 1 if the device can concurrently copy
    ///   memory between host and device while executing a kernel, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT: Number of multiprocessors on
    ///   the device;
    /// - ::CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT: 1 if there is a run time limit
    ///   for kernels executed on the device, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_INTEGRATED: 1 if the device is integrated with the
    ///   memory subsystem, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY: 1 if the device can map host
    ///   memory into the CUDA address space, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE: Compute mode that device is currently
    ///   in. Available modes are as follows:
    ///   - ::CU_COMPUTEMODE_DEFAULT: Default mode - Device is not restricted and
    ///     can have multiple CUDA contexts present at a single time.
    ///   - ::CU_COMPUTEMODE_PROHIBITED: Compute-prohibited mode - Device is
    ///     prohibited from creating new CUDA contexts.
    ///   - ::CU_COMPUTEMODE_EXCLUSIVE_PROCESS:  Compute-exclusive-process mode - Device
    ///     can have only one context used by a single process at a time.
    /// - ::CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS: 1 if the device supports
    ///   executing multiple kernels within the same context simultaneously, or 0 if
    ///   not. It is not guaranteed that multiple kernels will be resident
    ///   on the device concurrently so this feature should not be relied upon for
    ///   correctness;
    /// - ::CU_DEVICE_ATTRIBUTE_ECC_ENABLED: 1 if error correction is enabled on the
    ///    device, 0 if error correction is disabled or not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_PCI_BUS_ID: PCI bus identifier of the device;
    /// - ::CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID: PCI device (also known as slot) identifier
    ///   of the device;
    /// - ::CU_DEVICE_ATTRIBUTE_TCC_DRIVER: 1 if the device is using a TCC driver. TCC
    ///    is only available on Tesla hardware running Windows Vista or later;
    /// - ::CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE: Peak memory clock frequency in kilohertz;
    /// - ::CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH: Global memory bus width in bits;
    /// - ::CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE: Size of L2 cache in bytes. 0 if the device doesn't have L2 cache;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR: Maximum resident threads per multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING: 1 if the device shares a unified address space with
    ///   the host, or 0 if not;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR: Major compute capability version number;
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR: Minor compute capability version number;
    /// - ::CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED: 1 if device supports caching globals
    ///    in L1 cache, 0 if caching globals in L1 cache is not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED: 1 if device supports caching locals
    ///    in L1 cache, 0 if caching locals in L1 cache is not supported by the device;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: Maximum amount of
    ///   shared memory available to a multiprocessor in bytes; this amount is shared
    ///   by all thread blocks simultaneously resident on a multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR: Maximum number of 32-bit
    ///   registers available to a multiprocessor; this number is shared by all thread
    ///   blocks simultaneously resident on a multiprocessor;
    /// - ::CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY: 1 if device supports allocating managed memory
    ///   on this system, 0 if allocating managed memory is not supported by the device on this system.
    /// - ::CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD: 1 if device is on a multi-GPU board, 0 if not.
    /// - ::CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID: Unique identifier for a group of devices
    ///   associated with the same board. Devices on the same multi-GPU board will share the same identifier.
    /// - ::CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED: 1 if Link between the device and the host
    ///   supports native atomic operations.
    /// - ::CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO: Ratio of single precision performance
    ///   (in floating-point operations per second) to double precision performance.
    /// - ::CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS: Device suppports coherently accessing
    ///   pageable memory without calling cudaHostRegister on it.
    /// - ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS: Device can coherently access managed memory
    ///   concurrently with the CPU.
    /// - ::CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED: Device supports Compute Preemption.
    /// - ::CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM: Device can access host registered
    ///   memory at the same virtual address as the CPU.
    ///
    /// \param pi     - Returned device attribute value
    /// \param attrib - Device attribute to query
    /// \param dev    - Device handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceGetAttribute(pi: *mut ::std::os::raw::c_int,
                                attrib: CUdevice_attribute,
                                dev: CUdevice)
                                -> CUresult;
}
extern "C" {
    /// \brief Returns properties for a selected device
    ///
    /// \deprecated
    ///
    /// This function was deprecated as of CUDA 5.0 and replaced by ::cuDeviceGetAttribute().
    ///
    /// Returns in \p *prop the properties of device \p dev. The ::CUdevprop
    /// structure is defined as:
    ///
    /// \code
    /// typedef struct CUdevprop_st {
    /// int maxThreadsPerBlock;
    /// int maxThreadsDim[3];
    /// int maxGridSize[3];
    /// int sharedMemPerBlock;
    /// int totalConstantMemory;
    /// int SIMDWidth;
    /// int memPitch;
    /// int regsPerBlock;
    /// int clockRate;
    /// int textureAlign
    /// } CUdevprop;
    /// \endcode
    /// where:
    ///
    /// - ::maxThreadsPerBlock is the maximum number of threads per block;
    /// - ::maxThreadsDim[3] is the maximum sizes of each dimension of a block;
    /// - ::maxGridSize[3] is the maximum sizes of each dimension of a grid;
    /// - ::sharedMemPerBlock is the total amount of shared memory available per
    ///   block in bytes;
    /// - ::totalConstantMemory is the total amount of constant memory available on
    ///   the device in bytes;
    /// - ::SIMDWidth is the warp size;
    /// - ::memPitch is the maximum pitch allowed by the memory copy functions that
    ///   involve memory regions allocated through ::cuMemAllocPitch();
    /// - ::regsPerBlock is the total number of registers available per block;
    /// - ::clockRate is the clock frequency in kilohertz;
    /// - ::textureAlign is the alignment requirement; texture base addresses that
    ///   are aligned to ::textureAlign bytes do not need an offset applied to
    ///   texture fetches.
    ///
    /// \param prop - Returned properties of device
    /// \param dev  - Device to get properties for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceGetProperties(prop: *mut CUdevprop,
                                 dev: CUdevice)
                                 -> CUresult;
}
extern "C" {
    /// \brief Returns the compute capability of the device
    ///
    /// \deprecated
    ///
    /// This function was deprecated as of CUDA 5.0 and its functionality superceded
    /// by ::cuDeviceGetAttribute().
    ///
    /// Returns in \p *major and \p *minor the major and minor revision numbers that
    /// define the compute capability of the device \p dev.
    ///
    /// \param major - Major revision number
    /// \param minor - Minor revision number
    /// \param dev   - Device handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa
    /// ::cuDeviceGetAttribute,
    /// ::cuDeviceGetCount,
    /// ::cuDeviceGetName,
    /// ::cuDeviceGet,
    /// ::cuDeviceTotalMem
    ///
    pub fn cuDeviceComputeCapability(major: *mut ::std::os::raw::c_int,
                                     minor: *mut ::std::os::raw::c_int,
                                     dev: CUdevice)
                                     -> CUresult;
}
extern "C" {
    /// \brief Retain the primary context on the GPU
    ///
    /// Retains the primary context on the device, creating it if necessary,
    /// increasing its usage count. The caller must call
    /// ::cuDevicePrimaryCtxRelease() when done using the context.
    /// Unlike ::cuCtxCreate() the newly created context is not pushed onto the stack.
    ///
    /// Context creation will fail with ::CUDA_ERROR_UNKNOWN if the compute mode of
    /// the device is ::CU_COMPUTEMODE_PROHIBITED.  The function ::cuDeviceGetAttribute()
    /// can be used with ::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE to determine the compute mode
    /// of the device.
    /// The <i>nvidia-smi</i> tool can be used to set the compute mode for
    /// devices. Documentation for <i>nvidia-smi</i> can be obtained by passing a
    /// -h option to it.
    ///
    /// Please note that the primary context always supports pinned allocations. Other
    /// flags can be specified by ::cuDevicePrimaryCtxSetFlags().
    ///
    /// \param pctx  - Returned context handle of the new context
    /// \param dev   - Device for which primary context is requested
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRelease,
    /// ::cuDevicePrimaryCtxSetFlags,
    /// ::cuCtxCreate,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuDevicePrimaryCtxRetain(pctx: *mut CUcontext,
                                    dev: CUdevice)
                                    -> CUresult;
}
extern "C" {
    /// \brief Release the primary context on the GPU
    ///
    /// Releases the primary context interop on the device by decreasing the usage
    /// count by 1. If the usage drops to 0 the primary context of device \p dev
    /// will be destroyed regardless of how many threads it is current to.
    ///
    /// Please note that unlike ::cuCtxDestroy() this method does not pop the context
    /// from stack in any circumstances.
    ///
    /// \param dev - Device which primary context is released
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuDevicePrimaryCtxRelease(dev: CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Set flags for the primary context
    ///
    /// Sets the flags for the primary context on the device overwriting perviously
    /// set ones. If the primary context is already created
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE is returned.
    ///
    /// The three LSBs of the \p flags parameter can be used to control how the OS
    /// thread, which owns the CUDA context at the time of an API call, interacts
    /// with the OS scheduler when waiting for results from the GPU. Only one of
    /// the scheduling flags can be set when creating a context.
    ///
    /// - ::CU_CTX_SCHED_SPIN: Instruct CUDA to actively spin when waiting for
    /// results from the GPU. This can decrease latency when waiting for the GPU,
    /// but may lower the performance of CPU threads if they are performing work in
    /// parallel with the CUDA thread.
    ///
    /// - ::CU_CTX_SCHED_YIELD: Instruct CUDA to yield its thread when waiting for
    /// results from the GPU. This can increase latency when waiting for the GPU,
    /// but can increase the performance of CPU threads performing work in parallel
    /// with the GPU.
    ///
    /// - ::CU_CTX_SCHED_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a
    /// synchronization primitive when waiting for the GPU to finish work.
    ///
    /// - ::CU_CTX_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a
    /// synchronization primitive when waiting for the GPU to finish work. <br>
    /// <b>Deprecated:</b> This flag was deprecated as of CUDA 4.0 and was
    /// replaced with ::CU_CTX_SCHED_BLOCKING_SYNC.
    ///
    /// - ::CU_CTX_SCHED_AUTO: The default value if the \p flags parameter is zero,
    /// uses a heuristic based on the number of active CUDA contexts in the
    /// process \e C and the number of logical processors in the system \e P. If
    /// \e C > \e P, then CUDA will yield to other OS threads when waiting for
    /// the GPU (::CU_CTX_SCHED_YIELD), otherwise CUDA will not yield while
    /// waiting for results and actively spin on the processor (::CU_CTX_SCHED_SPIN).
    /// However, on low power devices like Tegra, it always defaults to
    /// ::CU_CTX_SCHED_BLOCKING_SYNC.
    ///
    /// - ::CU_CTX_LMEM_RESIZE_TO_MAX: Instruct CUDA to not reduce local memory
    /// after resizing local memory for a kernel. This can prevent thrashing by
    /// local memory allocations when launching many kernels with high local
    /// memory usage at the cost of potentially increased memory usage.
    ///
    /// \param dev   - Device for which the primary context flags are set
    /// \param flags - New flags for the device
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuDevicePrimaryCtxGetState,
    /// ::cuCtxCreate,
    /// ::cuCtxGetFlags
    ///
    pub fn cuDevicePrimaryCtxSetFlags(dev: CUdevice,
                                      flags: ::std::os::raw::c_uint)
                                      -> CUresult;
}
extern "C" {
    /// \brief Get the state of the primary context
    ///
    /// Returns in \p *flags the flags for the primary context of \p dev, and in
    /// \p *active whether it is active.  See ::cuDevicePrimaryCtxSetFlags for flag
    /// values.
    ///
    /// \param dev    - Device to get primary context flags for
    /// \param flags  - Pointer to store flags
    /// \param active - Pointer to store context state; 0 = inactive, 1 = active
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxSetFlags,
    /// ::cuCtxGetFlags
    ///
    pub fn cuDevicePrimaryCtxGetState(dev: CUdevice,
                                      flags: *mut ::std::os::raw::c_uint,
                                      active: *mut ::std::os::raw::c_int)
                                      -> CUresult;
}
extern "C" {
    /// \brief Destroy all allocations and reset all state on the primary context
    ///
    /// Explicitly destroys and cleans up all resources associated with the current
    /// device in the current process.
    ///
    /// Note that it is responsibility of the calling function to ensure that no
    /// other module in the process is using the device any more. For that reason
    /// it is recommended to use ::cuDevicePrimaryCtxRelease() in most cases.
    /// However it is safe for other modules to call ::cuDevicePrimaryCtxRelease()
    /// even after resetting the device.
    ///
    /// \param dev - Device for which primary context is destroyed
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE
    /// \notefnerr
    ///
    /// \sa ::cuDevicePrimaryCtxRetain,
    /// ::cuDevicePrimaryCtxRelease,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    ///
    pub fn cuDevicePrimaryCtxReset(dev: CUdevice) -> CUresult;
}
extern "C" {
    pub fn cuCtxCreate_v2(pctx: *mut CUcontext,
                          flags: ::std::os::raw::c_uint,
                          dev: CUdevice)
                          -> CUresult;
}
extern "C" {
    pub fn cuCtxDestroy_v2(ctx: CUcontext) -> CUresult;
}
extern "C" {
    pub fn cuCtxPushCurrent_v2(ctx: CUcontext) -> CUresult;
}
extern "C" {
    pub fn cuCtxPopCurrent_v2(pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Binds the specified CUDA context to the calling CPU thread
    ///
    /// Binds the specified CUDA context to the calling CPU thread.
    /// If \p ctx is NULL then the CUDA context previously bound to the
    /// calling CPU thread is unbound and ::CUDA_SUCCESS is returned.
    ///
    /// If there exists a CUDA context stack on the calling CPU thread, this
    /// will replace the top of that stack with \p ctx.
    /// If \p ctx is NULL then this will be equivalent to popping the top
    /// of the calling CPU thread's CUDA context stack (or a no-op if the
    /// calling CPU thread's CUDA context stack is empty).
    ///
    /// \param ctx - Context to bind to the calling CPU thread
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCurrent, ::cuCtxCreate, ::cuCtxDestroy
    ///
    pub fn cuCtxSetCurrent(ctx: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Returns the CUDA context bound to the calling CPU thread.
    ///
    /// Returns in \p *pctx the CUDA context bound to the calling CPU thread.
    /// If no context is bound to the calling CPU thread then \p *pctx is
    /// set to NULL and ::CUDA_SUCCESS is returned.
    ///
    /// \param pctx - Returned context handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// \notefnerr
    ///
    /// \sa ::cuCtxSetCurrent, ::cuCtxCreate, ::cuCtxDestroy
    ///
    pub fn cuCtxGetCurrent(pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Returns the device ID for the current context
    ///
    /// Returns in \p *device the ordinal of the current context's device.
    ///
    /// \param device - Returned device ID for the current context
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxGetDevice(device: *mut CUdevice) -> CUresult;
}
extern "C" {
    /// \brief Returns the flags for the current context
    ///
    /// Returns in \p *flags the flags of the current context. See ::cuCtxCreate
    /// for flag values.
    ///
    /// \param flags - Pointer to store flags of current context
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetCurrent,
    /// ::cuCtxGetDevice
    /// ::cuCtxGetLimit,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuCtxGetStreamPriorityRange
    ///
    pub fn cuCtxGetFlags(flags: *mut ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    /// \brief Block for a context's tasks to complete
    ///
    /// Blocks until the device has completed all preceding requested tasks.
    /// ::cuCtxSynchronize() returns an error if one of the preceding tasks failed.
    /// If the context was created with the ::CU_CTX_SCHED_BLOCKING_SYNC flag, the
    /// CPU thread will block until the GPU context has finished its work.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit
    ///
    pub fn cuCtxSynchronize() -> CUresult;
}
extern "C" {
    /// \brief Set resource limits
    ///
    /// Setting \p limit to \p value is a request by the application to update
    /// the current limit maintained by the context. The driver is free to
    /// modify the requested value to meet h/w requirements (this could be
    /// clamping to minimum or maximum values, rounding up to nearest element
    /// size, etc). The application can use ::cuCtxGetLimit() to find out exactly
    /// what the limit has been set to.
    ///
    /// Setting each ::CUlimit has its own specific restrictions, so each is
    /// discussed here.
    ///
    /// - ::CU_LIMIT_STACK_SIZE controls the stack size in bytes of each GPU thread.
    ///   This limit is only applicable to devices of compute capability 2.0 and
    ///   higher. Attempting to set this limit on devices of compute capability
    ///   less than 2.0 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT
    ///   being returned.
    ///
    /// - ::CU_LIMIT_PRINTF_FIFO_SIZE controls the size in bytes of the FIFO used
    ///   by the ::printf() device system call. Setting ::CU_LIMIT_PRINTF_FIFO_SIZE
    ///   must be performed before launching any kernel that uses the ::printf()
    ///   device system call, otherwise ::CUDA_ERROR_INVALID_VALUE will be returned.
    ///   This limit is only applicable to devices of compute capability 2.0 and
    ///   higher. Attempting to set this limit on devices of compute capability
    ///   less than 2.0 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT
    ///   being returned.
    ///
    /// - ::CU_LIMIT_MALLOC_HEAP_SIZE controls the size in bytes of the heap used
    ///   by the ::malloc() and ::free() device system calls. Setting
    ///   ::CU_LIMIT_MALLOC_HEAP_SIZE must be performed before launching any kernel
    ///   that uses the ::malloc() or ::free() device system calls, otherwise
    ///   ::CUDA_ERROR_INVALID_VALUE will be returned. This limit is only applicable
    ///   to devices of compute capability 2.0 and higher. Attempting to set this
    ///   limit on devices of compute capability less than 2.0 will result in the
    ///   error ::CUDA_ERROR_UNSUPPORTED_LIMIT being returned.
    ///
    /// - ::CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH controls the maximum nesting depth of
    ///   a grid at which a thread can safely call ::cudaDeviceSynchronize(). Setting
    ///   this limit must be performed before any launch of a kernel that uses the
    ///   device runtime and calls ::cudaDeviceSynchronize() above the default sync
    ///   depth, two levels of grids. Calls to ::cudaDeviceSynchronize() will fail
    ///   with error code ::cudaErrorSyncDepthExceeded if the limitation is
    ///   violated. This limit can be set smaller than the default or up the maximum
    ///   launch depth of 24. When setting this limit, keep in mind that additional
    ///   levels of sync depth require the driver to reserve large amounts of device
    ///   memory which can no longer be used for user allocations. If these
    ///   reservations of device memory fail, ::cuCtxSetLimit will return
    ///   ::CUDA_ERROR_OUT_OF_MEMORY, and the limit can be reset to a lower value.
    ///   This limit is only applicable to devices of compute capability 3.5 and
    ///   higher. Attempting to set this limit on devices of compute capability less
    ///   than 3.5 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT being
    ///   returned.
    ///
    /// - ::CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT controls the maximum number of
    ///   outstanding device runtime launches that can be made from the current
    ///   context. A grid is outstanding from the point of launch up until the grid
    ///   is known to have been completed. Device runtime launches which violate
    ///   this limitation fail and return ::cudaErrorLaunchPendingCountExceeded when
    ///   ::cudaGetLastError() is called after launch. If more pending launches than
    ///   the default (2048 launches) are needed for a module using the device
    ///   runtime, this limit can be increased. Keep in mind that being able to
    ///   sustain additional pending launches will require the driver to reserve
    ///   larger amounts of device memory upfront which can no longer be used for
    ///   allocations. If these reservations fail, ::cuCtxSetLimit will return
    ///   ::CUDA_ERROR_OUT_OF_MEMORY, and the limit can be reset to a lower value.
    ///   This limit is only applicable to devices of compute capability 3.5 and
    ///   higher. Attempting to set this limit on devices of compute capability less
    ///   than 3.5 will result in the error ::CUDA_ERROR_UNSUPPORTED_LIMIT being
    ///   returned.
    ///
    /// \param limit - Limit to set
    /// \param value - Size of limit
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNSUPPORTED_LIMIT,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxSetLimit(limit: CUlimit, value: usize) -> CUresult;
}
extern "C" {
    /// \brief Returns resource limits
    ///
    /// Returns in \p *pvalue the current size of \p limit.  The supported
    /// ::CUlimit values are:
    /// - ::CU_LIMIT_STACK_SIZE: stack size in bytes of each GPU thread.
    /// - ::CU_LIMIT_PRINTF_FIFO_SIZE: size in bytes of the FIFO used by the
    ///   ::printf() device system call.
    /// - ::CU_LIMIT_MALLOC_HEAP_SIZE: size in bytes of the heap used by the
    ///   ::malloc() and ::free() device system calls.
    /// - ::CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH: maximum grid depth at which a thread
    ///   can issue the device runtime call ::cudaDeviceSynchronize() to wait on
    ///   child grid launches to complete.
    /// - ::CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT: maximum number of outstanding
    ///   device runtime launches that can be made from this context.
    ///
    /// \param limit  - Limit to query
    /// \param pvalue - Returned size of limit
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNSUPPORTED_LIMIT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxGetLimit(pvalue: *mut usize, limit: CUlimit) -> CUresult;
}
extern "C" {
    /// \brief Returns the preferred cache configuration for the current context.
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this function returns through \p pconfig the preferred cache configuration
    /// for the current context. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute functions.
    ///
    /// This will return a \p pconfig of ::CU_FUNC_CACHE_PREFER_NONE on devices
    /// where the size of the L1 cache and shared memory are fixed.
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param pconfig - Returned cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuFuncSetCacheConfig
    ///
    pub fn cuCtxGetCacheConfig(pconfig: *mut CUfunc_cache) -> CUresult;
}
extern "C" {
    /// \brief Sets the preferred cache configuration for the current context.
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this sets through \p config the preferred cache configuration for
    /// the current context. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute the function. Any function preference
    /// set via ::cuFuncSetCacheConfig() will be preferred over this context-wide
    /// setting. Setting the context-wide cache configuration to
    /// ::CU_FUNC_CACHE_PREFER_NONE will cause subsequent kernel launches to prefer
    /// to not change the cache configuration unless required to launch the kernel.
    ///
    /// This setting does nothing on devices where the size of the L1 cache and
    /// shared memory are fixed.
    ///
    /// Launching a kernel with a different preference than the most recent
    /// preference setting may insert a device-side synchronization point.
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param config - Requested cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuFuncSetCacheConfig
    ///
    pub fn cuCtxSetCacheConfig(config: CUfunc_cache) -> CUresult;
}
extern "C" {
    /// \brief Returns the current shared memory configuration for the current context.
    ///
    /// This function will return in \p pConfig the current size of shared memory banks
    /// in the current context. On devices with configurable shared memory banks,
    /// ::cuCtxSetSharedMemConfig can be used to change this setting, so that all
    /// subsequent kernel launches will by default use the new bank size. When
    /// ::cuCtxGetSharedMemConfig is called on devices without configurable shared
    /// memory, it will return the fixed bank size of the hardware.
    ///
    /// The returned bank configurations can be either:
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE:  shared memory bank width is
    ///   four bytes.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: shared memory bank width will
    ///   eight bytes.
    ///
    /// \param pConfig - returned shared memory configuration
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuFuncSetCacheConfig,
    ///
    pub fn cuCtxGetSharedMemConfig(pConfig: *mut CUsharedconfig) -> CUresult;
}
extern "C" {
    /// \brief Sets the shared memory configuration for the current context.
    ///
    /// On devices with configurable shared memory banks, this function will set
    /// the context's shared memory bank size which is used for subsequent kernel
    /// launches.
    ///
    /// Changed the shared memory configuration between launches may insert a device
    /// side synchronization point between those launches.
    ///
    /// Changing the shared memory bank size will not increase shared memory usage
    /// or affect occupancy of kernels, but may have major effects on performance.
    /// Larger bank sizes will allow for greater potential bandwidth to shared memory,
    /// but will change what kinds of accesses to shared memory will result in bank
    /// conflicts.
    ///
    /// This function will do nothing on devices with fixed shared memory bank size.
    ///
    /// The supported bank configurations are:
    /// - ::CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE: set bank width to the default initial
    ///   setting (currently, four bytes).
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively four bytes.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively eight bytes.
    ///
    /// \param config - requested shared memory configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuFuncSetCacheConfig,
    ///
    pub fn cuCtxSetSharedMemConfig(config: CUsharedconfig) -> CUresult;
}
extern "C" {
    /// \brief Gets the context's API version.
    ///
    /// Returns a version number in \p version corresponding to the capabilities of
    /// the context (e.g. 3010 or 3020), which library developers can use to direct
    /// callers to a specific API version. If \p ctx is NULL, returns the API version
    /// used to create the currently bound context.
    ///
    /// Note that new API versions are only introduced when context capabilities are
    /// changed that break binary compatibility, so the API version and driver version
    /// may be different. For example, it is valid for the API version to be 3020 while
    /// the driver version is 4020.
    ///
    /// \param ctx     - Context to check
    /// \param version - Pointer to version
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxGetApiVersion(ctx: CUcontext,
                              version: *mut ::std::os::raw::c_uint)
                              -> CUresult;
}
extern "C" {
    /// \brief Returns numerical values that correspond to the least and
    /// greatest stream priorities.
    ///
    /// Returns in \p *leastPriority and \p *greatestPriority the numerical values that correspond
    /// to the least and greatest stream priorities respectively. Stream priorities
    /// follow a convention where lower numbers imply greater priorities. The range of
    /// meaningful stream priorities is given by [\p *greatestPriority, \p *leastPriority].
    /// If the user attempts to create a stream with a priority value that is
    /// outside the meaningful range as specified by this API, the priority is
    /// automatically clamped down or up to either \p *leastPriority or \p *greatestPriority
    /// respectively. See ::cuStreamCreateWithPriority for details on creating a
    /// priority stream.
    /// A NULL may be passed in for \p *leastPriority or \p *greatestPriority if the value
    /// is not desired.
    ///
    /// This function will return '0' in both \p *leastPriority and \p *greatestPriority if
    /// the current context's device does not support stream priorities
    /// (see ::cuDeviceGetAttribute).
    ///
    /// \param leastPriority    - Pointer to an int in which the numerical value for least
    ///                           stream priority is returned
    /// \param greatestPriority - Pointer to an int in which the numerical value for greatest
    ///                           stream priority is returned
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreateWithPriority,
    /// ::cuStreamGetPriority,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxGetStreamPriorityRange(leastPriority:
                                           *mut ::std::os::raw::c_int,
                                       greatestPriority:
                                           *mut ::std::os::raw::c_int)
     -> CUresult;
}
extern "C" {
    /// \brief Increment a context's usage-count
    ///
    /// \deprecated
    ///
    /// Note that this function is deprecated and should not be used.
    ///
    /// Increments the usage count of the context and passes back a context handle
    /// in \p *pctx that must be passed to ::cuCtxDetach() when the application is
    /// done with the context. ::cuCtxAttach() fails if there is no context current
    /// to the thread.
    ///
    /// Currently, the \p flags parameter must be 0.
    ///
    /// \param pctx  - Returned context handle of the current context
    /// \param flags - Context attach flags (must be 0)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxDetach,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxAttach(pctx: *mut CUcontext,
                       flags: ::std::os::raw::c_uint)
                       -> CUresult;
}
extern "C" {
    /// \brief Decrement a context's usage-count
    ///
    /// \deprecated
    ///
    /// Note that this function is deprecated and should not be used.
    ///
    /// Decrements the usage count of the context \p ctx, and destroys the context
    /// if the usage count goes to 0. The context must be a handle that was passed
    /// back by ::cuCtxCreate() or ::cuCtxAttach(), and must be current to the
    /// calling thread.
    ///
    /// \param ctx - Context to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxCreate,
    /// ::cuCtxDestroy,
    /// ::cuCtxGetApiVersion,
    /// ::cuCtxGetCacheConfig,
    /// ::cuCtxGetDevice,
    /// ::cuCtxGetFlags,
    /// ::cuCtxGetLimit,
    /// ::cuCtxPopCurrent,
    /// ::cuCtxPushCurrent,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxSetLimit,
    /// ::cuCtxSynchronize
    ///
    pub fn cuCtxDetach(ctx: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Loads a compute module
    ///
    /// Takes a filename \p fname and loads the corresponding module \p module into
    /// the current context. The CUDA driver API does not attempt to lazily
    /// allocate the resources needed by a module; if the memory for functions and
    /// data (constant and global) needed by the module cannot be allocated,
    /// ::cuModuleLoad() fails. The file should be a \e cubin file as output by
    /// \b nvcc, or a \e PTX file either as output by \b nvcc or handwritten, or
    /// a \e fatbin file as output by \b nvcc from toolchain 4.0 or later.
    ///
    /// \param module - Returned module
    /// \param fname  - Filename of module to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_NOT_FOUND,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_FILE_NOT_FOUND,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleLoad(module: *mut CUmodule,
                        fname: *const ::std::os::raw::c_char)
                        -> CUresult;
}
extern "C" {
    /// \brief Load a module's data
    ///
    /// Takes a pointer \p image and loads the corresponding module \p module into
    /// the current context. The pointer may be obtained by mapping a \e cubin or
    /// \e PTX or \e fatbin file, passing a \e cubin or \e PTX or \e fatbin file
    /// as a NULL-terminated text string, or incorporating a \e cubin or \e fatbin
    /// object into the executable resources and using operating system calls such
    /// as Windows \c FindResource() to obtain the pointer.
    ///
    /// \param module - Returned module
    /// \param image  - Module data to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleLoadData(module: *mut CUmodule,
                            image: *const ::std::os::raw::c_void)
                            -> CUresult;
}
extern "C" {
    /// \brief Load a module's data with options
    ///
    /// Takes a pointer \p image and loads the corresponding module \p module into
    /// the current context. The pointer may be obtained by mapping a \e cubin or
    /// \e PTX or \e fatbin file, passing a \e cubin or \e PTX or \e fatbin file
    /// as a NULL-terminated text string, or incorporating a \e cubin or \e fatbin
    /// object into the executable resources and using operating system calls such
    /// as Windows \c FindResource() to obtain the pointer. Options are passed as
    /// an array via \p options and any corresponding parameters are passed in
    /// \p optionValues. The number of total options is supplied via \p numOptions.
    /// Any outputs will be returned via \p optionValues.
    ///
    /// \param module       - Returned module
    /// \param image        - Module data to load
    /// \param numOptions   - Number of options
    /// \param options      - Options for JIT
    /// \param optionValues - Option values for JIT
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleLoadDataEx(module: *mut CUmodule,
                              image: *const ::std::os::raw::c_void,
                              numOptions: ::std::os::raw::c_uint,
                              options: *mut CUjit_option,
                              optionValues: *mut *mut ::std::os::raw::c_void)
     -> CUresult;
}
extern "C" {
    /// \brief Load a module's data
    ///
    /// Takes a pointer \p fatCubin and loads the corresponding module \p module
    /// into the current context. The pointer represents a <i>fat binary</i> object,
    /// which is a collection of different \e cubin and/or \e PTX files, all
    /// representing the same device code, but compiled and optimized for different
    /// architectures.
    ///
    /// Prior to CUDA 4.0, there was no documented API for constructing and using
    /// fat binary objects by programmers.  Starting with CUDA 4.0, fat binary
    /// objects can be constructed by providing the <i>-fatbin option</i> to \b nvcc.
    /// More information can be found in the \b nvcc document.
    ///
    /// \param module   - Returned module
    /// \param fatCubin - Fat binary to load
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_PTX,
    /// ::CUDA_ERROR_NOT_FOUND,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_NO_BINARY_FOR_GPU,
    /// ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleLoadFatBinary(module: *mut CUmodule,
                                 fatCubin: *const ::std::os::raw::c_void)
                                 -> CUresult;
}
extern "C" {
    /// \brief Unloads a module
    ///
    /// Unloads a module \p hmod from the current context.
    ///
    /// \param hmod - Module to unload
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary
    ///
    pub fn cuModuleUnload(hmod: CUmodule) -> CUresult;
}
extern "C" {
    /// \brief Returns a function handle
    ///
    /// Returns in \p *hfunc the handle of the function of name \p name located in
    /// module \p hmod. If no function of that name exists, ::cuModuleGetFunction()
    /// returns ::CUDA_ERROR_NOT_FOUND.
    ///
    /// \param hfunc - Returned function handle
    /// \param hmod  - Module to retrieve function from
    /// \param name  - Name of function to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleGetFunction(hfunc: *mut CUfunction,
                               hmod: CUmodule,
                               name: *const ::std::os::raw::c_char)
                               -> CUresult;
}
extern "C" {
    pub fn cuModuleGetGlobal_v2(dptr: *mut CUdeviceptr,
                                bytes: *mut usize,
                                hmod: CUmodule,
                                name: *const ::std::os::raw::c_char)
                                -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a texture reference
    ///
    /// Returns in \p *pTexRef the handle of the texture reference of name \p name
    /// in the module \p hmod. If no texture reference of that name exists,
    /// ::cuModuleGetTexRef() returns ::CUDA_ERROR_NOT_FOUND. This texture reference
    /// handle should not be destroyed, since it will be destroyed when the module
    /// is unloaded.
    ///
    /// \param pTexRef  - Returned texture reference
    /// \param hmod     - Module to retrieve texture reference from
    /// \param name     - Name of texture reference to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetSurfRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleGetTexRef(pTexRef: *mut CUtexref,
                             hmod: CUmodule,
                             name: *const ::std::os::raw::c_char)
                             -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a surface reference
    ///
    /// Returns in \p *pSurfRef the handle of the surface reference of name \p name
    /// in the module \p hmod. If no surface reference of that name exists,
    /// ::cuModuleGetSurfRef() returns ::CUDA_ERROR_NOT_FOUND.
    ///
    /// \param pSurfRef  - Returned surface reference
    /// \param hmod     - Module to retrieve surface reference from
    /// \param name     - Name of surface reference to retrieve
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_FOUND
    /// \notefnerr
    ///
    /// \sa ::cuModuleGetFunction,
    /// ::cuModuleGetGlobal,
    /// ::cuModuleGetTexRef,
    /// ::cuModuleLoad,
    /// ::cuModuleLoadData,
    /// ::cuModuleLoadDataEx,
    /// ::cuModuleLoadFatBinary,
    /// ::cuModuleUnload
    ///
    pub fn cuModuleGetSurfRef(pSurfRef: *mut CUsurfref,
                              hmod: CUmodule,
                              name: *const ::std::os::raw::c_char)
                              -> CUresult;
}
extern "C" {
    pub fn cuLinkCreate_v2(numOptions: ::std::os::raw::c_uint,
                           options: *mut CUjit_option,
                           optionValues: *mut *mut ::std::os::raw::c_void,
                           stateOut: *mut CUlinkState)
                           -> CUresult;
}
extern "C" {
    pub fn cuLinkAddData_v2(state: CUlinkState,
                            type_: CUjitInputType,
                            data: *mut ::std::os::raw::c_void,
                            size: usize,
                            name: *const ::std::os::raw::c_char,
                            numOptions: ::std::os::raw::c_uint,
                            options: *mut CUjit_option,
                            optionValues: *mut *mut ::std::os::raw::c_void)
                            -> CUresult;
}
extern "C" {
    pub fn cuLinkAddFile_v2(state: CUlinkState,
                            type_: CUjitInputType,
                            path: *const ::std::os::raw::c_char,
                            numOptions: ::std::os::raw::c_uint,
                            options: *mut CUjit_option,
                            optionValues: *mut *mut ::std::os::raw::c_void)
                            -> CUresult;
}
extern "C" {
    /// \brief Complete a pending linker invocation
    ///
    /// Completes the pending linker action and returns the cubin image for the linked
    /// device code, which can be used with ::cuModuleLoadData.  The cubin is owned by
    /// \p state, so it should be loaded before \p state is destroyed via ::cuLinkDestroy.
    /// This call does not destroy \p state.
    ///
    /// \param state    A pending linker invocation
    /// \param cubinOut On success, this will point to the output image
    /// \param sizeOut  Optional parameter to receive the size of the generated image
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    ///
    /// \sa ::cuLinkCreate,
    /// ::cuLinkAddData,
    /// ::cuLinkAddFile,
    /// ::cuLinkDestroy,
    /// ::cuModuleLoadData
    ///
    pub fn cuLinkComplete(state: CUlinkState,
                          cubinOut: *mut *mut ::std::os::raw::c_void,
                          sizeOut: *mut usize)
                          -> CUresult;
}
extern "C" {
    /// \brief Destroys state for a JIT linker invocation.
    ///
    /// \param state State object for the linker invocation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE
    ///
    /// \sa ::cuLinkCreate
    ///
    pub fn cuLinkDestroy(state: CUlinkState) -> CUresult;
}
extern "C" {
    pub fn cuMemGetInfo_v2(free: *mut usize, total: *mut usize) -> CUresult;
}
extern "C" {
    pub fn cuMemAlloc_v2(dptr: *mut CUdeviceptr, bytesize: usize) -> CUresult;
}
extern "C" {
    pub fn cuMemAllocPitch_v2(dptr: *mut CUdeviceptr,
                              pPitch: *mut usize,
                              WidthInBytes: usize,
                              Height: usize,
                              ElementSizeBytes: ::std::os::raw::c_uint)
                              -> CUresult;
}
extern "C" {
    pub fn cuMemFree_v2(dptr: CUdeviceptr) -> CUresult;
}
extern "C" {
    pub fn cuMemGetAddressRange_v2(pbase: *mut CUdeviceptr,
                                   psize: *mut usize,
                                   dptr: CUdeviceptr)
                                   -> CUresult;
}
extern "C" {
    pub fn cuMemAllocHost_v2(pp: *mut *mut ::std::os::raw::c_void,
                             bytesize: usize)
                             -> CUresult;
}
extern "C" {
    /// \brief Frees page-locked host memory
    ///
    /// Frees the memory space pointed to by \p p, which must have been returned by
    /// a previous call to ::cuMemAllocHost().
    ///
    /// \param p - Pointer to memory to free
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32
    ///
    pub fn cuMemFreeHost(p: *mut ::std::os::raw::c_void) -> CUresult;
}
extern "C" {
    /// \brief Allocates page-locked host memory
    ///
    /// Allocates \p bytesize bytes of host memory that is page-locked and accessible
    /// to the device. The driver tracks the virtual memory ranges allocated with
    /// this function and automatically accelerates calls to functions such as
    /// ::cuMemcpyHtoD(). Since the memory can be accessed directly by the device,
    /// it can be read or written with much higher bandwidth than pageable memory
    /// obtained with functions such as ::malloc(). Allocating excessive amounts of
    /// pinned memory may degrade system performance, since it reduces the amount
    /// of memory available to the system for paging. As a result, this function is
    /// best used sparingly to allocate staging areas for data exchange between
    /// host and device.
    ///
    /// The \p Flags parameter enables different options to be specified that
    /// affect the allocation, as follows.
    ///
    /// - ::CU_MEMHOSTALLOC_PORTABLE: The memory returned by this call will be
    ///   considered as pinned memory by all CUDA contexts, not just the one that
    ///   performed the allocation.
    ///
    /// - ::CU_MEMHOSTALLOC_DEVICEMAP: Maps the allocation into the CUDA address
    ///   space. The device pointer to the memory may be obtained by calling
    ///   ::cuMemHostGetDevicePointer(). This feature is available only on GPUs
    ///   with compute capability greater than or equal to 1.1.
    ///
    /// - ::CU_MEMHOSTALLOC_WRITECOMBINED: Allocates the memory as write-combined
    ///   (WC). WC memory can be transferred across the PCI Express bus more
    ///   quickly on some system configurations, but cannot be read efficiently by
    ///   most CPUs. WC memory is a good option for buffers that will be written by
    ///   the CPU and read by the GPU via mapped pinned memory or host->device
    ///   transfers.
    ///
    /// All of these flags are orthogonal to one another: a developer may allocate
    /// memory that is portable, mapped and/or write-combined with no restrictions.
    ///
    /// The CUDA context must have been created with the ::CU_CTX_MAP_HOST flag in
    /// order for the ::CU_MEMHOSTALLOC_DEVICEMAP flag to have any effect.
    ///
    /// The ::CU_MEMHOSTALLOC_DEVICEMAP flag may be specified on CUDA contexts for
    /// devices that do not support mapped pinned memory. The failure is deferred
    /// to ::cuMemHostGetDevicePointer() because the memory may be mapped into
    /// other CUDA contexts via the ::CU_MEMHOSTALLOC_PORTABLE flag.
    ///
    /// The memory allocated by this function must be freed with ::cuMemFreeHost().
    ///
    /// Note all host memory allocated using ::cuMemHostAlloc() will automatically
    /// be immediately accessible to all contexts on all devices which support unified
    /// addressing (as may be queried using ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING).
    /// Unless the flag ::CU_MEMHOSTALLOC_WRITECOMBINED is specified, the device pointer
    /// that may be used to access this host memory from those contexts is always equal
    /// to the returned host pointer \p *pp.  If the flag ::CU_MEMHOSTALLOC_WRITECOMBINED
    /// is specified, then the function ::cuMemHostGetDevicePointer() must be used
    /// to query the device pointer, even if the context supports unified addressing.
    /// See \ref CUDA_UNIFIED for additional details.
    ///
    /// \param pp       - Returned host pointer to page-locked memory
    /// \param bytesize - Requested allocation size in bytes
    /// \param Flags    - Flags for allocation request
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32
    ///
    pub fn cuMemHostAlloc(pp: *mut *mut ::std::os::raw::c_void,
                          bytesize: usize,
                          Flags: ::std::os::raw::c_uint)
                          -> CUresult;
}
extern "C" {
    pub fn cuMemHostGetDevicePointer_v2(pdptr: *mut CUdeviceptr,
                                        p: *mut ::std::os::raw::c_void,
                                        Flags: ::std::os::raw::c_uint)
                                        -> CUresult;
}
extern "C" {
    /// \brief Passes back flags that were used for a pinned allocation
    ///
    /// Passes back the flags \p pFlags that were specified when allocating
    /// the pinned host buffer \p p allocated by ::cuMemHostAlloc.
    ///
    /// ::cuMemHostGetFlags() will fail if the pointer does not reside in
    /// an allocation performed by ::cuMemAllocHost() or ::cuMemHostAlloc().
    ///
    /// \param pFlags - Returned flags word
    /// \param p     - Host pointer
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuMemAllocHost, ::cuMemHostAlloc
    ///
    pub fn cuMemHostGetFlags(pFlags: *mut ::std::os::raw::c_uint,
                             p: *mut ::std::os::raw::c_void)
                             -> CUresult;
}
extern "C" {
    /// \brief Allocates memory that will be automatically managed by the Unified Memory system
    ///
    /// Allocates \p bytesize bytes of managed memory on the device and returns in
    /// \p *dptr a pointer to the allocated memory. If the device doesn't support
    /// allocating managed memory, ::CUDA_ERROR_NOT_SUPPORTED is returned. Support
    /// for managed memory can be queried using the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY. The allocated memory is suitably
    /// aligned for any kind of variable. The memory is not cleared. If \p bytesize
    /// is 0, ::cuMemAllocManaged returns ::CUDA_ERROR_INVALID_VALUE. The pointer
    /// is valid on the CPU and on all GPUs in the system that support managed memory.
    /// All accesses to this pointer must obey the Unified Memory programming model.
    ///
    /// \p flags specifies the default stream association for this allocation.
    /// \p flags must be one of ::CU_MEM_ATTACH_GLOBAL or ::CU_MEM_ATTACH_HOST. If
    /// ::CU_MEM_ATTACH_GLOBAL is specified, then this memory is accessible from
    /// any stream on any device. If ::CU_MEM_ATTACH_HOST is specified, then the
    /// allocation should not be accessed from devices that have a zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS; an explicit call to
    /// ::cuStreamAttachMemAsync will be required to enable access on such devices.
    ///
    /// If the association is later changed via ::cuStreamAttachMemAsync to
    /// a single stream, the default association as specifed during ::cuMemAllocManaged
    /// is restored when that stream is destroyed. For __managed__ variables, the
    /// default association is always ::CU_MEM_ATTACH_GLOBAL. Note that destroying a
    /// stream is an asynchronous operation, and as a result, the change to default
    /// association won't happen until all work in the stream has completed.
    ///
    /// Memory allocated with ::cuMemAllocManaged should be released with ::cuMemFree.
    ///
    /// Device memory oversubscription is possible for GPUs that have a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS. Managed memory on
    /// such GPUs may be evicted from device memory to host memory at any time by the Unified
    /// Memory driver in order to make room for other allocations.
    ///
    /// In a multi-GPU system where all GPUs have a non-zero value for the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS, managed memory may not be populated when this
    /// API returns and instead may be populated on access. In such systems, managed memory can
    /// migrate to any processor's memory at any time. The Unified Memory driver will employ heuristics to
    /// maintain data locality and prevent excessive page faults to the extent possible. The application
    /// can also guide the driver about memory usage patterns via ::cuMemAdvise. The application
    /// can also explicitly migrate memory to a desired processor's memory via
    /// ::cuMemPrefetchAsync.
    ///
    /// In a multi-GPU system where all of the GPUs have a zero value for the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS and all the GPUs have peer-to-peer support
    /// with each other, the physical storage for managed memory is created on the GPU which is active
    /// at the time ::cuMemAllocManaged is called. All other GPUs will reference the data at reduced
    /// bandwidth via peer mappings over the PCIe bus. The Unified Memory driver does not migrate
    /// memory among such GPUs.
    ///
    /// In a multi-GPU system where not all GPUs have peer-to-peer support with each other and
    /// where the value of the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS
    /// is zero for at least one of those GPUs, the location chosen for physical storage of managed
    /// memory is system-dependent.
    /// - On Linux, the location chosen will be device memory as long as the current set of active
    /// contexts are on devices that either have peer-to-peer support with each other or have a
    /// non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// If there is an active context on a GPU that does not have a non-zero value for that device
    /// attribute and it does not have peer-to-peer support with the other devices that have active
    /// contexts on them, then the location for physical storage will be 'zero-copy' or host memory.
    /// Note that this means that managed memory that is located in device memory is migrated to
    /// host memory if a new context is created on a GPU that doesn't have a non-zero value for
    /// the device attribute and does not support peer-to-peer with at least one of the other devices
    /// that has an active context. This in turn implies that context creation may fail if there is
    /// insufficient host memory to migrate all managed allocations.
    /// - On Windows, the physical storage is always created in 'zero-copy' or host memory.
    /// All GPUs will reference the data at reduced bandwidth over the PCIe bus. In these
    /// circumstances, use of the environment variable CUDA_VISIBLE_DEVICES is recommended to
    /// restrict CUDA to only use those GPUs that have peer-to-peer support.
    /// Alternatively, users can also set CUDA_MANAGED_FORCE_DEVICE_ALLOC to a
    /// non-zero value to force the driver to always use device memory for physical storage.
    /// When this environment variable is set to a non-zero value, all contexts created in
    /// that process on devices that support managed memory have to be peer-to-peer compatible
    /// with each other. Context creation will fail if a context is created on a device that
    /// supports managed memory and is not peer-to-peer compatible with any of the other
    /// managed memory supporting devices on which contexts were previously created, even if
    /// those contexts have been destroyed. These environment variables are described
    /// in the CUDA programming guide under the "CUDA environment variables" section.
    ///
    /// \param dptr     - Returned device pointer
    /// \param bytesize - Requested allocation size in bytes
    /// \param flags    - Must be one of ::CU_MEM_ATTACH_GLOBAL or ::CU_MEM_ATTACH_HOST
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_NOT_SUPPORTED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32,
    /// ::cuDeviceGetAttribute, ::cuStreamAttachMemAsync
    ///
    pub fn cuMemAllocManaged(dptr: *mut CUdeviceptr,
                             bytesize: usize,
                             flags: ::std::os::raw::c_uint)
                             -> CUresult;
}
extern "C" {
    /// \brief Returns a handle to a compute device
    ///
    /// Returns in \p *device a device handle given a PCI bus ID string.
    ///
    /// \param dev      - Returned device handle
    ///
    /// \param pciBusId - String in one of the following forms:
    /// [domain]:[bus]:[device].[function]
    /// [domain]:[bus]:[device]
    /// [bus]:[device].[function]
    /// where \p domain, \p bus, \p device, and \p function are all hexadecimal values
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuDeviceGet, ::cuDeviceGetAttribute, ::cuDeviceGetPCIBusId
    ///
    pub fn cuDeviceGetByPCIBusId(dev: *mut CUdevice,
                                 pciBusId: *const ::std::os::raw::c_char)
                                 -> CUresult;
}
extern "C" {
    /// \brief Returns a PCI Bus Id string for the device
    ///
    /// Returns an ASCII string identifying the device \p dev in the NULL-terminated
    /// string pointed to by \p pciBusId. \p len specifies the maximum length of the
    /// string that may be returned.
    ///
    /// \param pciBusId - Returned identifier string for the device in the following format
    /// [domain]:[bus]:[device].[function]
    /// where \p domain, \p bus, \p device, and \p function are all hexadecimal values.
    /// pciBusId should be large enough to store 13 characters including the NULL-terminator.
    ///
    /// \param len      - Maximum length of string to store in \p name
    ///
    /// \param dev      - Device to get identifier string for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuDeviceGet, ::cuDeviceGetAttribute, ::cuDeviceGetByPCIBusId
    ///
    pub fn cuDeviceGetPCIBusId(pciBusId: *mut ::std::os::raw::c_char,
                               len: ::std::os::raw::c_int,
                               dev: CUdevice)
                               -> CUresult;
}
extern "C" {
    /// \brief Gets an interprocess handle for a previously allocated event
    ///
    /// Takes as input a previously allocated event. This event must have been
    /// created with the ::CU_EVENT_INTERPROCESS and ::CU_EVENT_DISABLE_TIMING
    /// flags set. This opaque handle may be copied into other processes and
    /// opened with ::cuIpcOpenEventHandle to allow efficient hardware
    /// synchronization between GPU work in different processes.
    ///
    /// After the event has been opened in the importing process,
    /// ::cuEventRecord, ::cuEventSynchronize, ::cuStreamWaitEvent and
    /// ::cuEventQuery may be used in either process. Performing operations
    /// on the imported event after the exported event has been freed
    /// with ::cuEventDestroy will result in undefined behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux operating systems.
    ///
    /// \param pHandle - Pointer to a user allocated CUipcEventHandle
    ///                    in which to return the opaque event handle
    /// \param event   - Event allocated with ::CU_EVENT_INTERPROCESS and
    ///                    ::CU_EVENT_DISABLE_TIMING flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_MAP_FAILED
    ///
    /// \sa
    /// ::cuEventCreate,
    /// ::cuEventDestroy,
    /// ::cuEventSynchronize,
    /// ::cuEventQuery,
    /// ::cuStreamWaitEvent,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle
    ///
    pub fn cuIpcGetEventHandle(pHandle: *mut CUipcEventHandle,
                               event: CUevent)
                               -> CUresult;
}
extern "C" {
    /// \brief Opens an interprocess event handle for use in the current process
    ///
    /// Opens an interprocess event handle exported from another process with
    /// ::cuIpcGetEventHandle. This function returns a ::CUevent that behaves like
    /// a locally created event with the ::CU_EVENT_DISABLE_TIMING flag specified.
    /// This event must be freed with ::cuEventDestroy.
    ///
    /// Performing operations on the imported event after the exported event has
    /// been freed with ::cuEventDestroy will result in undefined behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux operating systems.
    ///
    /// \param phEvent - Returns the imported event
    /// \param handle  - Interprocess handle to open
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED,
    /// ::CUDA_ERROR_INVALID_HANDLE
    ///
    /// \sa
    /// ::cuEventCreate,
    /// ::cuEventDestroy,
    /// ::cuEventSynchronize,
    /// ::cuEventQuery,
    /// ::cuStreamWaitEvent,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle
    ///
    pub fn cuIpcOpenEventHandle(phEvent: *mut CUevent,
                                handle: CUipcEventHandle)
                                -> CUresult;
}
extern "C" {
    /// \brief Gets an interprocess memory handle for an existing device memory
    /// allocation
    ///
    /// Takes a pointer to the base of an existing device memory allocation created
    /// with ::cuMemAlloc and exports it for use in another process. This is a
    /// lightweight operation and may be called multiple times on an allocation
    /// without adverse effects.
    ///
    /// If a region of memory is freed with ::cuMemFree and a subsequent call
    /// to ::cuMemAlloc returns memory with the same device address,
    /// ::cuIpcGetMemHandle will return a unique handle for the
    /// new memory.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux operating systems.
    ///
    /// \param pHandle - Pointer to user allocated ::CUipcMemHandle to return
    ///                    the handle in.
    /// \param dptr    - Base pointer to previously allocated device memory
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_MAP_FAILED,
    ///
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcOpenMemHandle,
    /// ::cuIpcCloseMemHandle
    ///
    pub fn cuIpcGetMemHandle(pHandle: *mut CUipcMemHandle,
                             dptr: CUdeviceptr)
                             -> CUresult;
}
extern "C" {
    /// \brief Opens an interprocess memory handle exported from another process
    /// and returns a device pointer usable in the local process.
    ///
    /// Maps memory exported from another process with ::cuIpcGetMemHandle into
    /// the current device address space. For contexts on different devices
    /// ::cuIpcOpenMemHandle can attempt to enable peer access between the
    /// devices as if the user called ::cuCtxEnablePeerAccess. This behavior is
    /// controlled by the ::CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS flag.
    /// ::cuDeviceCanAccessPeer can determine if a mapping is possible.
    ///
    /// Contexts that may open ::CUipcMemHandles are restricted in the following way.
    /// ::CUipcMemHandles from each ::CUdevice in a given process may only be opened
    /// by one ::CUcontext per ::CUdevice per other process.
    ///
    /// Memory returned from ::cuIpcOpenMemHandle must be freed with
    /// ::cuIpcCloseMemHandle.
    ///
    /// Calling ::cuMemFree on an exported memory region before calling
    /// ::cuIpcCloseMemHandle in the importing context will result in undefined
    /// behavior.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux operating systems.
    ///
    /// \param pdptr  - Returned device pointer
    /// \param handle - ::CUipcMemHandle to open
    /// \param Flags  - Flags for this operation. Must be specified as ::CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_TOO_MANY_PEERS
    ///
    /// \note No guarantees are made about the address returned in \p *pdptr.
    /// In particular, multiple processes may not receive the same address for the same \p handle.
    ///
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcCloseMemHandle,
    /// ::cuCtxEnablePeerAccess,
    /// ::cuDeviceCanAccessPeer,
    ///
    pub fn cuIpcOpenMemHandle(pdptr: *mut CUdeviceptr,
                              handle: CUipcMemHandle,
                              Flags: ::std::os::raw::c_uint)
                              -> CUresult;
}
extern "C" {
    /// \brief Close memory mapped with ::cuIpcOpenMemHandle
    ///
    /// Unmaps memory returnd by ::cuIpcOpenMemHandle. The original allocation
    /// in the exporting process as well as imported mappings in other processes
    /// will be unaffected.
    ///
    /// Any resources used to enable peer access will be freed if this is the
    /// last mapping using them.
    ///
    /// IPC functionality is restricted to devices with support for unified
    /// addressing on Linux operating systems.
    ///
    /// \param dptr - Device pointer returned by ::cuIpcOpenMemHandle
    ///
    /// \returns
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_MAP_FAILED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    ///
    /// \sa
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuIpcGetEventHandle,
    /// ::cuIpcOpenEventHandle,
    /// ::cuIpcGetMemHandle,
    /// ::cuIpcOpenMemHandle,
    ///
    pub fn cuIpcCloseMemHandle(dptr: CUdeviceptr) -> CUresult;
}
extern "C" {
    pub fn cuMemHostRegister_v2(p: *mut ::std::os::raw::c_void,
                                bytesize: usize,
                                Flags: ::std::os::raw::c_uint)
                                -> CUresult;
}
extern "C" {
    /// \brief Unregisters a memory range that was registered with cuMemHostRegister.
    ///
    /// Unmaps the memory range whose base address is specified by \p p, and makes
    /// it pageable again.
    ///
    /// The base address must be the same one specified to ::cuMemHostRegister().
    ///
    /// \param p - Host pointer to memory to unregister
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED,
    /// \notefnerr
    ///
    /// \sa ::cuMemHostRegister
    ///
    pub fn cuMemHostUnregister(p: *mut ::std::os::raw::c_void) -> CUresult;
}
extern "C" {
    /// \brief Copies memory
    ///
    /// Copies data between two pointers.
    /// \p dst and \p src are base pointers of the destination and source, respectively.
    /// \p ByteCount specifies the number of bytes to copy.
    /// Note that this function infers the type of the transfer (host to host, host to
    ///   device, device to device, or device to host) from the pointer values.  This
    ///   function is only allowed in contexts which support unified addressing.
    ///
    /// \param dst - Destination unified virtual address space pointer
    /// \param src - Source unified virtual address space pointer
    /// \param ByteCount - Size of memory copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32
    ///
    pub fn cuMemcpy(dst: CUdeviceptr,
                    src: CUdeviceptr,
                    ByteCount: usize)
                    -> CUresult;
}
extern "C" {
    /// \brief Copies device memory between two contexts
    ///
    /// Copies from device memory in one context to device memory in another
    /// context. \p dstDevice is the base device pointer of the destination memory
    /// and \p dstContext is the destination context.  \p srcDevice is the base
    /// device pointer of the source memory and \p srcContext is the source pointer.
    /// \p ByteCount specifies the number of bytes to copy.
    ///
    /// \param dstDevice  - Destination device pointer
    /// \param dstContext - Destination context
    /// \param srcDevice  - Source device pointer
    /// \param srcContext - Source context
    /// \param ByteCount  - Size of memory copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpy3DPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync
    ///
    pub fn cuMemcpyPeer(dstDevice: CUdeviceptr,
                        dstContext: CUcontext,
                        srcDevice: CUdeviceptr,
                        srcContext: CUcontext,
                        ByteCount: usize)
                        -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoD_v2(dstDevice: CUdeviceptr,
                           srcHost: *const ::std::os::raw::c_void,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoH_v2(dstHost: *mut ::std::os::raw::c_void,
                           srcDevice: CUdeviceptr,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoD_v2(dstDevice: CUdeviceptr,
                           srcDevice: CUdeviceptr,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoA_v2(dstArray: CUarray,
                           dstOffset: usize,
                           srcDevice: CUdeviceptr,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoD_v2(dstDevice: CUdeviceptr,
                           srcArray: CUarray,
                           srcOffset: usize,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoA_v2(dstArray: CUarray,
                           dstOffset: usize,
                           srcHost: *const ::std::os::raw::c_void,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoH_v2(dstHost: *mut ::std::os::raw::c_void,
                           srcArray: CUarray,
                           srcOffset: usize,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoA_v2(dstArray: CUarray,
                           dstOffset: usize,
                           srcArray: CUarray,
                           srcOffset: usize,
                           ByteCount: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2D_v2(pCopy: *const CUDA_MEMCPY2D) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2DUnaligned_v2(pCopy: *const CUDA_MEMCPY2D) -> CUresult;
}
extern "C" {
    pub fn cuMemcpy3D_v2(pCopy: *const CUDA_MEMCPY3D) -> CUresult;
}
extern "C" {
    /// \brief Copies memory between contexts
    ///
    /// Perform a 3D memory copy according to the parameters specified in
    /// \p pCopy.  See the definition of the ::CUDA_MEMCPY3D_PEER structure
    /// for documentation of its parameters.
    ///
    /// \param pCopy - Parameters for the memory copy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_sync
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync
    ///
    pub fn cuMemcpy3DPeer(pCopy: *const CUDA_MEMCPY3D_PEER) -> CUresult;
}
extern "C" {
    /// \brief Copies memory asynchronously
    ///
    /// Copies data between two pointers.
    /// \p dst and \p src are base pointers of the destination and source, respectively.
    /// \p ByteCount specifies the number of bytes to copy.
    /// Note that this function infers the type of the transfer (host to host, host to
    ///   device, device to device, or device to host) from the pointer values.  This
    ///   function is only allowed in contexts which support unified addressing.
    ///
    /// \param dst       - Destination unified virtual address space pointer
    /// \param src       - Source unified virtual address space pointer
    /// \param ByteCount - Size of memory copy in bytes
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemcpyAsync(dst: CUdeviceptr,
                         src: CUdeviceptr,
                         ByteCount: usize,
                         hStream: CUstream)
                         -> CUresult;
}
extern "C" {
    /// \brief Copies device memory between two contexts asynchronously.
    ///
    /// Copies from device memory in one context to device memory in another
    /// context. \p dstDevice is the base device pointer of the destination memory
    /// and \p dstContext is the destination context.  \p srcDevice is the base
    /// device pointer of the source memory and \p srcContext is the source pointer.
    /// \p ByteCount specifies the number of bytes to copy.
    ///
    /// \param dstDevice  - Destination device pointer
    /// \param dstContext - Destination context
    /// \param srcDevice  - Source device pointer
    /// \param srcContext - Source context
    /// \param ByteCount  - Size of memory copy in bytes
    /// \param hStream    - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpy3DPeer, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpy3DPeerAsync
    ///
    pub fn cuMemcpyPeerAsync(dstDevice: CUdeviceptr,
                             dstContext: CUcontext,
                             srcDevice: CUdeviceptr,
                             srcContext: CUcontext,
                             ByteCount: usize,
                             hStream: CUstream)
                             -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoDAsync_v2(dstDevice: CUdeviceptr,
                                srcHost: *const ::std::os::raw::c_void,
                                ByteCount: usize,
                                hStream: CUstream)
                                -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoHAsync_v2(dstHost: *mut ::std::os::raw::c_void,
                                srcDevice: CUdeviceptr,
                                ByteCount: usize,
                                hStream: CUstream)
                                -> CUresult;
}
extern "C" {
    pub fn cuMemcpyDtoDAsync_v2(dstDevice: CUdeviceptr,
                                srcDevice: CUdeviceptr,
                                ByteCount: usize,
                                hStream: CUstream)
                                -> CUresult;
}
extern "C" {
    pub fn cuMemcpyHtoAAsync_v2(dstArray: CUarray,
                                dstOffset: usize,
                                srcHost: *const ::std::os::raw::c_void,
                                ByteCount: usize,
                                hStream: CUstream)
                                -> CUresult;
}
extern "C" {
    pub fn cuMemcpyAtoHAsync_v2(dstHost: *mut ::std::os::raw::c_void,
                                srcArray: CUarray,
                                srcOffset: usize,
                                ByteCount: usize,
                                hStream: CUstream)
                                -> CUresult;
}
extern "C" {
    pub fn cuMemcpy2DAsync_v2(pCopy: *const CUDA_MEMCPY2D,
                              hStream: CUstream)
                              -> CUresult;
}
extern "C" {
    pub fn cuMemcpy3DAsync_v2(pCopy: *const CUDA_MEMCPY3D,
                              hStream: CUstream)
                              -> CUresult;
}
extern "C" {
    /// \brief Copies memory between contexts asynchronously.
    ///
    /// Perform a 3D memory copy according to the parameters specified in
    /// \p pCopy.  See the definition of the ::CUDA_MEMCPY3D_PEER structure
    /// for documentation of its parameters.
    ///
    /// \param pCopy - Parameters for the memory copy
    /// \param hStream - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpyDtoD, ::cuMemcpyPeer, ::cuMemcpyDtoDAsync, ::cuMemcpyPeerAsync,
    /// ::cuMemcpy3DPeerAsync
    ///
    pub fn cuMemcpy3DPeerAsync(pCopy: *const CUDA_MEMCPY3D_PEER,
                               hStream: CUstream)
                               -> CUresult;
}
extern "C" {
    pub fn cuMemsetD8_v2(dstDevice: CUdeviceptr,
                         uc: ::std::os::raw::c_uchar,
                         N: usize)
                         -> CUresult;
}
extern "C" {
    pub fn cuMemsetD16_v2(dstDevice: CUdeviceptr,
                          us: ::std::os::raw::c_ushort,
                          N: usize)
                          -> CUresult;
}
extern "C" {
    pub fn cuMemsetD32_v2(dstDevice: CUdeviceptr,
                          ui: ::std::os::raw::c_uint,
                          N: usize)
                          -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D8_v2(dstDevice: CUdeviceptr,
                           dstPitch: usize,
                           uc: ::std::os::raw::c_uchar,
                           Width: usize,
                           Height: usize)
                           -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D16_v2(dstDevice: CUdeviceptr,
                            dstPitch: usize,
                            us: ::std::os::raw::c_ushort,
                            Width: usize,
                            Height: usize)
                            -> CUresult;
}
extern "C" {
    pub fn cuMemsetD2D32_v2(dstDevice: CUdeviceptr,
                            dstPitch: usize,
                            ui: ::std::os::raw::c_uint,
                            Width: usize,
                            Height: usize)
                            -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 8-bit values to the specified value
    /// \p uc.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param uc        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemsetD8Async(dstDevice: CUdeviceptr,
                           uc: ::std::os::raw::c_uchar,
                           N: usize,
                           hStream: CUstream)
                           -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 16-bit values to the specified value
    /// \p us. The \p dstDevice pointer must be two byte aligned.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param us        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemsetD16Async(dstDevice: CUdeviceptr,
                            us: ::std::os::raw::c_ushort,
                            N: usize,
                            hStream: CUstream)
                            -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the memory range of \p N 32-bit values to the specified value
    /// \p ui. The \p dstDevice pointer must be four byte aligned.
    ///
    /// \param dstDevice - Destination device pointer
    /// \param ui        - Value to set
    /// \param N         - Number of elements
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async, ::cuMemsetD32
    ///
    pub fn cuMemsetD32Async(dstDevice: CUdeviceptr,
                            ui: ::std::os::raw::c_uint,
                            N: usize,
                            hStream: CUstream)
                            -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 8-bit values to the specified value
    /// \p uc. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param uc        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemsetD2D8Async(dstDevice: CUdeviceptr,
                             dstPitch: usize,
                             uc: ::std::os::raw::c_uchar,
                             Width: usize,
                             Height: usize,
                             hStream: CUstream)
                             -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 16-bit values to the specified value
    /// \p us. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. The \p dstDevice pointer
    /// and \p dstPitch offset must be two byte aligned. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param us        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D32, ::cuMemsetD2D32Async,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemsetD2D16Async(dstDevice: CUdeviceptr,
                              dstPitch: usize,
                              us: ::std::os::raw::c_ushort,
                              Width: usize,
                              Height: usize,
                              hStream: CUstream)
                              -> CUresult;
}
extern "C" {
    /// \brief Sets device memory
    ///
    /// Sets the 2D memory range of \p Width 32-bit values to the specified value
    /// \p ui. \p Height specifies the number of rows to set, and \p dstPitch
    /// specifies the number of bytes between each row. The \p dstDevice pointer
    /// and \p dstPitch offset must be four byte aligned. This function performs
    /// fastest when the pitch is one that has been passed back by
    /// ::cuMemAllocPitch().
    ///
    /// \param dstDevice - Destination device pointer
    /// \param dstPitch  - Pitch of destination device pointer
    /// \param ui        - Value to set
    /// \param Width     - Width of row
    /// \param Height    - Number of rows
    /// \param hStream   - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    /// \note_memset
    /// \note_null_stream
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayDestroy, ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D8Async,
    /// ::cuMemsetD2D16, ::cuMemsetD2D16Async, ::cuMemsetD2D32,
    /// ::cuMemsetD8, ::cuMemsetD8Async, ::cuMemsetD16, ::cuMemsetD16Async,
    /// ::cuMemsetD32, ::cuMemsetD32Async
    ///
    pub fn cuMemsetD2D32Async(dstDevice: CUdeviceptr,
                              dstPitch: usize,
                              ui: ::std::os::raw::c_uint,
                              Width: usize,
                              Height: usize,
                              hStream: CUstream)
                              -> CUresult;
}
extern "C" {
    pub fn cuArrayCreate_v2(pHandle: *mut CUarray,
                            pAllocateArray: *const CUDA_ARRAY_DESCRIPTOR)
                            -> CUresult;
}
extern "C" {
    pub fn cuArrayGetDescriptor_v2(pArrayDescriptor:
                                       *mut CUDA_ARRAY_DESCRIPTOR,
                                   hArray: CUarray) -> CUresult;
}
extern "C" {
    /// \brief Destroys a CUDA array
    ///
    /// Destroys the CUDA array \p hArray.
    ///
    /// \param hArray - Array to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ARRAY_IS_MAPPED
    /// \notefnerr
    ///
    /// \sa ::cuArray3DCreate, ::cuArray3DGetDescriptor, ::cuArrayCreate,
    /// ::cuArrayGetDescriptor, ::cuMemAlloc, ::cuMemAllocHost,
    /// ::cuMemAllocPitch, ::cuMemcpy2D, ::cuMemcpy2DAsync, ::cuMemcpy2DUnaligned,
    /// ::cuMemcpy3D, ::cuMemcpy3DAsync, ::cuMemcpyAtoA, ::cuMemcpyAtoD,
    /// ::cuMemcpyAtoH, ::cuMemcpyAtoHAsync, ::cuMemcpyDtoA, ::cuMemcpyDtoD, ::cuMemcpyDtoDAsync,
    /// ::cuMemcpyDtoH, ::cuMemcpyDtoHAsync, ::cuMemcpyHtoA, ::cuMemcpyHtoAAsync,
    /// ::cuMemcpyHtoD, ::cuMemcpyHtoDAsync, ::cuMemFree, ::cuMemFreeHost,
    /// ::cuMemGetAddressRange, ::cuMemGetInfo, ::cuMemHostAlloc,
    /// ::cuMemHostGetDevicePointer, ::cuMemsetD2D8, ::cuMemsetD2D16,
    /// ::cuMemsetD2D32, ::cuMemsetD8, ::cuMemsetD16, ::cuMemsetD32
    ///
    pub fn cuArrayDestroy(hArray: CUarray) -> CUresult;
}
extern "C" {
    pub fn cuArray3DCreate_v2(pHandle: *mut CUarray,
                              pAllocateArray: *const CUDA_ARRAY3D_DESCRIPTOR)
                              -> CUresult;
}
extern "C" {
    pub fn cuArray3DGetDescriptor_v2(pArrayDescriptor:
                                         *mut CUDA_ARRAY3D_DESCRIPTOR,
                                     hArray: CUarray) -> CUresult;
}
extern "C" {
    /// \brief Creates a CUDA mipmapped array
    ///
    /// Creates a CUDA mipmapped array according to the ::CUDA_ARRAY3D_DESCRIPTOR structure
    /// \p pMipmappedArrayDesc and returns a handle to the new CUDA mipmapped array in \p *pHandle.
    /// \p numMipmapLevels specifies the number of mipmap levels to be allocated. This value is
    /// clamped to the range [1, 1 + floor(log2(max(width, height, depth)))].
    ///
    /// The ::CUDA_ARRAY3D_DESCRIPTOR is defined as:
    ///
    /// \code
    /// typedef struct {
    /// unsigned int Width;
    /// unsigned int Height;
    /// unsigned int Depth;
    /// CUarray_format Format;
    /// unsigned int NumChannels;
    /// unsigned int Flags;
    /// } CUDA_ARRAY3D_DESCRIPTOR;
    /// \endcode
    /// where:
    ///
    /// - \p Width, \p Height, and \p Depth are the width, height, and depth of the
    /// CUDA array (in elements); the following types of CUDA arrays can be allocated:
    ///     - A 1D mipmapped array is allocated if \p Height and \p Depth extents are both zero.
    ///     - A 2D mipmapped array is allocated if only \p Depth extent is zero.
    ///     - A 3D mipmapped array is allocated if all three extents are non-zero.
    ///     - A 1D layered CUDA mipmapped array is allocated if only \p Height is zero and the
    ///       ::CUDA_ARRAY3D_LAYERED flag is set. Each layer is a 1D array. The number
    ///       of layers is determined by the depth extent.
    ///     - A 2D layered CUDA mipmapped array is allocated if all three extents are non-zero and
    ///       the ::CUDA_ARRAY3D_LAYERED flag is set. Each layer is a 2D array. The number
    ///       of layers is determined by the depth extent.
    ///     - A cubemap CUDA mipmapped array is allocated if all three extents are non-zero and the
    ///       ::CUDA_ARRAY3D_CUBEMAP flag is set. \p Width must be equal to \p Height, and
    ///       \p Depth must be six. A cubemap is a special type of 2D layered CUDA array,
    ///       where the six layers represent the six faces of a cube. The order of the six
    ///       layers in memory is the same as that listed in ::CUarray_cubemap_face.
    ///     - A cubemap layered CUDA mipmapped array is allocated if all three extents are non-zero,
    ///       and both, ::CUDA_ARRAY3D_CUBEMAP and ::CUDA_ARRAY3D_LAYERED flags are set.
    ///       \p Width must be equal to \p Height, and \p Depth must be a multiple of six.
    ///       A cubemap layered CUDA array is a special type of 2D layered CUDA array that
    ///       consists of a collection of cubemaps. The first six layers represent the first
    ///       cubemap, the next six layers form the second cubemap, and so on.
    ///
    /// - ::Format specifies the format of the elements; ::CUarray_format is
    /// defined as:
    /// \code
    /// typedef enum CUarray_format_enum {
    /// CU_AD_FORMAT_UNSIGNED_INT8 = 0x01,
    /// CU_AD_FORMAT_UNSIGNED_INT16 = 0x02,
    /// CU_AD_FORMAT_UNSIGNED_INT32 = 0x03,
    /// CU_AD_FORMAT_SIGNED_INT8 = 0x08,
    /// CU_AD_FORMAT_SIGNED_INT16 = 0x09,
    /// CU_AD_FORMAT_SIGNED_INT32 = 0x0a,
    /// CU_AD_FORMAT_HALF = 0x10,
    /// CU_AD_FORMAT_FLOAT = 0x20
    /// } CUarray_format;
    ///  \endcode
    ///
    /// - \p NumChannels specifies the number of packed components per CUDA array
    /// element; it may be 1, 2, or 4;
    ///
    /// - ::Flags may be set to
    ///   - ::CUDA_ARRAY3D_LAYERED to enable creation of layered CUDA mipmapped arrays. If this flag is set,
    ///     \p Depth specifies the number of layers, not the depth of a 3D array.
    ///   - ::CUDA_ARRAY3D_SURFACE_LDST to enable surface references to be bound to individual mipmap levels of
    ///     the CUDA mipmapped array. If this flag is not set, ::cuSurfRefSetArray will fail when attempting to
    ///     bind a mipmap level of the CUDA mipmapped array to a surface reference.
    ///   - ::CUDA_ARRAY3D_CUBEMAP to enable creation of mipmapped cubemaps. If this flag is set, \p Width must be
    ///     equal to \p Height, and \p Depth must be six. If the ::CUDA_ARRAY3D_LAYERED flag is also set,
    ///     then \p Depth must be a multiple of six.
    ///   - ::CUDA_ARRAY3D_TEXTURE_GATHER to indicate that the CUDA mipmapped array will be used for texture gather.
    ///     Texture gather can only be performed on 2D CUDA mipmapped arrays.
    ///
    /// \p Width, \p Height and \p Depth must meet certain size requirements as listed in the following table.
    /// All values are specified in elements. Note that for brevity's sake, the full name of the device attribute
    /// is not specified. For ex., TEXTURE1D_MIPMAPPED_WIDTH refers to the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH.
    ///
    /// <table>
    /// <tr><td><b>CUDA array type</b></td>
    /// <td><b>Valid extents that must always be met<br>{(width range in elements), (height range),
    /// (depth range)}</b></td></tr>
    /// <tr><td>1D</td>
    /// <td><small>{ (1,TEXTURE1D_MIPMAPPED_WIDTH), 0, 0 }</small></td></tr>
    /// <tr><td>2D</td>
    /// <td><small>{ (1,TEXTURE2D_MIPMAPPED_WIDTH), (1,TEXTURE2D_MIPMAPPED_HEIGHT), 0 }</small></td></tr>
    /// <tr><td>3D</td>
    /// <td><small>{ (1,TEXTURE3D_WIDTH), (1,TEXTURE3D_HEIGHT), (1,TEXTURE3D_DEPTH) }
    /// <br>OR<br>{ (1,TEXTURE3D_WIDTH_ALTERNATE), (1,TEXTURE3D_HEIGHT_ALTERNATE),
    /// (1,TEXTURE3D_DEPTH_ALTERNATE) }</small></td></tr>
    /// <tr><td>1D Layered</td>
    /// <td><small>{ (1,TEXTURE1D_LAYERED_WIDTH), 0,
    /// (1,TEXTURE1D_LAYERED_LAYERS) }</small></td></tr>
    /// <tr><td>2D Layered</td>
    /// <td><small>{ (1,TEXTURE2D_LAYERED_WIDTH), (1,TEXTURE2D_LAYERED_HEIGHT),
    /// (1,TEXTURE2D_LAYERED_LAYERS) }</small></td></tr>
    /// <tr><td>Cubemap</td>
    /// <td><small>{ (1,TEXTURECUBEMAP_WIDTH), (1,TEXTURECUBEMAP_WIDTH), 6 }</small></td></tr>
    /// <tr><td>Cubemap Layered</td>
    /// <td><small>{ (1,TEXTURECUBEMAP_LAYERED_WIDTH), (1,TEXTURECUBEMAP_LAYERED_WIDTH),
    /// (1,TEXTURECUBEMAP_LAYERED_LAYERS) }</small></td></tr>
    /// </table>
    ///
    ///
    /// \param pHandle             - Returned mipmapped array
    /// \param pMipmappedArrayDesc - mipmapped array descriptor
    /// \param numMipmapLevels     - Number of mipmap levels
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa ::cuMipmappedArrayDestroy, ::cuMipmappedArrayGetLevel, ::cuArrayCreate,
    ///
    pub fn cuMipmappedArrayCreate(pHandle: *mut CUmipmappedArray,
                                  pMipmappedArrayDesc:
                                      *const CUDA_ARRAY3D_DESCRIPTOR,
                                  numMipmapLevels: ::std::os::raw::c_uint)
     -> CUresult;
}
extern "C" {
    /// \brief Gets a mipmap level of a CUDA mipmapped array
    ///
    /// Returns in \p *pLevelArray a CUDA array that represents a single mipmap level
    /// of the CUDA mipmapped array \p hMipmappedArray.
    ///
    /// If \p level is greater than the maximum number of levels in this mipmapped array,
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// \param pLevelArray     - Returned mipmap level CUDA array
    /// \param hMipmappedArray - CUDA mipmapped array
    /// \param level           - Mipmap level
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuMipmappedArrayCreate, ::cuMipmappedArrayDestroy, ::cuArrayCreate,
    ///
    pub fn cuMipmappedArrayGetLevel(pLevelArray: *mut CUarray,
                                    hMipmappedArray: CUmipmappedArray,
                                    level: ::std::os::raw::c_uint)
                                    -> CUresult;
}
extern "C" {
    /// \brief Destroys a CUDA mipmapped array
    ///
    /// Destroys the CUDA mipmapped array \p hMipmappedArray.
    ///
    /// \param hMipmappedArray - Mipmapped array to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ARRAY_IS_MAPPED
    /// \notefnerr
    ///
    /// \sa ::cuMipmappedArrayCreate, ::cuMipmappedArrayGetLevel, ::cuArrayCreate,
    ///
    pub fn cuMipmappedArrayDestroy(hMipmappedArray: CUmipmappedArray)
                                   -> CUresult;
}
extern "C" {
    /// \brief Returns information about a pointer
    ///
    /// The supported attributes are:
    ///
    /// - ::CU_POINTER_ATTRIBUTE_CONTEXT:
    ///
    ///      Returns in \p *data the ::CUcontext in which \p ptr was allocated or
    ///      registered.
    ///      The type of \p data must be ::CUcontext *.
    ///
    ///      If \p ptr was not allocated by, mapped by, or registered with
    ///      a ::CUcontext which uses unified virtual addressing then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_MEMORY_TYPE:
    ///
    ///      Returns in \p *data the physical memory type of the memory that
    ///      \p ptr addresses as a ::CUmemorytype enumerated value.
    ///      The type of \p data must be unsigned int.
    ///
    ///      If \p ptr addresses device memory then \p *data is set to
    ///      ::CU_MEMORYTYPE_DEVICE.  The particular ::CUdevice on which the
    ///      memory resides is the ::CUdevice of the ::CUcontext returned by the
    ///      ::CU_POINTER_ATTRIBUTE_CONTEXT attribute of \p ptr.
    ///
    ///      If \p ptr addresses host memory then \p *data is set to
    ///      ::CU_MEMORYTYPE_HOST.
    ///
    ///      If \p ptr was not allocated by, mapped by, or registered with
    ///      a ::CUcontext which uses unified virtual addressing then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      If the current ::CUcontext does not support unified virtual
    ///      addressing then ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER:
    ///
    ///      Returns in \p *data the device pointer value through which
    ///      \p ptr may be accessed by kernels running in the current
    ///      ::CUcontext.
    ///      The type of \p data must be CUdeviceptr *.
    ///
    ///      If there exists no device pointer value through which
    ///      kernels running in the current ::CUcontext may access
    ///      \p ptr then ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      If there is no current ::CUcontext then
    ///      ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    ///      Except in the exceptional disjoint addressing cases discussed
    ///      below, the value returned in \p *data will equal the input
    ///      value \p ptr.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_HOST_POINTER:
    ///
    ///      Returns in \p *data the host pointer value through which
    ///      \p ptr may be accessed by by the host program.
    ///      The type of \p data must be void **.
    ///      If there exists no host pointer value through which
    ///      the host program may directly access \p ptr then
    ///      ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    ///      Except in the exceptional disjoint addressing cases discussed
    ///      below, the value returned in \p *data will equal the input
    ///      value \p ptr.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_P2P_TOKENS:
    ///
    ///      Returns in \p *data two tokens for use with the nv-p2p.h Linux
    ///      kernel interface. \p data must be a struct of type
    ///      CUDA_POINTER_ATTRIBUTE_P2P_TOKENS.
    ///
    ///      \p ptr must be a pointer to memory obtained from :cuMemAlloc().
    ///      Note that p2pToken and vaSpaceToken are only valid for the
    ///      lifetime of the source allocation. A subsequent allocation at
    ///      the same address may return completely different tokens.
    ///      Querying this attribute has a side effect of setting the attribute
    ///      ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS for the region of memory that
    ///      \p ptr points to.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS:
    ///
    ///      A boolean attribute which when set, ensures that synchronous memory operations
    ///      initiated on the region of memory that \p ptr points to will always synchronize.
    ///      See further documentation in the section titled "API synchronization behavior"
    ///      to learn more about cases when synchronous memory operations can
    ///      exhibit asynchronous behavior.
    ///
    /// - ::CU_POINTER_ATTRIBUTE_BUFFER_ID:
    ///
    ///      Returns in \p *data a buffer ID which is guaranteed to be unique within the process.
    ///      \p data must point to an unsigned long long.
    ///
    ///      \p ptr must be a pointer to memory obtained from a CUDA memory allocation API.
    ///      Every memory allocation from any of the CUDA memory allocation APIs will
    ///      have a unique ID over a process lifetime. Subsequent allocations do not reuse IDs
    ///      from previous freed allocations. IDs are only unique within a single process.
    ///
    ///
    /// - ::CU_POINTER_ATTRIBUTE_IS_MANAGED:
    ///
    ///      Returns in \p *data a boolean that indicates whether the pointer points to
    ///      managed memory or not.
    ///
    /// \par
    ///
    /// Note that for most allocations in the unified virtual address space
    /// the host and device pointer for accessing the allocation will be the
    /// same.  The exceptions to this are
    ///  - user memory registered using ::cuMemHostRegister
    ///  - host memory allocated using ::cuMemHostAlloc with the
    ///    ::CU_MEMHOSTALLOC_WRITECOMBINED flag
    /// For these types of allocation there will exist separate, disjoint host
    /// and device addresses for accessing the allocation.  In particular
    ///  - The host address will correspond to an invalid unmapped device address
    ///    (which will result in an exception if accessed from the device)
    ///  - The device address will correspond to an invalid unmapped host address
    ///    (which will result in an exception if accessed from the host).
    /// For these types of allocations, querying ::CU_POINTER_ATTRIBUTE_HOST_POINTER
    /// and ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER may be used to retrieve the host
    /// and device addresses from either address.
    ///
    /// \param data      - Returned pointer attribute value
    /// \param attribute - Pointer attribute to query
    /// \param ptr       - Pointer
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa cuPointerSetAttribute,
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuMemAllocHost,
    /// ::cuMemFreeHost,
    /// ::cuMemHostAlloc,
    /// ::cuMemHostRegister,
    /// ::cuMemHostUnregister
    ///
    pub fn cuPointerGetAttribute(data: *mut ::std::os::raw::c_void,
                                 attribute: CUpointer_attribute,
                                 ptr: CUdeviceptr)
                                 -> CUresult;
}
extern "C" {
    /// \brief Prefetches memory to the specified destination device
    ///
    /// Prefetches memory to the specified destination device.  \p devPtr is the
    /// base device pointer of the memory to be prefetched and \p dstDevice is the
    /// destination device. \p count specifies the number of bytes to copy. \p hStream
    /// is the stream in which the operation is enqueued. The memory range must refer
    /// to managed memory allocated via ::cuMemAllocManaged or declared via __managed__ variables.
    ///
    /// Passing in CU_DEVICE_CPU for \p dstDevice will prefetch the data to host memory. If
    /// \p dstDevice is a GPU, then the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS
    /// must be non-zero. Additionally, \p hStream must be associated with a device that has a
    /// non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    ///
    /// The start address and end address of the memory range will be rounded down and rounded up
    /// respectively to be aligned to CPU page size before the prefetch operation is enqueued
    /// in the stream.
    ///
    /// If no physical memory has been allocated for this region, then this memory region
    /// will be populated and mapped on the destination device. If there's insufficient
    /// memory to prefetch the desired region, the Unified Memory driver may evict pages from other
    /// ::cuMemAllocManaged allocations to host memory in order to make room. Device memory
    /// allocated using ::cuMemAlloc or ::cuArrayCreate will not be evicted.
    ///
    /// By default, any mappings to the previous location of the migrated pages are removed and
    /// mappings for the new location are only setup on \p dstDevice. The exact behavior however
    /// also depends on the settings applied to this memory range via ::cuMemAdvise as described
    /// below:
    ///
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY was set on any subset of this memory range,
    /// then that subset will create a read-only copy of the pages on \p dstDevice.
    ///
    /// If ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION was called on any subset of this memory
    /// range, then the pages will be migrated to \p dstDevice even if \p dstDevice is not the
    /// preferred location of any pages in the memory range.
    ///
    /// If ::CU_MEM_ADVISE_SET_ACCESSED_BY was called on any subset of this memory range,
    /// then mappings to those pages from all the appropriate processors are updated to
    /// refer to the new location if establishing such a mapping is possible. Otherwise,
    /// those mappings are cleared.
    ///
    /// Note that this API is not required for functionality and only serves to improve performance
    /// by allowing the application to migrate data to a suitable location before it is accessed.
    /// Memory accesses to this range are always coherent and are allowed even when the data is
    /// actively being migrated.
    ///
    /// Note that this function is asynchronous with respect to the host and all work
    /// on other devices.
    ///
    /// \param devPtr    - Pointer to be prefetched
    /// \param count     - Size in bytes
    /// \param dstDevice - Destination device to prefetch to
    /// \param hStream    - Stream to enqueue prefetch operation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpy, ::cuMemcpyPeer, ::cuMemcpyAsync,
    /// ::cuMemcpy3DPeerAsync, ::cuMemAdvise
    ///
    pub fn cuMemPrefetchAsync(devPtr: CUdeviceptr,
                              count: usize,
                              dstDevice: CUdevice,
                              hStream: CUstream)
                              -> CUresult;
}
extern "C" {
    /// \brief Advise about the usage of a given memory range
    ///
    /// Advise the Unified Memory subsystem about the usage pattern for the memory range
    /// starting at \p devPtr with a size of \p count bytes. The start address and end address of the memory
    /// range will be rounded down and rounded up respectively to be aligned to CPU page size before the
    /// advice is applied. The memory range must refer to managed memory allocated via ::cuMemAllocManaged
    /// or declared via __managed__ variables.
    ///
    /// The \p advice parameter can take the following values:
    /// - ::CU_MEM_ADVISE_SET_READ_MOSTLY: This implies that the data is mostly going to be read
    /// from and only occasionally written to. Any read accesses from any processor to this region will create a
    /// read-only copy of at least the accessed pages in that processor's memory. Additionally, if ::cuMemPrefetchAsync
    /// is called on this region, it will create a read-only copy of the data on the destination processor.
    /// If any processor writes to this region, all copies of the corresponding page will be invalidated
    /// except for the one where the write occurred. The \p device argument is ignored for this advice.
    /// Note that for a page to be read-duplicated, the accessing processor must either be the CPU or a GPU
    /// that has a non-zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// Also, if a context is created on a device that does not have the device attribute
    /// ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS set, then read-duplication will not occur until
    /// all such contexts are destroyed.
    /// - ::CU_MEM_ADVISE_UNSET_READ_MOSTLY:  Undoes the effect of ::CU_MEM_ADVISE_SET_READ_MOSTLY and also prevents the
    /// Unified Memory driver from attempting heuristic read-duplication on the memory range. Any read-duplicated
    /// copies of the data will be collapsed into a single copy. The location for the collapsed
    /// copy will be the preferred location if the page has a preferred location and one of the read-duplicated
    /// copies was resident at that location. Otherwise, the location chosen is arbitrary.
    /// - ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION: This advice sets the preferred location for the
    /// data to be the memory belonging to \p device. Passing in CU_DEVICE_CPU for \p device sets the
    /// preferred location as host memory. If \p device is a GPU, then it must have a non-zero value for the
    /// device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS. Setting the preferred location
    /// does not cause data to migrate to that location immediately. Instead, it guides the migration policy
    /// when a fault occurs on that memory region. If the data is already in its preferred location and the
    /// faulting processor can establish a mapping without requiring the data to be migrated, then
    /// data migration will be avoided. On the other hand, if the data is not in its preferred location
    /// or if a direct mapping cannot be established, then it will be migrated to the processor accessing
    /// it. It is important to note that setting the preferred location does not prevent data prefetching
    /// done using ::cuMemPrefetchAsync.
    /// Having a preferred location can override the page thrash detection and resolution logic in the Unified
    /// Memory driver. Normally, if a page is detected to be constantly thrashing between for example host and device
    /// memory, the page may eventually be pinned to host memory by the Unified Memory driver. But
    /// if the preferred location is set as device memory, then the page will continue to thrash indefinitely.
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
    /// policies associated with that advice will override the policies of this advice.
    /// - ::CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION: Undoes the effect of ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION
    /// and changes the preferred location to none.
    /// - ::CU_MEM_ADVISE_SET_ACCESSED_BY: This advice implies that the data will be accessed by \p device.
    /// Passing in ::CU_DEVICE_CPU for \p device will set the advice for the CPU. If \p device is a GPU, then
    /// the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS must be non-zero.
    /// This advice does not cause data migration and has no impact on the location of the data per se. Instead,
    /// it causes the data to always be mapped in the specified processor's page tables, as long as the
    /// location of the data permits a mapping to be established. If the data gets migrated for any reason,
    /// the mappings are updated accordingly.
    /// This advice is recommended in scenarios where data locality is not important, but avoiding faults is.
    /// Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the
    /// data located on one GPU is occasionally accessed by peer GPUs. In such scenarios, migrating data
    /// over to the other GPUs is not as important because the accesses are infrequent and the overhead of
    /// migration may be too high. But preventing faults can still help improve performance, and so having
    /// a mapping set up in advance is useful. Note that on CPU access of this data, the data may be migrated
    /// to host memory because the CPU typically cannot access device memory directly. Any GPU that had the
    /// ::CU_MEM_ADVISE_SET_ACCESSED_BY flag set for this data will now have its mapping updated to point to the
    /// page in host memory.
    /// If ::CU_MEM_ADVISE_SET_READ_MOSTLY is also set on this memory region or any subset of it, then the
    /// policies associated with that advice will override the policies of this advice. Additionally, if the
    /// preferred location of this memory region or any subset of it is also \p device, then the policies
    /// associated with ::CU_MEM_ADVISE_SET_PREFERRED_LOCATION will override the policies of this advice.
    /// - ::CU_MEM_ADVISE_UNSET_ACCESSED_BY: Undoes the effect of ::CU_MEM_ADVISE_SET_ACCESSED_BY. Any mappings to
    /// the data from \p device may be removed at any time causing accesses to result in non-fatal page faults.
    ///
    /// \param devPtr - Pointer to memory to set the advice for
    /// \param count  - Size in bytes of the memory range
    /// \param advice - Advice to be applied for the specified memory range
    /// \param device - Device to apply the advice for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemcpy, ::cuMemcpyPeer, ::cuMemcpyAsync,
    /// ::cuMemcpy3DPeerAsync, ::cuMemPrefetchAsync
    ///
    pub fn cuMemAdvise(devPtr: CUdeviceptr,
                       count: usize,
                       advice: CUmem_advise,
                       device: CUdevice)
                       -> CUresult;
}
extern "C" {
    /// \brief Query an attribute of a given memory range
    ///
    /// Query an attribute about the memory range starting at \p devPtr with a size of \p count bytes. The
    /// memory range must refer to managed memory allocated via ::cuMemAllocManaged or declared via
    /// __managed__ variables.
    ///
    /// The \p attribute parameter can take the following values:
    /// - ::CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY: If this attribute is specified, \p data will be interpreted
    /// as a 32-bit integer, and \p dataSize must be 4. The result returned will be 1 if all pages in the given
    /// memory range have read-duplication enabled, or 0 otherwise.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION: If this attribute is specified, \p data will be
    /// interpreted as a 32-bit integer, and \p dataSize must be 4. The result returned will be a GPU device
    /// id if all pages in the memory range have that GPU as their preferred location, or it will be CU_DEVICE_CPU
    /// if all pages in the memory range have the CPU as their preferred location, or it will be CU_DEVICE_INVALID
    /// if either all the pages don't have the same preferred location or some of the pages don't have a
    /// preferred location at all. Note that the actual location of the pages in the memory range at the time of
    /// the query may be different from the preferred location.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY: If this attribute is specified, \p data will be interpreted
    /// as an array of 32-bit integers, and \p dataSize must be a non-zero multiple of 4. The result returned
    /// will be a list of device ids that had ::CU_MEM_ADVISE_SET_ACCESSED_BY set for that entire memory range.
    /// If any device does not have that advice set for the entire memory range, that device will not be included.
    /// If \p data is larger than the number of devices that have that advice set for that memory range,
    /// CU_DEVICE_INVALID will be returned in all the extra space provided. For ex., if \p dataSize is 12
    /// (i.e. \p data has 3 elements) and only device 0 has the advice set, then the result returned will be
    /// { 0, CU_DEVICE_INVALID, CU_DEVICE_INVALID }. If \p data is smaller than the number of devices that have
    /// that advice set, then only as many devices will be returned as can fit in the array. There is no
    /// guarantee on which specific devices will be returned, however.
    /// - ::CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION: If this attribute is specified, \p data will be
    /// interpreted as a 32-bit integer, and \p dataSize must be 4. The result returned will be the last location
    /// to which all pages in the memory range were prefetched explicitly via ::cuMemPrefetchAsync. This will either be
    /// a GPU id or CU_DEVICE_CPU depending on whether the last location for prefetch was a GPU or the CPU
    /// respectively. If any page in the memory range was never explicitly prefetched or if all pages were not
    /// prefetched to the same location, CU_DEVICE_INVALID will be returned. Note that this simply returns the
    /// last location that the applicaton requested to prefetch the memory range to. It gives no indication as to
    /// whether the prefetch operation to that location has completed or even begun.
    ///
    /// \param data      - A pointers to a memory location where the result
    ///                    of each attribute query will be written to.
    /// \param dataSize  - Array containing the size of data
    /// \param attribute - The attribute to query
    /// \param devPtr    - Start of the range to query
    /// \param count     - Size of the range to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    /// \note_async
    /// \note_null_stream
    ///
    /// \sa ::cuMemRangeGetAttributes, ::cuMemPrefetchAsync,
    /// ::cuMemAdvise
    ///
    pub fn cuMemRangeGetAttribute(data: *mut ::std::os::raw::c_void,
                                  dataSize: usize,
                                  attribute: CUmem_range_attribute,
                                  devPtr: CUdeviceptr,
                                  count: usize)
                                  -> CUresult;
}
extern "C" {
    /// \brief Query attributes of a given memory range.
    ///
    /// Query attributes of the memory range starting at \p devPtr with a size of \p count bytes. The
    /// memory range must refer to managed memory allocated via ::cuMemAllocManaged or declared via
    /// __managed__ variables. The \p attributes array will be interpreted to have \p numAttributes
    /// entries. The \p dataSizes array will also be interpreted to have \p numAttributes entries.
    /// The results of the query will be stored in \p data.
    ///
    /// The list of supported attributes are given below. Please refer to ::cuMemRangeGetAttribute for
    /// attribute descriptions and restrictions.
    ///
    /// - ::CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY
    /// - ::CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION
    /// - ::CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY
    /// - ::CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION
    ///
    /// \param data          - A two-dimensional array containing pointers to memory
    ///                        locations where the result of each attribute query will be written to.
    /// \param dataSizes     - Array containing the sizes of each result
    /// \param attributes    - An array of attributes to query
    ///                        (numAttributes and the number of attributes in this array should match)
    /// \param numAttributes - Number of attributes to query
    /// \param devPtr        - Start of the range to query
    /// \param count         - Size of the range to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuMemRangeGetAttribute, ::cuMemAdvise
    /// ::cuMemPrefetchAsync
    ///
    pub fn cuMemRangeGetAttributes(data: *mut *mut ::std::os::raw::c_void,
                                   dataSizes: *mut usize,
                                   attributes: *mut CUmem_range_attribute,
                                   numAttributes: usize,
                                   devPtr: CUdeviceptr,
                                   count: usize)
                                   -> CUresult;
}
extern "C" {
    /// \brief Set attributes on a previously allocated memory region
    ///
    /// The supported attributes are:
    ///
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS:
    ///
    ///      A boolean attribute that can either be set (1) or unset (0). When set,
    ///      the region of memory that \p ptr points to is guaranteed to always synchronize
    ///      memory operations that are synchronous. If there are some previously initiated
    ///      synchronous memory operations that are pending when this attribute is set, the
    ///      function does not return until those memory operations are complete.
    ///      See further documentation in the section titled "API synchronization behavior"
    ///      to learn more about cases when synchronous memory operations can
    ///      exhibit asynchronous behavior.
    ///      \p value will be considered as a pointer to an unsigned integer to which this attribute is to be set.
    ///
    /// \param value     - Pointer to memory containing the value to be set
    /// \param attribute - Pointer attribute to set
    /// \param ptr       - Pointer to a memory region allocated using CUDA memory allocation APIs
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuPointerGetAttribute,
    /// ::cuPointerGetAttributes,
    /// ::cuMemAlloc,
    /// ::cuMemFree,
    /// ::cuMemAllocHost,
    /// ::cuMemFreeHost,
    /// ::cuMemHostAlloc,
    /// ::cuMemHostRegister,
    /// ::cuMemHostUnregister
    ///
    pub fn cuPointerSetAttribute(value: *const ::std::os::raw::c_void,
                                 attribute: CUpointer_attribute,
                                 ptr: CUdeviceptr)
                                 -> CUresult;
}
extern "C" {
    /// \brief Returns information about a pointer.
    ///
    /// The supported attributes are (refer to ::cuPointerGetAttribute for attribute descriptions and restrictions):
    ///
    /// - ::CU_POINTER_ATTRIBUTE_CONTEXT
    /// - ::CU_POINTER_ATTRIBUTE_MEMORY_TYPE
    /// - ::CU_POINTER_ATTRIBUTE_DEVICE_POINTER
    /// - ::CU_POINTER_ATTRIBUTE_HOST_POINTER
    /// - ::CU_POINTER_ATTRIBUTE_SYNC_MEMOPS
    /// - ::CU_POINTER_ATTRIBUTE_BUFFER_ID
    /// - ::CU_POINTER_ATTRIBUTE_IS_MANAGED
    ///
    /// \param numAttributes - Number of attributes to query
    /// \param attributes    - An array of attributes to query
    ///                      (numAttributes and the number of attributes in this array should match)
    /// \param data          - A two-dimensional array containing pointers to memory
    ///                      locations where the result of each attribute query will be written to.
    /// \param ptr           - Pointer to query
    ///
    /// Unlike ::cuPointerGetAttribute, this function will not return an error when the \p ptr
    /// encountered is not a valid CUDA pointer. Instead, the attributes are assigned default NULL values
    /// and CUDA_SUCCESS is returned.
    ///
    /// If \p ptr was not allocated by, mapped by, or registered with a ::CUcontext which uses UVA
    /// (Unified Virtual Addressing), ::CUDA_ERROR_INVALID_CONTEXT is returned.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuPointerGetAttribute,
    /// ::cuPointerSetAttribute
    ///
    pub fn cuPointerGetAttributes(numAttributes: ::std::os::raw::c_uint,
                                  attributes: *mut CUpointer_attribute,
                                  data: *mut *mut ::std::os::raw::c_void,
                                  ptr: CUdeviceptr)
                                  -> CUresult;
}
extern "C" {
    /// \brief Create a stream
    ///
    /// Creates a stream and returns a handle in \p phStream.  The \p Flags argument
    /// determines behaviors of the stream.  Valid values for \p Flags are:
    /// - ::CU_STREAM_DEFAULT: Default stream creation flag.
    /// - ::CU_STREAM_NON_BLOCKING: Specifies that work running in the created
    ///   stream may run concurrently with work in stream 0 (the NULL stream), and that
    ///   the created stream should perform no implicit synchronization with stream 0.
    ///
    /// \param phStream - Returned newly created stream
    /// \param Flags    - Parameters for stream creation
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreateWithPriority,
    /// ::cuStreamGetPriority,
    /// ::cuStreamGetFlags,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback
    ///
    pub fn cuStreamCreate(phStream: *mut CUstream,
                          Flags: ::std::os::raw::c_uint)
                          -> CUresult;
}
extern "C" {
    /// \brief Create a stream with the given priority
    ///
    /// Creates a stream with the specified priority and returns a handle in \p phStream.
    /// This API alters the scheduler priority of work in the stream. Work in a higher
    /// priority stream may preempt work already executing in a low priority stream.
    ///
    /// \p priority follows a convention where lower numbers represent higher priorities.
    /// '0' represents default priority. The range of meaningful numerical priorities can
    /// be queried using ::cuCtxGetStreamPriorityRange. If the specified priority is
    /// outside the numerical range returned by ::cuCtxGetStreamPriorityRange,
    /// it will automatically be clamped to the lowest or the highest number in the range.
    ///
    /// \param phStream    - Returned newly created stream
    /// \param flags       - Flags for stream creation. See ::cuStreamCreate for a list of
    ///                      valid flags
    /// \param priority    - Stream priority. Lower numbers represent higher priorities.
    ///                      See ::cuCtxGetStreamPriorityRange for more information about
    ///                      meaningful stream priorities that can be passed.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \note Stream priorities are supported only on Quadro and Tesla GPUs
    /// with compute capability 3.5 or higher.
    ///
    /// \note In the current implementation, only compute kernels launched in
    /// priority streams are affected by the stream's priority. Stream priorities have
    /// no effect on host-to-device and device-to-host memory operations.
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamGetPriority,
    /// ::cuCtxGetStreamPriorityRange,
    /// ::cuStreamGetFlags,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback
    ///
    pub fn cuStreamCreateWithPriority(phStream: *mut CUstream,
                                      flags: ::std::os::raw::c_uint,
                                      priority: ::std::os::raw::c_int)
                                      -> CUresult;
}
extern "C" {
    /// \brief Query the priority of a given stream
    ///
    /// Query the priority of a stream created using ::cuStreamCreate or ::cuStreamCreateWithPriority
    /// and return the priority in \p priority. Note that if the stream was created with a
    /// priority outside the numerical range returned by ::cuCtxGetStreamPriorityRange,
    /// this function returns the clamped priority.
    /// See ::cuStreamCreateWithPriority for details about priority clamping.
    ///
    /// \param hStream    - Handle to the stream to be queried
    /// \param priority   - Pointer to a signed integer in which the stream's priority is returned
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamCreateWithPriority,
    /// ::cuCtxGetStreamPriorityRange,
    /// ::cuStreamGetFlags
    ///
    pub fn cuStreamGetPriority(hStream: CUstream,
                               priority: *mut ::std::os::raw::c_int)
                               -> CUresult;
}
extern "C" {
    /// \brief Query the flags of a given stream
    ///
    /// Query the flags of a stream created using ::cuStreamCreate or ::cuStreamCreateWithPriority
    /// and return the flags in \p flags.
    ///
    /// \param hStream    - Handle to the stream to be queried
    /// \param flags      - Pointer to an unsigned integer in which the stream's flags are returned
    ///                     The value returned in \p flags is a logical 'OR' of all flags that
    ///                     were used while creating this stream. See ::cuStreamCreate for the list
    ///                     of valid flags
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa ::cuStreamDestroy,
    /// ::cuStreamCreate,
    /// ::cuStreamGetPriority
    ///
    pub fn cuStreamGetFlags(hStream: CUstream,
                            flags: *mut ::std::os::raw::c_uint)
                            -> CUresult;
}
extern "C" {
    /// \brief Make a compute stream wait on an event
    ///
    /// Makes all future work submitted to \p hStream wait until \p hEvent
    /// reports completion before beginning execution.  This synchronization
    /// will be performed efficiently on the device.  The event \p hEvent may
    /// be from a different context than \p hStream, in which case this function
    /// will perform cross-device synchronization.
    ///
    /// The stream \p hStream will wait only for the completion of the most recent
    /// host call to ::cuEventRecord() on \p hEvent.  Once this call has returned,
    /// any functions (including ::cuEventRecord() and ::cuEventDestroy()) may be
    /// called on \p hEvent again, and subsequent calls will not have any
    /// effect on \p hStream.
    ///
    /// If ::cuEventRecord() has not been called on \p hEvent, this call acts as if
    /// the record has already completed, and so is a functional no-op.
    ///
    /// \param hStream - Stream to wait
    /// \param hEvent  - Event to wait on (may not be NULL)
    /// \param Flags   - Parameters for the operation (must be 0)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuEventRecord,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback,
    /// ::cuStreamDestroy
    ///
    pub fn cuStreamWaitEvent(hStream: CUstream,
                             hEvent: CUevent,
                             Flags: ::std::os::raw::c_uint)
                             -> CUresult;
}
extern "C" {
    /// \brief Add a callback to a compute stream
    ///
    /// Adds a callback to be called on the host after all currently enqueued
    /// items in the stream have completed.  For each
    /// cuStreamAddCallback call, the callback will be executed exactly once.
    /// The callback will block later work in the stream until it is finished.
    ///
    /// The callback may be passed ::CUDA_SUCCESS or an error code.  In the event
    /// of a device error, all subsequently executed callbacks will receive an
    /// appropriate ::CUresult.
    ///
    /// Callbacks must not make any CUDA API calls.  Attempting to use a CUDA API
    /// will result in ::CUDA_ERROR_NOT_PERMITTED.  Callbacks must not perform any
    /// synchronization that may depend on outstanding device work or other callbacks
    /// that are not mandated to run earlier.  Callbacks without a mandated order
    /// (in independent streams) execute in undefined order and may be serialized.
    ///
    /// This API requires compute capability 1.1 or greater.  See
    /// ::cuDeviceGetAttribute or ::cuDeviceGetProperties to query compute
    /// capability.  Attempting to use this API with earlier compute versions will
    /// return ::CUDA_ERROR_NOT_SUPPORTED.
    ///
    /// For the purposes of Unified Memory, callback execution makes a number of
    /// guarantees:
    /// <ul>
    ///   <li>The callback stream is considered idle for the duration of the
    ///   callback.  Thus, for example, a callback may always use memory attached
    ///   to the callback stream.</li>
    ///   <li>The start of execution of a callback has the same effect as
    ///   synchronizing an event recorded in the same stream immediately prior to
    ///   the callback.  It thus synchronizes streams which have been "joined"
    ///   prior to the callback.</li>
    ///   <li>Adding device work to any stream does not have the effect of making
    ///   the stream active until all preceding callbacks have executed.  Thus, for
    ///   example, a callback might use global attached memory even if work has
    ///   been added to another stream, if it has been properly ordered with an
    ///   event.</li>
    ///   <li>Completion of a callback does not cause a stream to become
    ///   active except as described above.  The callback stream will remain idle
    ///   if no device work follows the callback, and will remain idle across
    ///   consecutive callbacks without device work in between.  Thus, for example,
    ///   stream synchronization can be done by signaling from a callback at the
    ///   end of the stream.</li>
    /// </ul>
    ///
    /// \param hStream  - Stream to add callback to
    /// \param callback - The function to call once preceding stream operations are complete
    /// \param userData - User specified data to be passed to the callback function
    /// \param flags    - Reserved for future use, must be 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuMemAllocManaged,
    /// ::cuStreamAttachMemAsync
    ///
    pub fn cuStreamAddCallback(hStream: CUstream,
                               callback: CUstreamCallback,
                               userData: *mut ::std::os::raw::c_void,
                               flags: ::std::os::raw::c_uint)
                               -> CUresult;
}
extern "C" {
    /// \brief Attach memory to a stream asynchronously
    ///
    /// Enqueues an operation in \p hStream to specify stream association of
    /// \p length bytes of memory starting from \p dptr. This function is a
    /// stream-ordered operation, meaning that it is dependent on, and will
    /// only take effect when, previous work in stream has completed. Any
    /// previous association is automatically replaced.
    ///
    /// \p dptr must point to an address within managed memory space declared
    /// using the __managed__ keyword or allocated with ::cuMemAllocManaged.
    ///
    /// \p length must be zero, to indicate that the entire allocation's
    /// stream association is being changed. Currently, it's not possible
    /// to change stream association for a portion of an allocation.
    ///
    /// The stream association is specified using \p flags which must be
    /// one of ::CUmemAttach_flags.
    /// If the ::CU_MEM_ATTACH_GLOBAL flag is specified, the memory can be accessed
    /// by any stream on any device.
    /// If the ::CU_MEM_ATTACH_HOST flag is specified, the program makes a guarantee
    /// that it won't access the memory on the device from any stream on a device that
    /// has a zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS.
    /// If the ::CU_MEM_ATTACH_SINGLE flag is specified and \p hStream is associated with
    /// a device that has a zero value for the device attribute ::CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS,
    /// the program makes a guarantee that it will only access the memory on the device
    /// from \p hStream. It is illegal to attach singly to the NULL stream, because the
    /// NULL stream is a virtual global stream and not a specific stream. An error will
    /// be returned in this case.
    ///
    /// When memory is associated with a single stream, the Unified Memory system will
    /// allow CPU access to this memory region so long as all operations in \p hStream
    /// have completed, regardless of whether other streams are active. In effect,
    /// this constrains exclusive ownership of the managed memory region by
    /// an active GPU to per-stream activity instead of whole-GPU activity.
    ///
    /// Accessing memory on the device from streams that are not associated with
    /// it will produce undefined results. No error checking is performed by the
    /// Unified Memory system to ensure that kernels launched into other streams
    /// do not access this region.
    ///
    /// It is a program's responsibility to order calls to ::cuStreamAttachMemAsync
    /// via events, synchronization or other means to ensure legal access to memory
    /// at all times. Data visibility and coherency will be changed appropriately
    /// for all kernels which follow a stream-association change.
    ///
    /// If \p hStream is destroyed while data is associated with it, the association is
    /// removed and the association reverts to the default visibility of the allocation
    /// as specified at ::cuMemAllocManaged. For __managed__ variables, the default
    /// association is always ::CU_MEM_ATTACH_GLOBAL. Note that destroying a stream is an
    /// asynchronous operation, and as a result, the change to default association won't
    /// happen until all work in the stream has completed.
    ///
    /// \param hStream - Stream in which to enqueue the attach operation
    /// \param dptr    - Pointer to memory (must be a pointer to managed memory)
    /// \param length  - Length of memory (must be zero)
    /// \param flags   - Must be one of ::CUmemAttach_flags
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamQuery,
    /// ::cuStreamSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuMemAllocManaged
    ///
    pub fn cuStreamAttachMemAsync(hStream: CUstream,
                                  dptr: CUdeviceptr,
                                  length: usize,
                                  flags: ::std::os::raw::c_uint)
                                  -> CUresult;
}
extern "C" {
    /// \brief Determine status of a compute stream
    ///
    /// Returns ::CUDA_SUCCESS if all operations in the stream specified by
    /// \p hStream have completed, or ::CUDA_ERROR_NOT_READY if not.
    ///
    /// For the purposes of Unified Memory, a return value of ::CUDA_SUCCESS
    /// is equivalent to having called ::cuStreamSynchronize().
    ///
    /// \param hStream - Stream to query status of
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_READY
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamDestroy,
    /// ::cuStreamSynchronize,
    /// ::cuStreamAddCallback
    ///
    pub fn cuStreamQuery(hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Wait until a stream's tasks are completed
    ///
    /// Waits until the device has completed all operations in the stream specified
    /// by \p hStream. If the context was created with the
    /// ::CU_CTX_SCHED_BLOCKING_SYNC flag, the CPU thread will block until the
    /// stream is finished with all of its tasks.
    ///
    /// \param hStream - Stream to wait for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuStreamCreate,
    /// ::cuStreamDestroy,
    /// ::cuStreamWaitEvent,
    /// ::cuStreamQuery,
    /// ::cuStreamAddCallback
    ///
    pub fn cuStreamSynchronize(hStream: CUstream) -> CUresult;
}
extern "C" {
    pub fn cuStreamDestroy_v2(hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Creates an event
    ///
    /// Creates an event *phEvent with the flags specified via \p Flags. Valid flags
    /// include:
    /// - ::CU_EVENT_DEFAULT: Default event creation flag.
    /// - ::CU_EVENT_BLOCKING_SYNC: Specifies that the created event should use blocking
    ///   synchronization.  A CPU thread that uses ::cuEventSynchronize() to wait on
    ///   an event created with this flag will block until the event has actually
    ///   been recorded.
    /// - ::CU_EVENT_DISABLE_TIMING: Specifies that the created event does not need
    ///   to record timing data.  Events created with this flag specified and
    ///   the ::CU_EVENT_BLOCKING_SYNC flag not specified will provide the best
    ///   performance when used with ::cuStreamWaitEvent() and ::cuEventQuery().
    /// - ::CU_EVENT_INTERPROCESS: Specifies that the created event may be used as an
    ///   interprocess event by ::cuIpcGetEventHandle(). ::CU_EVENT_INTERPROCESS must
    ///   be specified along with ::CU_EVENT_DISABLE_TIMING.
    ///
    /// \param phEvent - Returns newly created event
    /// \param Flags   - Event creation flags
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_OUT_OF_MEMORY
    /// \notefnerr
    ///
    /// \sa
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime
    ///
    pub fn cuEventCreate(phEvent: *mut CUevent,
                         Flags: ::std::os::raw::c_uint)
                         -> CUresult;
}
extern "C" {
    /// \brief Records an event
    ///
    /// Records an event. See note on NULL stream behavior. Since operation is
    /// asynchronous, ::cuEventQuery or ::cuEventSynchronize() must be used
    /// to determine when the event has actually been recorded.
    ///
    /// If ::cuEventRecord() has previously been called on \p hEvent, then this
    /// call will overwrite any existing state in \p hEvent.  Any subsequent calls
    /// which examine the status of \p hEvent will only examine the completion of
    /// this most recent call to ::cuEventRecord().
    ///
    /// It is necessary that \p hEvent and \p hStream be created on the same context.
    ///
    /// \param hEvent  - Event to record
    /// \param hStream - Stream to record event for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuStreamWaitEvent,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime
    ///
    pub fn cuEventRecord(hEvent: CUevent, hStream: CUstream) -> CUresult;
}
extern "C" {
    /// \brief Queries an event's status
    ///
    /// Query the status of all device work preceding the most recent
    /// call to ::cuEventRecord() (in the appropriate compute streams,
    /// as specified by the arguments to ::cuEventRecord()).
    ///
    /// If this work has successfully been completed by the device, or if
    /// ::cuEventRecord() has not been called on \p hEvent, then ::CUDA_SUCCESS is
    /// returned. If this work has not yet been completed by the device then
    /// ::CUDA_ERROR_NOT_READY is returned.
    ///
    /// For the purposes of Unified Memory, a return value of ::CUDA_SUCCESS
    /// is equivalent to having called ::cuEventSynchronize().
    ///
    /// \param hEvent - Event to query
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_READY
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime
    ///
    pub fn cuEventQuery(hEvent: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Waits for an event to complete
    ///
    /// Wait until the completion of all device work preceding the most recent
    /// call to ::cuEventRecord() (in the appropriate compute streams, as specified
    /// by the arguments to ::cuEventRecord()).
    ///
    /// If ::cuEventRecord() has not been called on \p hEvent, ::CUDA_SUCCESS is
    /// returned immediately.
    ///
    /// Waiting for an event that was created with the ::CU_EVENT_BLOCKING_SYNC
    /// flag will cause the calling CPU thread to block until the event has
    /// been completed by the device.  If the ::CU_EVENT_BLOCKING_SYNC flag has
    /// not been set, then the CPU thread will busy-wait until the event has
    /// been completed by the device.
    ///
    /// \param hEvent - Event to wait for
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventDestroy,
    /// ::cuEventElapsedTime
    ///
    pub fn cuEventSynchronize(hEvent: CUevent) -> CUresult;
}
extern "C" {
    pub fn cuEventDestroy_v2(hEvent: CUevent) -> CUresult;
}
extern "C" {
    /// \brief Computes the elapsed time between two events
    ///
    /// Computes the elapsed time between two events (in milliseconds with a
    /// resolution of around 0.5 microseconds).
    ///
    /// If either event was last recorded in a non-NULL stream, the resulting time
    /// may be greater than expected (even if both used the same stream handle). This
    /// happens because the ::cuEventRecord() operation takes place asynchronously
    /// and there is no guarantee that the measured latency is actually just between
    /// the two events. Any number of other different stream operations could execute
    /// in between the two measured events, thus altering the timing in a significant
    /// way.
    ///
    /// If ::cuEventRecord() has not been called on either event then
    /// ::CUDA_ERROR_INVALID_HANDLE is returned. If ::cuEventRecord() has been called
    /// on both events but one or both of them has not yet been completed (that is,
    /// ::cuEventQuery() would return ::CUDA_ERROR_NOT_READY on at least one of the
    /// events), ::CUDA_ERROR_NOT_READY is returned. If either event was created with
    /// the ::CU_EVENT_DISABLE_TIMING flag, then this function will return
    /// ::CUDA_ERROR_INVALID_HANDLE.
    ///
    /// \param pMilliseconds - Time between \p hStart and \p hEnd in ms
    /// \param hStart        - Starting event
    /// \param hEnd          - Ending event
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_READY
    /// \notefnerr
    ///
    /// \sa ::cuEventCreate,
    /// ::cuEventRecord,
    /// ::cuEventQuery,
    /// ::cuEventSynchronize,
    /// ::cuEventDestroy
    ///
    pub fn cuEventElapsedTime(pMilliseconds: *mut f32,
                              hStart: CUevent,
                              hEnd: CUevent)
                              -> CUresult;
}
extern "C" {
    /// \brief Wait on a memory location
    ///
    /// Enqueues a synchronization of the stream on the given memory location. Work
    /// ordered after the operation will block until the given condition on the
    /// memory is satisfied. By default, the condition is to wait for
    /// (int32_t)(*addr - value) >= 0, a cyclic greater-or-equal.
    /// Other condition types can be specified via \p flags.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer(). This function cannot
    /// be used with managed memory (::cuMemAllocManaged).
    ///
    /// On Windows, the device must be using TCC, or the operation is not supported.
    /// See ::cuDeviceGetAttributes().
    ///
    /// \param stream The stream to synchronize on the memory location.
    /// \param addr The memory location to wait on.
    /// \param value The value to compare with the memory location.
    /// \param flags See ::CUstreamWaitValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWriteValue32,
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuStreamWaitEvent
    ///
    pub fn cuStreamWaitValue32(stream: CUstream,
                               addr: CUdeviceptr,
                               value: cuuint32_t,
                               flags: ::std::os::raw::c_uint)
                               -> CUresult;
}
extern "C" {
    /// \brief Write a value to memory
    ///
    /// Write a value to memory. Unless the ::CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER
    /// flag is passed, the write is preceded by a system-wide memory fence,
    /// equivalent to a __threadfence_system() but scoped to the stream
    /// rather than a CUDA thread.
    ///
    /// If the memory was registered via ::cuMemHostRegister(), the device pointer
    /// should be obtained with ::cuMemHostGetDevicePointer(). This function cannot
    /// be used with managed memory (::cuMemAllocManaged).
    ///
    /// On Windows, the device must be using TCC, or the operation is not supported.
    /// See ::cuDeviceGetAttribute().
    ///
    /// \param stream The stream to do the write in.
    /// \param addr The device address to write to.
    /// \param value The value to write.
    /// \param flags See ::CUstreamWriteValue_flags.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWaitValue32,
    /// ::cuStreamBatchMemOp,
    /// ::cuMemHostRegister,
    /// ::cuEventRecord
    ///
    pub fn cuStreamWriteValue32(stream: CUstream,
                                addr: CUdeviceptr,
                                value: cuuint32_t,
                                flags: ::std::os::raw::c_uint)
                                -> CUresult;
}
extern "C" {
    /// \brief Batch operations to synchronize the stream via memory operations
    ///
    /// This is a batch version of ::cuStreamWaitValue32() and ::cuStreamWriteValue32().
    /// Batching operations may avoid some performance overhead in both the API call
    /// and the device execution versus adding them to the stream in separate API
    /// calls. The operations are enqueued in the order they appear in the array.
    ///
    /// See ::CUstreamBatchMemOpType for the full set of supported operations, and
    /// ::cuStreamWaitValue32() and ::cuStreamWriteValue32() for details of specific
    /// operations.
    ///
    /// On Windows, the device must be using TCC, or this call is not supported. See
    /// ::cuDeviceGetAttribute().
    ///
    /// \param stream The stream to enqueue the operations in.
    /// \param count The number of operations in the array. Must be less than 256.
    /// \param paramArray The types and parameters of the individual operations.
    /// \param flags Reserved for future expansion; must be 0.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_NOT_SUPPORTED
    /// \notefnerr
    ///
    /// \sa ::cuStreamWaitValue32,
    /// ::cuStreamWriteValue32,
    /// ::cuMemHostRegister
    ///
    pub fn cuStreamBatchMemOp(stream: CUstream,
                              count: ::std::os::raw::c_uint,
                              paramArray: *mut CUstreamBatchMemOpParams,
                              flags: ::std::os::raw::c_uint)
                              -> CUresult;
}
extern "C" {
    /// \brief Returns information about a function
    ///
    /// Returns in \p *pi the integer value of the attribute \p attrib on the kernel
    /// given by \p hfunc. The supported attributes are:
    /// - ::CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK: The maximum number of threads
    ///   per block, beyond which a launch of the function would fail. This number
    ///   depends on both the function and the device on which the function is
    ///   currently loaded.
    /// - ::CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES: The size in bytes of
    ///   statically-allocated shared memory per block required by this function.
    ///   This does not include dynamically-allocated shared memory requested by
    ///   the user at runtime.
    /// - ::CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES: The size in bytes of user-allocated
    ///   constant memory required by this function.
    /// - ::CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES: The size in bytes of local memory
    ///   used by each thread of this function.
    /// - ::CU_FUNC_ATTRIBUTE_NUM_REGS: The number of registers used by each thread
    ///   of this function.
    /// - ::CU_FUNC_ATTRIBUTE_PTX_VERSION: The PTX virtual architecture version for
    ///   which the function was compiled. This value is the major PTX version * 10
    ///   + the minor PTX version, so a PTX version 1.3 function would return the
    ///   value 13. Note that this may return the undefined value of 0 for cubins
    ///   compiled prior to CUDA 3.0.
    /// - ::CU_FUNC_ATTRIBUTE_BINARY_VERSION: The binary architecture version for
    ///   which the function was compiled. This value is the major binary
    ///   version * 10 + the minor binary version, so a binary version 1.3 function
    ///   would return the value 13. Note that this will return a value of 10 for
    ///   legacy cubins that do not have a properly-encoded binary architecture
    ///   version.
    /// - ::CU_FUNC_CACHE_MODE_CA: The attribute to indicate whether the function has
    ///   been compiled with user specified option "-Xptxas --dlcm=ca" set .
    ///
    /// \param pi     - Returned attribute value
    /// \param attrib - Attribute requested
    /// \param hfunc  - Function to query attribute of
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuLaunchKernel
    ///
    pub fn cuFuncGetAttribute(pi: *mut ::std::os::raw::c_int,
                              attrib: CUfunction_attribute,
                              hfunc: CUfunction)
                              -> CUresult;
}
extern "C" {
    /// \brief Sets the preferred cache configuration for a device function
    ///
    /// On devices where the L1 cache and shared memory use the same hardware
    /// resources, this sets through \p config the preferred cache configuration for
    /// the device function \p hfunc. This is only a preference. The driver will use
    /// the requested configuration if possible, but it is free to choose a different
    /// configuration if required to execute \p hfunc.  Any context-wide preference
    /// set via ::cuCtxSetCacheConfig() will be overridden by this per-function
    /// setting unless the per-function setting is ::CU_FUNC_CACHE_PREFER_NONE. In
    /// that case, the current context-wide setting will be used.
    ///
    /// This setting does nothing on devices where the size of the L1 cache and
    /// shared memory are fixed.
    ///
    /// Launching a kernel with a different preference than the most recent
    /// preference setting may insert a device-side synchronization point.
    ///
    ///
    /// The supported cache configurations are:
    /// - ::CU_FUNC_CACHE_PREFER_NONE: no preference for shared memory or L1 (default)
    /// - ::CU_FUNC_CACHE_PREFER_SHARED: prefer larger shared memory and smaller L1 cache
    /// - ::CU_FUNC_CACHE_PREFER_L1: prefer larger L1 cache and smaller shared memory
    /// - ::CU_FUNC_CACHE_PREFER_EQUAL: prefer equal sized L1 cache and shared memory
    ///
    /// \param hfunc  - Kernel to configure cache for
    /// \param config - Requested cache configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchKernel
    ///
    pub fn cuFuncSetCacheConfig(hfunc: CUfunction,
                                config: CUfunc_cache)
                                -> CUresult;
}
extern "C" {
    /// \brief Sets the shared memory configuration for a device function.
    ///
    /// On devices with configurable shared memory banks, this function will
    /// force all subsequent launches of the specified device function to have
    /// the given shared memory bank size configuration. On any given launch of the
    /// function, the shared memory configuration of the device will be temporarily
    /// changed if needed to suit the function's preferred configuration. Changes in
    /// shared memory configuration between subsequent launches of functions,
    /// may introduce a device side synchronization point.
    ///
    /// Any per-function setting of shared memory bank size set via
    /// ::cuFuncSetSharedMemConfig will override the context wide setting set with
    /// ::cuCtxSetSharedMemConfig.
    ///
    /// Changing the shared memory bank size will not increase shared memory usage
    /// or affect occupancy of kernels, but may have major effects on performance.
    /// Larger bank sizes will allow for greater potential bandwidth to shared memory,
    /// but will change what kinds of accesses to shared memory will result in bank
    /// conflicts.
    ///
    /// This function will do nothing on devices with fixed shared memory bank size.
    ///
    /// The supported bank configurations are:
    /// - ::CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE: use the context's shared memory
    ///   configuration when launching this function.
    /// - ::CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively four bytes when launching this function.
    /// - ::CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE: set shared memory bank width to
    ///   be natively eight bytes when launching this function.
    ///
    /// \param hfunc  - kernel to be given a shared memory config
    /// \param config - requested shared memory configuration
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuCtxGetSharedMemConfig,
    /// ::cuCtxSetSharedMemConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuLaunchKernel
    ///
    pub fn cuFuncSetSharedMemConfig(hfunc: CUfunction,
                                    config: CUsharedconfig)
                                    -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// Invokes the kernel \p f on a \p gridDimX x \p gridDimY x \p gridDimZ
    /// grid of blocks. Each block contains \p blockDimX x \p blockDimY x
    /// \p blockDimZ threads.
    ///
    /// \p sharedMemBytes sets the amount of dynamic shared memory that will be
    /// available to each thread block.
    ///
    /// Kernel parameters to \p f can be specified in one of two ways:
    ///
    /// 1) Kernel parameters can be specified via \p kernelParams.  If \p f
    /// has N parameters, then \p kernelParams needs to be an array of N
    /// pointers.  Each of \p kernelParams[0] through \p kernelParams[N-1]
    /// must point to a region of memory from which the actual kernel
    /// parameter will be copied.  The number of kernel parameters and their
    /// offsets and sizes do not need to be specified as that information is
    /// retrieved directly from the kernel's image.
    ///
    /// 2) Kernel parameters can also be packaged by the application into
    /// a single buffer that is passed in via the \p extra parameter.
    /// This places the burden on the application of knowing each kernel
    /// parameter's size and alignment/padding within the buffer.  Here is
    /// an example of using the \p extra parameter in this manner:
    /// \code
    /// size_t argBufferSize;
    /// char argBuffer[256];
    ///
    /// populate argBuffer and argBufferSize
    ///
    /// void *config[] = {
    /// CU_LAUNCH_PARAM_BUFFER_POINTER, argBuffer,
    /// CU_LAUNCH_PARAM_BUFFER_SIZE,    &argBufferSize,
    /// CU_LAUNCH_PARAM_END
    /// };
    /// status = cuLaunchKernel(f, gx, gy, gz, bx, by, bz, sh, s, NULL, config);
    /// \endcode
    ///
    /// The \p extra parameter exists to allow ::cuLaunchKernel to take
    /// additional less commonly used arguments.  \p extra specifies a list of
    /// names of extra settings and their corresponding values.  Each extra
    /// setting name is immediately followed by the corresponding value.  The
    /// list must be terminated with either NULL or ::CU_LAUNCH_PARAM_END.
    ///
    /// - ::CU_LAUNCH_PARAM_END, which indicates the end of the \p extra
    ///   array;
    /// - ::CU_LAUNCH_PARAM_BUFFER_POINTER, which specifies that the next
    ///   value in \p extra will be a pointer to a buffer containing all
    ///   the kernel parameters for launching kernel \p f;
    /// - ::CU_LAUNCH_PARAM_BUFFER_SIZE, which specifies that the next
    ///   value in \p extra will be a pointer to a size_t containing the
    ///   size of the buffer specified with ::CU_LAUNCH_PARAM_BUFFER_POINTER;
    ///
    /// The error ::CUDA_ERROR_INVALID_VALUE will be returned if kernel
    /// parameters are specified with both \p kernelParams and \p extra
    /// (i.e. both \p kernelParams and \p extra are non-NULL).
    ///
    /// Calling ::cuLaunchKernel() sets persistent function state that is
    /// the same as function state set through the following deprecated APIs:
    ///  ::cuFuncSetBlockShape(),
    ///  ::cuFuncSetSharedSize(),
    ///  ::cuParamSetSize(),
    ///  ::cuParamSeti(),
    ///  ::cuParamSetf(),
    ///  ::cuParamSetv().
    ///
    /// When the kernel \p f is launched via ::cuLaunchKernel(), the previous
    /// block shape, shared size and parameter info associated with \p f
    /// is overwritten.
    ///
    /// Note that to use ::cuLaunchKernel(), the kernel \p f must either have
    /// been compiled with toolchain version 3.2 or later so that it will
    /// contain kernel parameter information, or have no kernel parameters.
    /// If either of these conditions is not met, then ::cuLaunchKernel() will
    /// return ::CUDA_ERROR_INVALID_IMAGE.
    ///
    /// \param f              - Kernel to launch
    /// \param gridDimX       - Width of grid in blocks
    /// \param gridDimY       - Height of grid in blocks
    /// \param gridDimZ       - Depth of grid in blocks
    /// \param blockDimX      - X dimension of each thread block
    /// \param blockDimY      - Y dimension of each thread block
    /// \param blockDimZ      - Z dimension of each thread block
    /// \param sharedMemBytes - Dynamic shared-memory size per thread block in bytes
    /// \param hStream        - Stream identifier
    /// \param kernelParams   - Array of pointers to kernel parameters
    /// \param extra          - Extra options
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_IMAGE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuCtxGetCacheConfig,
    /// ::cuCtxSetCacheConfig,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute
    ///
    pub fn cuLaunchKernel(f: CUfunction,
                          gridDimX: ::std::os::raw::c_uint,
                          gridDimY: ::std::os::raw::c_uint,
                          gridDimZ: ::std::os::raw::c_uint,
                          blockDimX: ::std::os::raw::c_uint,
                          blockDimY: ::std::os::raw::c_uint,
                          blockDimZ: ::std::os::raw::c_uint,
                          sharedMemBytes: ::std::os::raw::c_uint,
                          hStream: CUstream,
                          kernelParams: *mut *mut ::std::os::raw::c_void,
                          extra: *mut *mut ::std::os::raw::c_void)
                          -> CUresult;
}
extern "C" {
    /// \brief Sets the block-dimensions for the function
    ///
    /// \deprecated
    ///
    /// Specifies the \p x, \p y, and \p z dimensions of the thread blocks that are
    /// created when the kernel given by \p hfunc is launched.
    ///
    /// \param hfunc - Kernel to specify dimensions of
    /// \param x     - X dimension
    /// \param y     - Y dimension
    /// \param z     - Z dimension
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetSharedSize,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuFuncSetBlockShape(hfunc: CUfunction,
                               x: ::std::os::raw::c_int,
                               y: ::std::os::raw::c_int,
                               z: ::std::os::raw::c_int)
                               -> CUresult;
}
extern "C" {
    /// \brief Sets the dynamic shared-memory size for the function
    ///
    /// \deprecated
    ///
    /// Sets through \p bytes the amount of dynamic shared memory that will be
    /// available to each thread block when the kernel given by \p hfunc is launched.
    ///
    /// \param hfunc - Kernel to specify dynamic shared-memory size for
    /// \param bytes - Dynamic shared-memory size per thread in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetCacheConfig,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuFuncSetSharedSize(hfunc: CUfunction,
                               bytes: ::std::os::raw::c_uint)
                               -> CUresult;
}
extern "C" {
    /// \brief Sets the parameter size for the function
    ///
    /// \deprecated
    ///
    /// Sets through \p numbytes the total size in bytes needed by the function
    /// parameters of the kernel corresponding to \p hfunc.
    ///
    /// \param hfunc    - Kernel to set parameter size for
    /// \param numbytes - Size of parameter list in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuParamSetSize(hfunc: CUfunction,
                          numbytes: ::std::os::raw::c_uint)
                          -> CUresult;
}
extern "C" {
    /// \brief Adds an integer parameter to the function's argument list
    ///
    /// \deprecated
    ///
    /// Sets an integer parameter that will be specified the next time the
    /// kernel corresponding to \p hfunc will be invoked. \p offset is a byte offset.
    ///
    /// \param hfunc  - Kernel to add parameter to
    /// \param offset - Offset to add parameter to argument list
    /// \param value  - Value of parameter
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuParamSeti(hfunc: CUfunction,
                       offset: ::std::os::raw::c_int,
                       value: ::std::os::raw::c_uint)
                       -> CUresult;
}
extern "C" {
    /// \brief Adds a floating-point parameter to the function's argument list
    ///
    /// \deprecated
    ///
    /// Sets a floating-point parameter that will be specified the next time the
    /// kernel corresponding to \p hfunc will be invoked. \p offset is a byte offset.
    ///
    /// \param hfunc  - Kernel to add parameter to
    /// \param offset - Offset to add parameter to argument list
    /// \param value  - Value of parameter
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuParamSetf(hfunc: CUfunction,
                       offset: ::std::os::raw::c_int,
                       value: f32)
                       -> CUresult;
}
extern "C" {
    /// \brief Adds arbitrary data to the function's argument list
    ///
    /// \deprecated
    ///
    /// Copies an arbitrary amount of data (specified in \p numbytes) from \p ptr
    /// into the parameter space of the kernel corresponding to \p hfunc. \p offset
    /// is a byte offset.
    ///
    /// \param hfunc    - Kernel to add data to
    /// \param offset   - Offset to add data to argument list
    /// \param ptr      - Pointer to arbitrary data
    /// \param numbytes - Size of data to copy in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuParamSetv(hfunc: CUfunction,
                       offset: ::std::os::raw::c_int,
                       ptr: *mut ::std::os::raw::c_void,
                       numbytes: ::std::os::raw::c_uint)
                       -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a 1 x 1 x 1 grid of blocks. The block
    /// contains the number of threads specified by a previous call to
    /// ::cuFuncSetBlockShape().
    ///
    /// \param f - Kernel to launch
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunchGrid,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuLaunch(f: CUfunction) -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a \p grid_width x \p grid_height grid of
    /// blocks. Each block contains the number of threads specified by a previous
    /// call to ::cuFuncSetBlockShape().
    ///
    /// \param f           - Kernel to launch
    /// \param grid_width  - Width of grid in blocks
    /// \param grid_height - Height of grid in blocks
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGridAsync,
    /// ::cuLaunchKernel
    ///
    pub fn cuLaunchGrid(f: CUfunction,
                        grid_width: ::std::os::raw::c_int,
                        grid_height: ::std::os::raw::c_int)
                        -> CUresult;
}
extern "C" {
    /// \brief Launches a CUDA function
    ///
    /// \deprecated
    ///
    /// Invokes the kernel \p f on a \p grid_width x \p grid_height grid of
    /// blocks. Each block contains the number of threads specified by a previous
    /// call to ::cuFuncSetBlockShape().
    ///
    /// \param f           - Kernel to launch
    /// \param grid_width  - Width of grid in blocks
    /// \param grid_height - Height of grid in blocks
    /// \param hStream     - Stream identifier
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_LAUNCH_FAILED,
    /// ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,
    /// ::CUDA_ERROR_LAUNCH_TIMEOUT,
    /// ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,
    /// ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED
    ///
    /// \note In certain cases where cubins are created with no ABI (i.e., using \p ptxas \p --abi-compile \p no),
    ///       this function may serialize kernel launches. In order to force the CUDA driver to retain
    /// 		 asynchronous behavior, set the ::CU_CTX_LMEM_RESIZE_TO_MAX flag during context creation (see ::cuCtxCreate).
    ///
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa ::cuFuncSetBlockShape,
    /// ::cuFuncSetSharedSize,
    /// ::cuFuncGetAttribute,
    /// ::cuParamSetSize,
    /// ::cuParamSetf,
    /// ::cuParamSeti,
    /// ::cuParamSetv,
    /// ::cuLaunch,
    /// ::cuLaunchGrid,
    /// ::cuLaunchKernel
    ///
    pub fn cuLaunchGridAsync(f: CUfunction,
                             grid_width: ::std::os::raw::c_int,
                             grid_height: ::std::os::raw::c_int,
                             hStream: CUstream)
                             -> CUresult;
}
extern "C" {
    /// \brief Adds a texture-reference to the function's argument list
    ///
    /// \deprecated
    ///
    /// Makes the CUDA array or linear memory bound to the texture reference
    /// \p hTexRef available to a device program as a texture. In this version of
    /// CUDA, the texture-reference must be obtained via ::cuModuleGetTexRef() and
    /// the \p texunit parameter must be set to ::CU_PARAM_TR_DEFAULT.
    ///
    /// \param hfunc   - Kernel to add texture-reference to
    /// \param texunit - Texture unit (must be ::CU_PARAM_TR_DEFAULT)
    /// \param hTexRef - Texture-reference to add to argument list
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    pub fn cuParamSetTexRef(hfunc: CUfunction,
                            texunit: ::std::os::raw::c_int,
                            hTexRef: CUtexref)
                            -> CUresult;
}
extern "C" {
    /// \brief Returns occupancy of a function
    ///
    /// Returns in \p *numBlocks the number of the maximum active blocks per
    /// streaming multiprocessor.
    ///
    /// \param numBlocks       - Returned occupancy
    /// \param func            - Kernel for which occupancy is calculated
    /// \param blockSize       - Block size the kernel is intended to be launched with
    /// \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    ///
    pub fn cuOccupancyMaxActiveBlocksPerMultiprocessor(numBlocks:
                                                           *mut ::std::os::raw::c_int,
                                                       func: CUfunction,
                                                       blockSize:
                                                           ::std::os::raw::c_int,
                                                       dynamicSMemSize: usize)
     -> CUresult;
}
extern "C" {
    /// \brief Returns occupancy of a function
    ///
    /// Returns in \p *numBlocks the number of the maximum active blocks per
    /// streaming multiprocessor.
    ///
    /// The \p Flags parameter controls how special cases are handled. The
    /// valid flags are:
    ///
    /// - ::CU_OCCUPANCY_DEFAULT, which maintains the default behavior as
    ///   ::cuOccupancyMaxActiveBlocksPerMultiprocessor;
    ///
    /// - ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE, which suppresses the
    ///   default behavior on platform where global caching affects
    ///   occupancy. On such platforms, if caching is enabled, but
    ///   per-block SM resource usage would result in zero occupancy, the
    ///   occupancy calculator will calculate the occupancy as if caching
    ///   is disabled. Setting ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE makes
    ///   the occupancy calculator to return 0 in such cases. More information
    ///   can be found about this feature in the "Unified L1/Texture Cache"
    ///   section of the Maxwell tuning guide.
    ///
    /// \param numBlocks       - Returned occupancy
    /// \param func            - Kernel for which occupancy is calculated
    /// \param blockSize       - Block size the kernel is intended to be launched with
    /// \param dynamicSMemSize - Per-block dynamic shared memory usage intended, in bytes
    /// \param flags           - Requested behavior for the occupancy calculator
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    ///
    pub fn cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(numBlocks:
                                                                    *mut ::std::os::raw::c_int,
                                                                func:
                                                                    CUfunction,
                                                                blockSize:
                                                                    ::std::os::raw::c_int,
                                                                dynamicSMemSize:
                                                                    usize,
                                                                flags:
                                                                    ::std::os::raw::c_uint)
     -> CUresult;
}
extern "C" {
    /// \brief Suggest a launch configuration with reasonable occupancy
    ///
    /// Returns in \p *blockSize a reasonable block size that can achieve
    /// the maximum occupancy (or, the maximum number of active warps with
    /// the fewest blocks per multiprocessor), and in \p *minGridSize the
    /// minimum grid size to achieve the maximum occupancy.
    ///
    /// If \p blockSizeLimit is 0, the configurator will use the maximum
    /// block size permitted by the device / function instead.
    ///
    /// If per-block dynamic shared memory allocation is not needed, the
    /// user should leave both \p blockSizeToDynamicSMemSize and \p
    /// dynamicSMemSize as 0.
    ///
    /// If per-block dynamic shared memory allocation is needed, then if
    /// the dynamic shared memory size is constant regardless of block
    /// size, the size should be passed through \p dynamicSMemSize, and \p
    /// blockSizeToDynamicSMemSize should be NULL.
    ///
    /// Otherwise, if the per-block dynamic shared memory size varies with
    /// different block sizes, the user needs to provide a unary function
    /// through \p blockSizeToDynamicSMemSize that computes the dynamic
    /// shared memory needed by \p func for any given block size. \p
    /// dynamicSMemSize is ignored. An example signature is:
    ///
    /// \code
    ///    // Take block size, returns dynamic shared memory needed
    ///    size_t blockToSmem(int blockSize);
    /// \endcode
    ///
    /// \param minGridSize - Returned minimum grid size needed to achieve the maximum occupancy
    /// \param blockSize   - Returned maximum block size that can achieve the maximum occupancy
    /// \param func        - Kernel for which launch configuration is calculated
    /// \param blockSizeToDynamicSMemSize - A function that calculates how much per-block dynamic shared memory \p func uses based on the block size
    /// \param dynamicSMemSize - Dynamic shared memory usage intended, in bytes
    /// \param blockSizeLimit  - The maximum block size \p func is designed to handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    ///
    pub fn cuOccupancyMaxPotentialBlockSize(minGridSize:
                                                *mut ::std::os::raw::c_int,
                                            blockSize:
                                                *mut ::std::os::raw::c_int,
                                            func: CUfunction,
                                            blockSizeToDynamicSMemSize:
                                                CUoccupancyB2DSize,
                                            dynamicSMemSize: usize,
                                            blockSizeLimit:
                                                ::std::os::raw::c_int)
     -> CUresult;
}
extern "C" {
    /// \brief Suggest a launch configuration with reasonable occupancy
    ///
    /// An extended version of ::cuOccupancyMaxPotentialBlockSize. In
    /// addition to arguments passed to ::cuOccupancyMaxPotentialBlockSize,
    /// ::cuOccupancyMaxPotentialBlockSizeWithFlags also takes a \p Flags
    /// parameter.
    ///
    /// The \p Flags parameter controls how special cases are handled. The
    /// valid flags are:
    ///
    /// - ::CU_OCCUPANCY_DEFAULT, which maintains the default behavior as
    ///   ::cuOccupancyMaxPotentialBlockSize;
    ///
    /// - ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE, which suppresses the
    ///   default behavior on platform where global caching affects
    ///   occupancy. On such platforms, the launch configurations that
    ///   produces maximal occupancy might not support global
    ///   caching. Setting ::CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE
    ///   guarantees that the the produced launch configuration is global
    ///   caching compatible at a potential cost of occupancy. More information
    ///   can be found about this feature in the "Unified L1/Texture Cache"
    ///   section of the Maxwell tuning guide.
    ///
    /// \param minGridSize - Returned minimum grid size needed to achieve the maximum occupancy
    /// \param blockSize   - Returned maximum block size that can achieve the maximum occupancy
    /// \param func        - Kernel for which launch configuration is calculated
    /// \param blockSizeToDynamicSMemSize - A function that calculates how much per-block dynamic shared memory \p func uses based on the block size
    /// \param dynamicSMemSize - Dynamic shared memory usage intended, in bytes
    /// \param blockSizeLimit  - The maximum block size \p func is designed to handle
    /// \param flags       - Options
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    ///
    pub fn cuOccupancyMaxPotentialBlockSizeWithFlags(minGridSize:
                                                         *mut ::std::os::raw::c_int,
                                                     blockSize:
                                                         *mut ::std::os::raw::c_int,
                                                     func: CUfunction,
                                                     blockSizeToDynamicSMemSize:
                                                         CUoccupancyB2DSize,
                                                     dynamicSMemSize: usize,
                                                     blockSizeLimit:
                                                         ::std::os::raw::c_int,
                                                     flags:
                                                         ::std::os::raw::c_uint)
     -> CUresult;
}
extern "C" {
    /// \brief Binds an array as a texture reference
    ///
    /// Binds the CUDA array \p hArray to the texture reference \p hTexRef. Any
    /// previous address or CUDA array state associated with the texture reference
    /// is superseded by this function. \p Flags must be set to
    /// ::CU_TRSA_OVERRIDE_FORMAT. Any CUDA array previously bound to \p hTexRef is
    /// unbound.
    ///
    /// \param hTexRef - Texture reference to bind
    /// \param hArray  - Array to bind
    /// \param Flags   - Options (must be ::CU_TRSA_OVERRIDE_FORMAT)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetArray(hTexRef: CUtexref,
                            hArray: CUarray,
                            Flags: ::std::os::raw::c_uint)
                            -> CUresult;
}
extern "C" {
    /// \brief Binds a mipmapped array to a texture reference
    ///
    /// Binds the CUDA mipmapped array \p hMipmappedArray to the texture reference \p hTexRef.
    /// Any previous address or CUDA array state associated with the texture reference
    /// is superseded by this function. \p Flags must be set to ::CU_TRSA_OVERRIDE_FORMAT.
    /// Any CUDA array previously bound to \p hTexRef is unbound.
    ///
    /// \param hTexRef         - Texture reference to bind
    /// \param hMipmappedArray - Mipmapped array to bind
    /// \param Flags           - Options (must be ::CU_TRSA_OVERRIDE_FORMAT)
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetMipmappedArray(hTexRef: CUtexref,
                                     hMipmappedArray: CUmipmappedArray,
                                     Flags: ::std::os::raw::c_uint)
                                     -> CUresult;
}
extern "C" {
    pub fn cuTexRefSetAddress_v2(ByteOffset: *mut usize,
                                 hTexRef: CUtexref,
                                 dptr: CUdeviceptr,
                                 bytes: usize)
                                 -> CUresult;
}
extern "C" {
    pub fn cuTexRefSetAddress2D_v3(hTexRef: CUtexref,
                                   desc: *const CUDA_ARRAY_DESCRIPTOR,
                                   dptr: CUdeviceptr,
                                   Pitch: usize)
                                   -> CUresult;
}
extern "C" {
    /// \brief Sets the format for a texture reference
    ///
    /// Specifies the format of the data to be read by the texture reference
    /// \p hTexRef. \p fmt and \p NumPackedComponents are exactly analogous to the
    /// ::Format and ::NumChannels members of the ::CUDA_ARRAY_DESCRIPTOR structure:
    /// They specify the format of each component and the number of components per
    /// array element.
    ///
    /// \param hTexRef             - Texture reference
    /// \param fmt                 - Format to set
    /// \param NumPackedComponents - Number of components per array element
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetFormat(hTexRef: CUtexref,
                             fmt: CUarray_format,
                             NumPackedComponents: ::std::os::raw::c_int)
                             -> CUresult;
}
extern "C" {
    /// \brief Sets the addressing mode for a texture reference
    ///
    /// Specifies the addressing mode \p am for the given dimension \p dim of the
    /// texture reference \p hTexRef. If \p dim is zero, the addressing mode is
    /// applied to the first parameter of the functions used to fetch from the
    /// texture; if \p dim is 1, the second, and so on. ::CUaddress_mode is defined
    /// as:
    /// \code
    /// typedef enum CUaddress_mode_enum {
    /// CU_TR_ADDRESS_MODE_WRAP = 0,
    /// CU_TR_ADDRESS_MODE_CLAMP = 1,
    /// CU_TR_ADDRESS_MODE_MIRROR = 2,
    /// CU_TR_ADDRESS_MODE_BORDER = 3
    /// } CUaddress_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    /// Also, if the flag, ::CU_TRSF_NORMALIZED_COORDINATES, is not set, the only
    /// supported address mode is ::CU_TR_ADDRESS_MODE_CLAMP.
    ///
    /// \param hTexRef - Texture reference
    /// \param dim     - Dimension
    /// \param am      - Addressing mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetAddressMode(hTexRef: CUtexref,
                                  dim: ::std::os::raw::c_int,
                                  am: CUaddress_mode)
                                  -> CUresult;
}
extern "C" {
    /// \brief Sets the filtering mode for a texture reference
    ///
    /// Specifies the filtering mode \p fm to be used when reading memory through
    /// the texture reference \p hTexRef. ::CUfilter_mode_enum is defined as:
    ///
    /// \code
    /// typedef enum CUfilter_mode_enum {
    /// CU_TR_FILTER_MODE_POINT = 0,
    /// CU_TR_FILTER_MODE_LINEAR = 1
    /// } CUfilter_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    ///
    /// \param hTexRef - Texture reference
    /// \param fm      - Filtering mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetFilterMode(hTexRef: CUtexref,
                                 fm: CUfilter_mode)
                                 -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap filtering mode for a texture reference
    ///
    /// Specifies the mipmap filtering mode \p fm to be used when reading memory through
    /// the texture reference \p hTexRef. ::CUfilter_mode_enum is defined as:
    ///
    /// \code
    /// typedef enum CUfilter_mode_enum {
    /// CU_TR_FILTER_MODE_POINT = 0,
    /// CU_TR_FILTER_MODE_LINEAR = 1
    /// } CUfilter_mode;
    /// \endcode
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef - Texture reference
    /// \param fm      - Filtering mode to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetMipmapFilterMode(hTexRef: CUtexref,
                                       fm: CUfilter_mode)
                                       -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap level bias for a texture reference
    ///
    /// Specifies the mipmap level bias \p bias to be added to the specified mipmap level when
    /// reading memory through the texture reference \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef - Texture reference
    /// \param bias    - Mipmap level bias
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetMipmapLevelBias(hTexRef: CUtexref,
                                      bias: f32)
                                      -> CUresult;
}
extern "C" {
    /// \brief Sets the mipmap min/max mipmap level clamps for a texture reference
    ///
    /// Specifies the min/max mipmap level clamps, \p minMipmapLevelClamp and \p maxMipmapLevelClamp
    /// respectively, to be used when reading memory through the texture reference
    /// \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is not bound to a mipmapped array.
    ///
    /// \param hTexRef        - Texture reference
    /// \param minMipmapLevelClamp - Mipmap min level clamp
    /// \param maxMipmapLevelClamp - Mipmap max level clamp
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetMipmapLevelClamp(hTexRef: CUtexref,
                                       minMipmapLevelClamp: f32,
                                       maxMipmapLevelClamp: f32)
                                       -> CUresult;
}
extern "C" {
    /// \brief Sets the maximum anisotropy for a texture reference
    ///
    /// Specifies the maximum anisotropy \p maxAniso to be used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// Note that this call has no effect if \p hTexRef is bound to linear memory.
    ///
    /// \param hTexRef  - Texture reference
    /// \param maxAniso - Maximum anisotropy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetMaxAnisotropy(hTexRef: CUtexref,
                                    maxAniso: ::std::os::raw::c_uint)
                                    -> CUresult;
}
extern "C" {
    /// \brief Sets the border color for a texture reference
    ///
    /// Specifies the value of the RGBA color via the \p pBorderColor to the texture reference
    /// \p hTexRef. The color value supports only float type and holds color components in
    /// the following sequence:
    /// pBorderColor[0] holds 'R' component
    /// pBorderColor[1] holds 'G' component
    /// pBorderColor[2] holds 'B' component
    /// pBorderColor[3] holds 'A' component
    ///
    /// Note that the color values can be set only when the Address mode is set to
    /// CU_TR_ADDRESS_MODE_BORDER using ::cuTexRefSetAddressMode.
    /// Applications using integer border color values have to "reinterpret_cast" their values to float.
    ///
    /// \param hTexRef       - Texture reference
    /// \param pBorderColor  - RGBA color
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddressMode,
    /// ::cuTexRefGetAddressMode, ::cuTexRefGetBorderColor
    ///
    pub fn cuTexRefSetBorderColor(hTexRef: CUtexref,
                                  pBorderColor: *mut f32)
                                  -> CUresult;
}
extern "C" {
    /// \brief Sets the flags for a texture reference
    ///
    /// Specifies optional flags via \p Flags to specify the behavior of data
    /// returned through the texture reference \p hTexRef. The valid flags are:
    ///
    /// - ::CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of
    ///   having the texture promote integer data to floating point data in the
    ///   range [0, 1]. Note that texture with 32-bit integer format
    ///   would not be promoted, regardless of whether or not this
    ///   flag is specified;
    /// - ::CU_TRSF_NORMALIZED_COORDINATES, which suppresses the
    ///   default behavior of having the texture coordinates range
    ///   from [0, Dim) where Dim is the width or height of the CUDA
    ///   array. Instead, the texture coordinates [0, 1.0) reference
    ///   the entire breadth of the array dimension;
    ///
    /// \param hTexRef - Texture reference
    /// \param Flags   - Optional flags to set
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefSetFlags(hTexRef: CUtexref,
                            Flags: ::std::os::raw::c_uint)
                            -> CUresult;
}
extern "C" {
    pub fn cuTexRefGetAddress_v2(pdptr: *mut CUdeviceptr,
                                 hTexRef: CUtexref)
                                 -> CUresult;
}
extern "C" {
    /// \brief Gets the array bound to a texture reference
    ///
    /// Returns in \p *phArray the CUDA array bound to the texture reference
    /// \p hTexRef, or returns ::CUDA_ERROR_INVALID_VALUE if the texture reference
    /// is not bound to any CUDA array.
    ///
    /// \param phArray - Returned array
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetArray(phArray: *mut CUarray,
                            hTexRef: CUtexref)
                            -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmapped array bound to a texture reference
    ///
    /// Returns in \p *phMipmappedArray the CUDA mipmapped array bound to the texture
    /// reference \p hTexRef, or returns ::CUDA_ERROR_INVALID_VALUE if the texture reference
    /// is not bound to any CUDA mipmapped array.
    ///
    /// \param phMipmappedArray - Returned mipmapped array
    /// \param hTexRef          - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetMipmappedArray(phMipmappedArray: *mut CUmipmappedArray,
                                     hTexRef: CUtexref)
                                     -> CUresult;
}
extern "C" {
    /// \brief Gets the addressing mode used by a texture reference
    ///
    /// Returns in \p *pam the addressing mode corresponding to the
    /// dimension \p dim of the texture reference \p hTexRef. Currently, the only
    /// valid value for \p dim are 0 and 1.
    ///
    /// \param pam     - Returned addressing mode
    /// \param hTexRef - Texture reference
    /// \param dim     - Dimension
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetAddressMode(pam: *mut CUaddress_mode,
                                  hTexRef: CUtexref,
                                  dim: ::std::os::raw::c_int)
                                  -> CUresult;
}
extern "C" {
    /// \brief Gets the filter-mode used by a texture reference
    ///
    /// Returns in \p *pfm the filtering mode of the texture reference
    /// \p hTexRef.
    ///
    /// \param pfm     - Returned filtering mode
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetFilterMode(pfm: *mut CUfilter_mode,
                                 hTexRef: CUtexref)
                                 -> CUresult;
}
extern "C" {
    /// \brief Gets the format used by a texture reference
    ///
    /// Returns in \p *pFormat and \p *pNumChannels the format and number
    /// of components of the CUDA array bound to the texture reference \p hTexRef.
    /// If \p pFormat or \p pNumChannels is NULL, it will be ignored.
    ///
    /// \param pFormat      - Returned format
    /// \param pNumChannels - Returned number of components
    /// \param hTexRef      - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags
    ///
    pub fn cuTexRefGetFormat(pFormat: *mut CUarray_format,
                             pNumChannels: *mut ::std::os::raw::c_int,
                             hTexRef: CUtexref)
                             -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmap filtering mode for a texture reference
    ///
    /// Returns the mipmap filtering mode in \p pfm that's used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// \param pfm     - Returned mipmap filtering mode
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetMipmapFilterMode(pfm: *mut CUfilter_mode,
                                       hTexRef: CUtexref)
                                       -> CUresult;
}
extern "C" {
    /// \brief Gets the mipmap level bias for a texture reference
    ///
    /// Returns the mipmap level bias in \p pBias that's added to the specified mipmap
    /// level when reading memory through the texture reference \p hTexRef.
    ///
    /// \param pbias   - Returned mipmap level bias
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetMipmapLevelBias(pbias: *mut f32,
                                      hTexRef: CUtexref)
                                      -> CUresult;
}
extern "C" {
    /// \brief Gets the min/max mipmap level clamps for a texture reference
    ///
    /// Returns the min/max mipmap level clamps in \p pminMipmapLevelClamp and \p pmaxMipmapLevelClamp
    /// that's used when reading memory through the texture reference \p hTexRef.
    ///
    /// \param pminMipmapLevelClamp - Returned mipmap min level clamp
    /// \param pmaxMipmapLevelClamp - Returned mipmap max level clamp
    /// \param hTexRef              - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetMipmapLevelClamp(pminMipmapLevelClamp: *mut f32,
                                       pmaxMipmapLevelClamp: *mut f32,
                                       hTexRef: CUtexref)
                                       -> CUresult;
}
extern "C" {
    /// \brief Gets the maximum anisotropy for a texture reference
    ///
    /// Returns the maximum anisotropy in \p pmaxAniso that's used when reading memory through
    /// the texture reference \p hTexRef.
    ///
    /// \param pmaxAniso - Returned maximum anisotropy
    /// \param hTexRef   - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFlags, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetMaxAnisotropy(pmaxAniso: *mut ::std::os::raw::c_int,
                                    hTexRef: CUtexref)
                                    -> CUresult;
}
extern "C" {
    /// \brief Gets the border color used by a texture reference
    ///
    /// Returns in \p pBorderColor, values of the RGBA color used by
    /// the texture reference \p hTexRef.
    /// The color value is of type float and holds color components in
    /// the following sequence:
    /// pBorderColor[0] holds 'R' component
    /// pBorderColor[1] holds 'G' component
    /// pBorderColor[2] holds 'B' component
    /// pBorderColor[3] holds 'A' component
    ///
    /// \param hTexRef  - Texture reference
    /// \param pBorderColor   - Returned Type and Value of RGBA color
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddressMode,
    /// ::cuTexRefSetAddressMode, ::cuTexRefSetBorderColor
    ///
    pub fn cuTexRefGetBorderColor(pBorderColor: *mut f32,
                                  hTexRef: CUtexref)
                                  -> CUresult;
}
extern "C" {
    /// \brief Gets the flags used by a texture reference
    ///
    /// Returns in \p *pFlags the flags of the texture reference \p hTexRef.
    ///
    /// \param pFlags  - Returned flags
    /// \param hTexRef - Texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefSetAddress,
    /// ::cuTexRefSetAddress2D, ::cuTexRefSetAddressMode, ::cuTexRefSetArray,
    /// ::cuTexRefSetFilterMode, ::cuTexRefSetFlags, ::cuTexRefSetFormat,
    /// ::cuTexRefGetAddress, ::cuTexRefGetAddressMode, ::cuTexRefGetArray,
    /// ::cuTexRefGetFilterMode, ::cuTexRefGetFormat
    ///
    pub fn cuTexRefGetFlags(pFlags: *mut ::std::os::raw::c_uint,
                            hTexRef: CUtexref)
                            -> CUresult;
}
extern "C" {
    /// \brief Creates a texture reference
    ///
    /// \deprecated
    ///
    /// Creates a texture reference and returns its handle in \p *pTexRef. Once
    /// created, the application must call ::cuTexRefSetArray() or
    /// ::cuTexRefSetAddress() to associate the reference with allocated memory.
    /// Other texture reference functions are used to specify the format and
    /// interpretation (addressing, filtering, etc.) to be used when the memory is
    /// read through this texture reference.
    ///
    /// \param pTexRef - Returned texture reference
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefDestroy
    ///
    pub fn cuTexRefCreate(pTexRef: *mut CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Destroys a texture reference
    ///
    /// \deprecated
    ///
    /// Destroys the texture reference specified by \p hTexRef.
    ///
    /// \param hTexRef - Texture reference to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexRefCreate
    ///
    pub fn cuTexRefDestroy(hTexRef: CUtexref) -> CUresult;
}
extern "C" {
    /// \brief Sets the CUDA array for a surface reference.
    ///
    /// Sets the CUDA array \p hArray to be read and written by the surface reference
    /// \p hSurfRef.  Any previous CUDA array state associated with the surface
    /// reference is superseded by this function.  \p Flags must be set to 0.
    /// The ::CUDA_ARRAY3D_SURFACE_LDST flag must have been set for the CUDA array.
    /// Any CUDA array previously bound to \p hSurfRef is unbound.
    ///
    /// \param hSurfRef - Surface reference handle
    /// \param hArray - CUDA array handle
    /// \param Flags - set to 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuModuleGetSurfRef, ::cuSurfRefGetArray
    ///
    pub fn cuSurfRefSetArray(hSurfRef: CUsurfref,
                             hArray: CUarray,
                             Flags: ::std::os::raw::c_uint)
                             -> CUresult;
}
extern "C" {
    /// \brief Passes back the CUDA array bound to a surface reference.
    ///
    /// Returns in \p *phArray the CUDA array bound to the surface reference
    /// \p hSurfRef, or returns ::CUDA_ERROR_INVALID_VALUE if the surface reference
    /// is not bound to any CUDA array.
    ///
    /// \param phArray - Surface reference handle
    /// \param hSurfRef - Surface reference handle
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuModuleGetSurfRef, ::cuSurfRefSetArray
    ///
    pub fn cuSurfRefGetArray(phArray: *mut CUarray,
                             hSurfRef: CUsurfref)
                             -> CUresult;
}
extern "C" {
    /// \brief Creates a texture object
    ///
    /// Creates a texture object and returns it in \p pTexObject. \p pResDesc describes
    /// the data to texture from. \p pTexDesc describes how the data should be sampled.
    /// \p pResViewDesc is an optional argument that specifies an alternate format for
    /// the data described by \p pResDesc, and also describes the subresource region
    /// to restrict access to when texturing. \p pResViewDesc can only be specified if
    /// the type of resource is a CUDA array or a CUDA mipmapped array.
    ///
    /// Texture objects are only supported on devices of compute capability 3.0 or higher.
    /// Additionally, a texture object is an opaque value, and, as such, should only be
    /// accessed through CUDA API calls.
    ///
    /// The ::CUDA_RESOURCE_DESC structure is defined as:
    /// \code
    /// typedef struct CUDA_RESOURCE_DESC_st
    /// {
    /// CUresourcetype resType;
    ///
    /// union {
    /// struct {
    /// CUarray hArray;
    /// } array;
    /// struct {
    /// CUmipmappedArray hMipmappedArray;
    /// } mipmap;
    /// struct {
    /// CUdeviceptr devPtr;
    /// CUarray_format format;
    /// unsigned int numChannels;
    /// size_t sizeInBytes;
    /// } linear;
    /// struct {
    /// CUdeviceptr devPtr;
    /// CUarray_format format;
    /// unsigned int numChannels;
    /// size_t width;
    /// size_t height;
    /// size_t pitchInBytes;
    /// } pitch2D;
    /// } res;
    ///
    /// unsigned int flags;
    /// } CUDA_RESOURCE_DESC;
    ///
    /// \endcode
    /// where:
    /// - ::CUDA_RESOURCE_DESC::resType specifies the type of resource to texture from.
    /// CUresourceType is defined as:
    /// \code
    /// typedef enum CUresourcetype_enum {
    /// CU_RESOURCE_TYPE_ARRAY           = 0x00,
    /// CU_RESOURCE_TYPE_MIPMAPPED_ARRAY = 0x01,
    /// CU_RESOURCE_TYPE_LINEAR          = 0x02,
    /// CU_RESOURCE_TYPE_PITCH2D         = 0x03
    /// } CUresourcetype;
    /// \endcode
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_ARRAY, ::CUDA_RESOURCE_DESC::res::array::hArray
    /// must be set to a valid CUDA array handle.
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_MIPMAPPED_ARRAY, ::CUDA_RESOURCE_DESC::res::mipmap::hMipmappedArray
    /// must be set to a valid CUDA mipmapped array handle.
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_LINEAR, ::CUDA_RESOURCE_DESC::res::linear::devPtr
    /// must be set to a valid device pointer, that is aligned to ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT.
    /// ::CUDA_RESOURCE_DESC::res::linear::format and ::CUDA_RESOURCE_DESC::res::linear::numChannels
    /// describe the format of each component and the number of components per array element. ::CUDA_RESOURCE_DESC::res::linear::sizeInBytes
    /// specifies the size of the array in bytes. The total number of elements in the linear address range cannot exceed
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH. The number of elements is computed as (sizeInBytes / (sizeof(format) * numChannels)).
    ///
    /// \par
    /// If ::CUDA_RESOURCE_DESC::resType is set to ::CU_RESOURCE_TYPE_PITCH2D, ::CUDA_RESOURCE_DESC::res::pitch2D::devPtr
    /// must be set to a valid device pointer, that is aligned to ::CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT.
    /// ::CUDA_RESOURCE_DESC::res::pitch2D::format and ::CUDA_RESOURCE_DESC::res::pitch2D::numChannels
    /// describe the format of each component and the number of components per array element. ::CUDA_RESOURCE_DESC::res::pitch2D::width
    /// and ::CUDA_RESOURCE_DESC::res::pitch2D::height specify the width and height of the array in elements, and cannot exceed
    /// ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH and ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT respectively.
    /// ::CUDA_RESOURCE_DESC::res::pitch2D::pitchInBytes specifies the pitch between two rows in bytes and has to be aligned to
    /// ::CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT. Pitch cannot exceed ::CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH.
    ///
    /// - ::flags must be set to zero.
    ///
    ///
    /// The ::CUDA_TEXTURE_DESC struct is defined as
    /// \code
    /// typedef struct CUDA_TEXTURE_DESC_st {
    /// CUaddress_mode addressMode[3];
    /// CUfilter_mode filterMode;
    /// unsigned int flags;
    /// unsigned int maxAnisotropy;
    /// CUfilter_mode mipmapFilterMode;
    /// float mipmapLevelBias;
    /// float minMipmapLevelClamp;
    /// float maxMipmapLevelClamp;
    /// } CUDA_TEXTURE_DESC;
    /// \endcode
    /// where
    /// - ::CUDA_TEXTURE_DESC::addressMode specifies the addressing mode for each dimension of the texture data. ::CUaddress_mode is defined as:
    ///   \code
    /// typedef enum CUaddress_mode_enum {
    /// CU_TR_ADDRESS_MODE_WRAP = 0,
    /// CU_TR_ADDRESS_MODE_CLAMP = 1,
    /// CU_TR_ADDRESS_MODE_MIRROR = 2,
    /// CU_TR_ADDRESS_MODE_BORDER = 3
    /// } CUaddress_mode;
    ///   \endcode
    ///   This is ignored if ::CUDA_RESOURCE_DESC::resType is ::CU_RESOURCE_TYPE_LINEAR. Also, if the flag, ::CU_TRSF_NORMALIZED_COORDINATES
    ///   is not set, the only supported address mode is ::CU_TR_ADDRESS_MODE_CLAMP.
    ///
    /// - ::CUDA_TEXTURE_DESC::filterMode specifies the filtering mode to be used when fetching from the texture. CUfilter_mode is defined as:
    ///   \code
    /// typedef enum CUfilter_mode_enum {
    /// CU_TR_FILTER_MODE_POINT = 0,
    /// CU_TR_FILTER_MODE_LINEAR = 1
    /// } CUfilter_mode;
    ///   \endcode
    ///   This is ignored if ::CUDA_RESOURCE_DESC::resType is ::CU_RESOURCE_TYPE_LINEAR.
    ///
    /// - ::CUDA_TEXTURE_DESC::flags can be any combination of the following:
    ///   - ::CU_TRSF_READ_AS_INTEGER, which suppresses the default behavior of having the texture promote integer data to floating point data in the
    ///     range [0, 1]. Note that texture with 32-bit integer format would not be promoted, regardless of whether or not this flag is specified.
    ///   - ::CU_TRSF_NORMALIZED_COORDINATES, which suppresses the default behavior of having the texture coordinates range from [0, Dim) where Dim is
    ///     the width or height of the CUDA array. Instead, the texture coordinates [0, 1.0) reference the entire breadth of the array dimension; Note
    ///     that for CUDA mipmapped arrays, this flag has to be set.
    ///
    /// - ::CUDA_TEXTURE_DESC::maxAnisotropy specifies the maximum anisotropy ratio to be used when doing anisotropic filtering. This value will be
    ///   clamped to the range [1,16].
    ///
    /// - ::CUDA_TEXTURE_DESC::mipmapFilterMode specifies the filter mode when the calculated mipmap level lies between two defined mipmap levels.
    ///
    /// - ::CUDA_TEXTURE_DESC::mipmapLevelBias specifies the offset to be applied to the calculated mipmap level.
    ///
    /// - ::CUDA_TEXTURE_DESC::minMipmapLevelClamp specifies the lower end of the mipmap level range to clamp access to.
    ///
    /// - ::CUDA_TEXTURE_DESC::maxMipmapLevelClamp specifies the upper end of the mipmap level range to clamp access to.
    ///
    ///
    /// The ::CUDA_RESOURCE_VIEW_DESC struct is defined as
    /// \code
    /// typedef struct CUDA_RESOURCE_VIEW_DESC_st
    /// {
    /// CUresourceViewFormat format;
    /// size_t width;
    /// size_t height;
    /// size_t depth;
    /// unsigned int firstMipmapLevel;
    /// unsigned int lastMipmapLevel;
    /// unsigned int firstLayer;
    /// unsigned int lastLayer;
    /// } CUDA_RESOURCE_VIEW_DESC;
    /// \endcode
    /// where:
    /// - ::CUDA_RESOURCE_VIEW_DESC::format specifies how the data contained in the CUDA array or CUDA mipmapped array should
    ///   be interpreted. Note that this can incur a change in size of the texture data. If the resource view format is a block
    ///   compressed format, then the underlying CUDA array or CUDA mipmapped array has to have a base of format ::CU_AD_FORMAT_UNSIGNED_INT32.
    ///   with 2 or 4 channels, depending on the block compressed format. For ex., BC1 and BC4 require the underlying CUDA array to have
    ///   a format of ::CU_AD_FORMAT_UNSIGNED_INT32 with 2 channels. The other BC formats require the underlying resource to have the same base
    ///   format but with 4 channels.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::width specifies the new width of the texture data. If the resource view format is a block
    ///   compressed format, this value has to be 4 times the original width of the resource. For non block compressed formats,
    ///   this value has to be equal to that of the original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::height specifies the new height of the texture data. If the resource view format is a block
    ///   compressed format, this value has to be 4 times the original height of the resource. For non block compressed formats,
    ///   this value has to be equal to that of the original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::depth specifies the new depth of the texture data. This value has to be equal to that of the
    ///   original resource.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::firstMipmapLevel specifies the most detailed mipmap level. This will be the new mipmap level zero.
    ///   For non-mipmapped resources, this value has to be zero.::CUDA_TEXTURE_DESC::minMipmapLevelClamp and ::CUDA_TEXTURE_DESC::maxMipmapLevelClamp
    ///   will be relative to this value. For ex., if the firstMipmapLevel is set to 2, and a minMipmapLevelClamp of 1.2 is specified,
    ///   then the actual minimum mipmap level clamp will be 3.2.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::lastMipmapLevel specifies the least detailed mipmap level. For non-mipmapped resources, this value
    ///   has to be zero.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::firstLayer specifies the first layer index for layered textures. This will be the new layer zero.
    ///   For non-layered resources, this value has to be zero.
    ///
    /// - ::CUDA_RESOURCE_VIEW_DESC::lastLayer specifies the last layer index for layered textures. For non-layered resources,
    ///   this value has to be zero.
    ///
    ///
    /// \param pTexObject   - Texture object to create
    /// \param pResDesc     - Resource descriptor
    /// \param pTexDesc     - Texture descriptor
    /// \param pResViewDesc - Resource view descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexObjectDestroy
    ///
    pub fn cuTexObjectCreate(pTexObject: *mut CUtexObject,
                             pResDesc: *const CUDA_RESOURCE_DESC,
                             pTexDesc: *const CUDA_TEXTURE_DESC,
                             pResViewDesc: *const CUDA_RESOURCE_VIEW_DESC)
                             -> CUresult;
}
extern "C" {
    /// \brief Destroys a texture object
    ///
    /// Destroys the texture object specified by \p texObject.
    ///
    /// \param texObject - Texture object to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexObjectCreate
    ///
    pub fn cuTexObjectDestroy(texObject: CUtexObject) -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's resource descriptor
    ///
    /// Returns the resource descriptor for the texture object specified by \p texObject.
    ///
    /// \param pResDesc  - Resource descriptor
    /// \param texObject - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexObjectCreate
    ///
    pub fn cuTexObjectGetResourceDesc(pResDesc: *mut CUDA_RESOURCE_DESC,
                                      texObject: CUtexObject)
                                      -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's texture descriptor
    ///
    /// Returns the texture descriptor for the texture object specified by \p texObject.
    ///
    /// \param pTexDesc  - Texture descriptor
    /// \param texObject - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexObjectCreate
    ///
    pub fn cuTexObjectGetTextureDesc(pTexDesc: *mut CUDA_TEXTURE_DESC,
                                     texObject: CUtexObject)
                                     -> CUresult;
}
extern "C" {
    /// \brief Returns a texture object's resource view descriptor
    ///
    /// Returns the resource view descriptor for the texture object specified by \p texObject.
    /// If no resource view was set for \p texObject, the ::CUDA_ERROR_INVALID_VALUE is returned.
    ///
    /// \param pResViewDesc - Resource view descriptor
    /// \param texObject    - Texture object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuTexObjectCreate
    ///
    pub fn cuTexObjectGetResourceViewDesc(pResViewDesc:
                                              *mut CUDA_RESOURCE_VIEW_DESC,
                                          texObject: CUtexObject) -> CUresult;
}
extern "C" {
    /// \brief Creates a surface object
    ///
    /// Creates a surface object and returns it in \p pSurfObject. \p pResDesc describes
    /// the data to perform surface load/stores on. ::CUDA_RESOURCE_DESC::resType must be
    /// ::CU_RESOURCE_TYPE_ARRAY and  ::CUDA_RESOURCE_DESC::res::array::hArray
    /// must be set to a valid CUDA array handle. ::CUDA_RESOURCE_DESC::flags must be set to zero.
    ///
    /// Surface objects are only supported on devices of compute capability 3.0 or higher.
    /// Additionally, a surface object is an opaque value, and, as such, should only be
    /// accessed through CUDA API calls.
    ///
    /// \param pSurfObject - Surface object to create
    /// \param pResDesc    - Resource descriptor
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuSurfObjectDestroy
    ///
    pub fn cuSurfObjectCreate(pSurfObject: *mut CUsurfObject,
                              pResDesc: *const CUDA_RESOURCE_DESC)
                              -> CUresult;
}
extern "C" {
    /// \brief Destroys a surface object
    ///
    /// Destroys the surface object specified by \p surfObject.
    ///
    /// \param surfObject - Surface object to destroy
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuSurfObjectCreate
    ///
    pub fn cuSurfObjectDestroy(surfObject: CUsurfObject) -> CUresult;
}
extern "C" {
    /// \brief Returns a surface object's resource descriptor
    ///
    /// Returns the resource descriptor for the surface object specified by \p surfObject.
    ///
    /// \param pResDesc   - Resource descriptor
    /// \param surfObject - Surface object
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE
    ///
    /// \sa ::cuSurfObjectCreate
    ///
    pub fn cuSurfObjectGetResourceDesc(pResDesc: *mut CUDA_RESOURCE_DESC,
                                       surfObject: CUsurfObject)
                                       -> CUresult;
}
extern "C" {
    /// \brief Queries if a device may directly access a peer device's memory.
    ///
    /// Returns in \p *canAccessPeer a value of 1 if contexts on \p dev are capable of
    /// directly accessing memory from contexts on \p peerDev and 0 otherwise.
    /// If direct access of \p peerDev from \p dev is possible, then access may be
    /// enabled on two specific contexts by calling ::cuCtxEnablePeerAccess().
    ///
    /// \param canAccessPeer - Returned access capability
    /// \param dev           - Device from which allocations on \p peerDev are to
    ///                        be directly accessed.
    /// \param peerDev       - Device on which the allocations to be directly accessed
    ///                        by \p dev reside.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE
    /// \notefnerr
    ///
    /// \sa ::cuCtxEnablePeerAccess,
    /// ::cuCtxDisablePeerAccess
    ///
    pub fn cuDeviceCanAccessPeer(canAccessPeer: *mut ::std::os::raw::c_int,
                                 dev: CUdevice,
                                 peerDev: CUdevice)
                                 -> CUresult;
}
extern "C" {
    /// \brief Queries attributes of the link between two devices.
    ///
    /// Returns in \p *value the value of the requested attribute \p attrib of the
    /// link between \p srcDevice and \p dstDevice. The supported attributes are:
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK: A relative value indicating the
    ///   performance of the link between two devices.
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED P2P: 1 if P2P Access is enable.
    /// - ::CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED: 1 if Atomic operations over
    ///   the link are supported.
    ///
    /// Returns ::CUDA_ERROR_INVALID_DEVICE if \p srcDevice or \p dstDevice are not valid
    /// or if they represent the same device.
    ///
    /// Returns ::CUDA_ERROR_INVALID_VALUE if \p attrib is not valid or if \p value is
    /// a null pointer.
    ///
    /// \param value         - Returned value of the requested attribute
    /// \param attrib        - The requested attribute of the link between \p srcDevice and \p dstDevice.
    /// \param srcDevice     - The source device of the target link.
    /// \param dstDevice     - The destination device of the target link.
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_DEVICE,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuCtxEnablePeerAccess,
    /// ::cuCtxDisablePeerAccess,
    /// ::cuCtxCanAccessPeer
    ///
    pub fn cuDeviceGetP2PAttribute(value: *mut ::std::os::raw::c_int,
                                   attrib: CUdevice_P2PAttribute,
                                   srcDevice: CUdevice,
                                   dstDevice: CUdevice)
                                   -> CUresult;
}
extern "C" {
    /// \brief Enables direct access to memory allocations in a peer context.
    ///
    /// If both the current context and \p peerContext are on devices which support unified
    /// addressing (as may be queried using ::CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING) and same
    /// major compute capability, then on success all allocations from \p peerContext will
    /// immediately be accessible by the current context.  See \ref CUDA_UNIFIED for additional
    /// details.
    ///
    /// Note that access granted by this call is unidirectional and that in order to access
    /// memory from the current context in \p peerContext, a separate symmetric call
    /// to ::cuCtxEnablePeerAccess() is required.
    ///
    /// There is a system-wide maximum of eight peer connections per device.
    ///
    /// Returns ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED if ::cuDeviceCanAccessPeer() indicates
    /// that the ::CUdevice of the current context cannot directly access memory
    /// from the ::CUdevice of \p peerContext.
    ///
    /// Returns ::CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED if direct access of
    /// \p peerContext from the current context has already been enabled.
    ///
    /// Returns ::CUDA_ERROR_TOO_MANY_PEERS if direct peer access is not possible
    /// because hardware resources required for peer access have been exhausted.
    ///
    /// Returns ::CUDA_ERROR_INVALID_CONTEXT if there is no current context, \p peerContext
    /// is not a valid context, or if the current context is \p peerContext.
    ///
    /// Returns ::CUDA_ERROR_INVALID_VALUE if \p Flags is not 0.
    ///
    /// \param peerContext - Peer context to enable direct access to from the current context
    /// \param Flags       - Reserved for future use and must be set to 0
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED,
    /// ::CUDA_ERROR_TOO_MANY_PEERS,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_PEER_ACCESS_UNSUPPORTED,
    /// ::CUDA_ERROR_INVALID_VALUE
    /// \notefnerr
    ///
    /// \sa ::cuDeviceCanAccessPeer,
    /// ::cuCtxDisablePeerAccess
    ///
    pub fn cuCtxEnablePeerAccess(peerContext: CUcontext,
                                 Flags: ::std::os::raw::c_uint)
                                 -> CUresult;
}
extern "C" {
    /// \brief Disables direct access to memory allocations in a peer context and
    /// unregisters any registered allocations.
    ///
    /// Returns ::CUDA_ERROR_PEER_ACCESS_NOT_ENABLED if direct peer access has
    /// not yet been enabled from \p peerContext to the current context.
    ///
    /// Returns ::CUDA_ERROR_INVALID_CONTEXT if there is no current context, or if
    /// \p peerContext is not a valid context.
    ///
    /// \param peerContext - Peer context to disable direct access to
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_PEER_ACCESS_NOT_ENABLED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// \notefnerr
    ///
    /// \sa ::cuDeviceCanAccessPeer,
    /// ::cuCtxEnablePeerAccess
    ///
    pub fn cuCtxDisablePeerAccess(peerContext: CUcontext) -> CUresult;
}
extern "C" {
    /// \brief Unregisters a graphics resource for access by CUDA
    ///
    /// Unregisters the graphics resource \p resource so it is not accessible by
    /// CUDA unless registered again.
    ///
    /// If \p resource is invalid then ::CUDA_ERROR_INVALID_HANDLE is
    /// returned.
    ///
    /// \param resource - Resource to unregister
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_UNKNOWN
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsD3D9RegisterResource,
    /// ::cuGraphicsD3D10RegisterResource,
    /// ::cuGraphicsD3D11RegisterResource,
    /// ::cuGraphicsGLRegisterBuffer,
    /// ::cuGraphicsGLRegisterImage
    ///
    pub fn cuGraphicsUnregisterResource(resource: CUgraphicsResource)
                                        -> CUresult;
}
extern "C" {
    /// \brief Get an array through which to access a subresource of a mapped graphics resource.
    ///
    /// Returns in \p *pArray an array through which the subresource of the mapped
    /// graphics resource \p resource which corresponds to array index \p arrayIndex
    /// and mipmap level \p mipLevel may be accessed.  The value set in \p *pArray may
    /// change every time that \p resource is mapped.
    ///
    /// If \p resource is not a texture then it cannot be accessed via an array and
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY is returned.
    /// If \p arrayIndex is not a valid array index for \p resource then
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    /// If \p mipLevel is not a valid mipmap level for \p resource then
    /// ::CUDA_ERROR_INVALID_VALUE is returned.
    /// If \p resource is not mapped then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param pArray      - Returned array through which a subresource of \p resource may be accessed
    /// \param resource    - Mapped resource to access
    /// \param arrayIndex  - Array index for array textures or cubemap face
    ///                      index as defined by ::CUarray_cubemap_face for
    ///                      cubemap textures for the subresource to access
    /// \param mipLevel    - Mipmap level for the subresource to access
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY
    /// \notefnerr
    ///
    /// \sa ::cuGraphicsResourceGetMappedPointer
    ///
    pub fn cuGraphicsSubResourceGetMappedArray(pArray: *mut CUarray,
                                               resource: CUgraphicsResource,
                                               arrayIndex:
                                                   ::std::os::raw::c_uint,
                                               mipLevel:
                                                   ::std::os::raw::c_uint)
     -> CUresult;
}
extern "C" {
    /// \brief Get a mipmapped array through which to access a mapped graphics resource.
    ///
    /// Returns in \p *pMipmappedArray a mipmapped array through which the mapped graphics
    /// resource \p resource. The value set in \p *pMipmappedArray may change every time
    /// that \p resource is mapped.
    ///
    /// If \p resource is not a texture then it cannot be accessed via a mipmapped array and
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY is returned.
    /// If \p resource is not mapped then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param pMipmappedArray - Returned mipmapped array through which \p resource may be accessed
    /// \param resource        - Mapped resource to access
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_VALUE,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_NOT_MAPPED_AS_ARRAY
    /// \notefnerr
    ///
    /// \sa ::cuGraphicsResourceGetMappedPointer
    ///
    pub fn cuGraphicsResourceGetMappedMipmappedArray(pMipmappedArray:
                                                         *mut CUmipmappedArray,
                                                     resource:
                                                         CUgraphicsResource)
     -> CUresult;
}
extern "C" {
    pub fn cuGraphicsResourceGetMappedPointer_v2(pDevPtr: *mut CUdeviceptr,
                                                 pSize: *mut usize,
                                                 resource: CUgraphicsResource)
                                                 -> CUresult;
}
extern "C" {
    pub fn cuGraphicsResourceSetMapFlags_v2(resource: CUgraphicsResource,
                                            flags: ::std::os::raw::c_uint)
                                            -> CUresult;
}
extern "C" {
    /// \brief Map graphics resources for access by CUDA
    ///
    /// Maps the \p count graphics resources in \p resources for access by CUDA.
    ///
    /// The resources in \p resources may be accessed by CUDA until they
    /// are unmapped. The graphics API from which \p resources were registered
    /// should not access any resources while they are mapped by CUDA. If an
    /// application does so, the results are undefined.
    ///
    /// This function provides the synchronization guarantee that any graphics calls
    /// issued before ::cuGraphicsMapResources() will complete before any subsequent CUDA
    /// work issued in \p stream begins.
    ///
    /// If \p resources includes any duplicate entries then ::CUDA_ERROR_INVALID_HANDLE is returned.
    /// If any of \p resources are presently mapped for access by CUDA then ::CUDA_ERROR_ALREADY_MAPPED is returned.
    ///
    /// \param count      - Number of resources to map
    /// \param resources  - Resources to map for CUDA usage
    /// \param hStream    - Stream with which to synchronize
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_ALREADY_MAPPED,
    /// ::CUDA_ERROR_UNKNOWN
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsResourceGetMappedPointer,
    /// ::cuGraphicsSubResourceGetMappedArray,
    /// ::cuGraphicsUnmapResources
    ///
    pub fn cuGraphicsMapResources(count: ::std::os::raw::c_uint,
                                  resources: *mut CUgraphicsResource,
                                  hStream: CUstream)
                                  -> CUresult;
}
extern "C" {
    /// \brief Unmap graphics resources.
    ///
    /// Unmaps the \p count graphics resources in \p resources.
    ///
    /// Once unmapped, the resources in \p resources may not be accessed by CUDA
    /// until they are mapped again.
    ///
    /// This function provides the synchronization guarantee that any CUDA work issued
    /// in \p stream before ::cuGraphicsUnmapResources() will complete before any
    /// subsequently issued graphics work begins.
    ///
    ///
    /// If \p resources includes any duplicate entries then ::CUDA_ERROR_INVALID_HANDLE is returned.
    /// If any of \p resources are not presently mapped for access by CUDA then ::CUDA_ERROR_NOT_MAPPED is returned.
    ///
    /// \param count      - Number of resources to unmap
    /// \param resources  - Resources to unmap
    /// \param hStream    - Stream with which to synchronize
    ///
    /// \return
    /// ::CUDA_SUCCESS,
    /// ::CUDA_ERROR_DEINITIALIZED,
    /// ::CUDA_ERROR_NOT_INITIALIZED,
    /// ::CUDA_ERROR_INVALID_CONTEXT,
    /// ::CUDA_ERROR_INVALID_HANDLE,
    /// ::CUDA_ERROR_NOT_MAPPED,
    /// ::CUDA_ERROR_UNKNOWN
    /// \note_null_stream
    /// \notefnerr
    ///
    /// \sa
    /// ::cuGraphicsMapResources
    ///
    pub fn cuGraphicsUnmapResources(count: ::std::os::raw::c_uint,
                                    resources: *mut CUgraphicsResource,
                                    hStream: CUstream)
                                    -> CUresult;
}
extern "C" {
    /// @}
    pub fn cuGetExportTable(ppExportTable: *mut *const ::std::os::raw::c_void,
                            pExportTableId: *const CUuuid) -> CUresult;
}
